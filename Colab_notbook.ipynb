{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokeddemhalima/multimodal_fake_news_detection/blob/main/Halima_code_version5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3PUx5_rzVvz"
      },
      "source": [
        "# Mini-conda and Drive installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP-dyhRV7egW",
        "outputId": "74acf7b1-9ca0-492c-d8dc-ef5294df3472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python # should return /usr/local/bin/python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSAPsqJU7juj",
        "outputId": "26ccdd8f-abc5-4689-c480-11dddf8d7c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.14\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uwn2aMO70fO",
        "outputId": "eeb96247-4b82-4e1d-ef87-4203bb873598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nktc2Ww8GSc",
        "outputId": "c07c4eac-fe6e-475d-c2ad-c71ecfc97503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ibC2rSiGjh",
        "outputId": "0f2880d3-51c8-441b-93e6-25b607420376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREFIX=/usr/local\n",
            "reinstalling: python-3.7.1-h0371630_7 ...\n",
            "Python 3.7.1\n",
            "reinstalling: ca-certificates-2018.03.07-0 ...\n",
            "reinstalling: conda-env-2.6.0-1 ...\n",
            "reinstalling: libgcc-ng-8.2.0-hdf63c60_1 ...\n",
            "reinstalling: libstdcxx-ng-8.2.0-hdf63c60_1 ...\n",
            "reinstalling: libffi-3.2.1-hd88cf55_4 ...\n",
            "reinstalling: ncurses-6.1-he6710b0_1 ...\n",
            "reinstalling: openssl-1.1.1a-h7b6447c_0 ...\n",
            "reinstalling: xz-5.2.4-h14c3975_4 ...\n",
            "reinstalling: yaml-0.1.7-had09818_2 ...\n",
            "reinstalling: zlib-1.2.11-h7b6447c_3 ...\n",
            "reinstalling: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "reinstalling: readline-7.0-h7b6447c_5 ...\n",
            "reinstalling: tk-8.6.8-hbc83047_0 ...\n",
            "reinstalling: sqlite-3.26.0-h7b6447c_0 ...\n",
            "reinstalling: asn1crypto-0.24.0-py37_0 ...\n",
            "reinstalling: certifi-2018.11.29-py37_0 ...\n",
            "reinstalling: chardet-3.0.4-py37_1 ...\n",
            "reinstalling: idna-2.8-py37_0 ...\n",
            "reinstalling: pycosat-0.6.3-py37h14c3975_0 ...\n",
            "reinstalling: pycparser-2.19-py37_0 ...\n",
            "reinstalling: pysocks-1.6.8-py37_0 ...\n",
            "reinstalling: ruamel_yaml-0.15.46-py37h14c3975_0 ...\n",
            "reinstalling: six-1.12.0-py37_0 ...\n",
            "reinstalling: cffi-1.11.5-py37he75722e_1 ...\n",
            "reinstalling: setuptools-40.6.3-py37_0 ...\n",
            "reinstalling: cryptography-2.4.2-py37h1ba5d50_0 ...\n",
            "reinstalling: wheel-0.32.3-py37_0 ...\n",
            "reinstalling: pip-18.1-py37_0 ...\n",
            "reinstalling: pyopenssl-18.0.0-py37_0 ...\n",
            "reinstalling: urllib3-1.24.1-py37_0 ...\n",
            "reinstalling: requests-2.21.0-py37_0 ...\n",
            "reinstalling: conda-4.5.12-py37_0 ...\n",
            "installation finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2022-10-10 20:10:08--  https://repo.continuum.io/miniconda/Miniconda3-4.5.12-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.12-Linux-x86_64.sh [following]\n",
            "--2022-10-10 20:10:08--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.12-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69826864 (67M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.12-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 2.36M 28s\n",
            "    50K .......... .......... .......... .......... ..........  0% 1.47M 37s\n",
            "   100K .......... .......... .......... .......... ..........  0% 1.40M 40s\n",
            "   150K .......... .......... .......... .......... ..........  0% 2.62M 37s\n",
            "   200K .......... .......... .......... .......... ..........  0% 2.86M 34s\n",
            "   250K .......... .......... .......... .......... ..........  0% 1.36M 36s\n",
            "   300K .......... .......... .......... .......... ..........  0% 1.36M 38s\n",
            "   350K .......... .......... .......... .......... ..........  0% 2.69M 36s\n",
            "   400K .......... .......... .......... .......... ..........  0%  597K 45s\n",
            "   450K .......... .......... .......... .......... ..........  0% 2.75M 43s\n",
            "   500K .......... .......... .......... .......... ..........  0% 1.37M 43s\n",
            "   550K .......... .......... .......... .......... ..........  0% 3.01M 41s\n",
            "   600K .......... .......... .......... .......... ..........  0% 1.30M 42s\n",
            "   650K .......... .......... .......... .......... ..........  1% 3.52M 40s\n",
            "   700K .......... .......... .......... .......... ..........  1% 1.88M 40s\n",
            "   750K .......... .......... .......... .......... ..........  1%  524K 46s\n",
            "   800K .......... .......... .......... .......... ..........  1% 8.80M 43s\n",
            "   850K .......... .......... .......... .......... ..........  1% 7.74M 41s\n",
            "   900K .......... .......... .......... .......... ..........  1%  977K 43s\n",
            "   950K .......... .......... .......... .......... ..........  1% 4.13M 41s\n",
            "  1000K .......... .......... .......... .......... ..........  1% 7.97M 40s\n",
            "  1050K .......... .......... .......... .......... ..........  1%  988K 41s\n",
            "  1100K .......... .......... .......... .......... ..........  1% 6.92M 40s\n",
            "  1150K .......... .......... .......... .......... ..........  1% 4.05M 39s\n",
            "  1200K .......... .......... .......... .......... ..........  1%  485K 43s\n",
            "  1250K .......... .......... .......... .......... ..........  1% 7.67M 41s\n",
            "  1300K .......... .......... .......... .......... ..........  1% 3.42M 40s\n",
            "  1350K .......... .......... .......... .......... ..........  2%  909K 41s\n",
            "  1400K .......... .......... .......... .......... ..........  2% 8.41M 40s\n",
            "  1450K .......... .......... .......... .......... ..........  2% 8.18M 39s\n",
            "  1500K .......... .......... .......... .......... ..........  2%  949K 40s\n",
            "  1550K .......... .......... .......... .......... ..........  2% 6.88M 39s\n",
            "  1600K .......... .......... .......... .......... ..........  2%  510K 42s\n",
            "  1650K .......... .......... .......... .......... ..........  2% 8.45M 41s\n",
            "  1700K .......... .......... .......... .......... ..........  2% 4.32M 40s\n",
            "  1750K .......... .......... .......... .......... ..........  2%  894K 41s\n",
            "  1800K .......... .......... .......... .......... ..........  2% 8.45M 40s\n",
            "  1850K .......... .......... .......... .......... ..........  2% 4.50M 39s\n",
            "  1900K .......... .......... .......... .......... ..........  2% 1.14M 40s\n",
            "  1950K .......... .......... .......... .......... ..........  2% 4.14M 39s\n",
            "  2000K .......... .......... .......... .......... ..........  3% 4.52M 39s\n",
            "  2050K .......... .......... .......... .......... ..........  3%  568K 40s\n",
            "  2100K .......... .......... .......... .......... ..........  3% 4.36M 40s\n",
            "  2150K .......... .......... .......... .......... ..........  3%  785K 41s\n",
            "  2200K .......... .......... .......... .......... ..........  3% 10.3M 40s\n",
            "  2250K .......... .......... .......... .......... ..........  3% 4.35M 39s\n",
            "  2300K .......... .......... .......... .......... ..........  3% 8.43M 39s\n",
            "  2350K .......... .......... .......... .......... ..........  3% 1.19M 39s\n",
            "  2400K .......... .......... .......... .......... ..........  3% 3.25M 39s\n",
            "  2450K .......... .......... .......... .......... ..........  3% 5.69M 38s\n",
            "  2500K .......... .......... .......... .......... ..........  3%  504K 40s\n",
            "  2550K .......... .......... .......... .......... ..........  3% 8.31M 39s\n",
            "  2600K .......... .......... .......... .......... ..........  3% 8.41M 38s\n",
            "  2650K .......... .......... .......... .......... ..........  3%  813K 39s\n",
            "  2700K .......... .......... .......... .......... ..........  4% 6.52M 39s\n",
            "  2750K .......... .......... .......... .......... ..........  4% 10.3M 38s\n",
            "  2800K .......... .......... .......... .......... ..........  4% 1.17M 38s\n",
            "  2850K .......... .......... .......... .......... ..........  4% 4.48M 38s\n",
            "  2900K .......... .......... .......... .......... ..........  4%  500K 39s\n",
            "  2950K .......... .......... .......... .......... ..........  4% 9.38M 39s\n",
            "  3000K .......... .......... .......... .......... ..........  4% 3.88M 38s\n",
            "  3050K .......... .......... .......... .......... ..........  4% 11.1M 38s\n",
            "  3100K .......... .......... .......... .......... ..........  4%  874K 38s\n",
            "  3150K .......... .......... .......... .......... ..........  4% 4.26M 38s\n",
            "  3200K .......... .......... .......... .......... ..........  4% 1.20M 38s\n",
            "  3250K .......... .......... .......... .......... ..........  4% 8.60M 38s\n",
            "  3300K .......... .......... .......... .......... ..........  4% 4.57M 37s\n",
            "  3350K .......... .......... .......... .......... ..........  4%  458K 39s\n",
            "  3400K .......... .......... .......... .......... ..........  5% 13.4M 38s\n",
            "  3450K .......... .......... .......... .......... ..........  5% 3.99M 38s\n",
            "  3500K .......... .......... .......... .......... ..........  5%  936K 38s\n",
            "  3550K .......... .......... .......... .......... ..........  5% 4.15M 38s\n",
            "  3600K .......... .......... .......... .......... ..........  5%  172M 37s\n",
            "  3650K .......... .......... .......... .......... ..........  5% 1.13M 38s\n",
            "  3700K .......... .......... .......... .......... ..........  5% 4.85M 37s\n",
            "  3750K .......... .......... .......... .......... ..........  5% 9.01M 37s\n",
            "  3800K .......... .......... .......... .......... ..........  5%  468K 38s\n",
            "  3850K .......... .......... .......... .......... ..........  5% 8.28M 38s\n",
            "  3900K .......... .......... .......... .......... ..........  5% 4.07M 37s\n",
            "  3950K .......... .......... .......... .......... ..........  5%  733K 38s\n",
            "  4000K .......... .......... .......... .......... ..........  5% 3.98M 38s\n",
            "  4050K .......... .......... .......... .......... ..........  6% 9.48M 37s\n",
            "  4100K .......... .......... .......... .......... ..........  6% 2.09M 37s\n",
            "  4150K .......... .......... .......... .......... ..........  6% 4.28M 37s\n",
            "  4200K .......... .......... .......... .......... ..........  6%  476K 38s\n",
            "  4250K .......... .......... .......... .......... ..........  6% 7.31M 38s\n",
            "  4300K .......... .......... .......... .......... ..........  6% 9.00M 37s\n",
            "  4350K .......... .......... .......... .......... ..........  6%  611K 38s\n",
            "  4400K .......... .......... .......... .......... ..........  6%  182M 38s\n",
            "  4450K .......... .......... .......... .......... ..........  6% 4.58M 37s\n",
            "  4500K .......... .......... .......... .......... ..........  6% 2.14M 37s\n",
            "  4550K .......... .......... .......... .......... ..........  6% 7.19M 37s\n",
            "  4600K .......... .......... .......... .......... ..........  6% 4.57M 37s\n",
            "  4650K .......... .......... .......... .......... ..........  6% 8.32M 36s\n",
            "  4700K .......... .......... .......... .......... ..........  6%  339K 38s\n",
            "  4750K .......... .......... .......... .......... ..........  7% 8.64M 37s\n",
            "  4800K .......... .......... .......... .......... ..........  7%  437K 38s\n",
            "  4850K .......... .......... .......... .......... ..........  7% 8.38M 38s\n",
            "  4900K .......... .......... .......... .......... ..........  7% 2.23M 38s\n",
            "  4950K .......... .......... .......... .......... ..........  7% 1.60M 38s\n",
            "  5000K .......... .......... .......... .......... ..........  7% 8.48M 38s\n",
            "  5050K .......... .......... .......... .......... ..........  7% 4.08M 37s\n",
            "  5100K .......... .......... .......... .......... ..........  7% 8.37M 37s\n",
            "  5150K .......... .......... .......... .......... ..........  7%  627K 38s\n",
            "  5200K .......... .......... .......... .......... ..........  7% 8.82M 37s\n",
            "  5250K .......... .......... .......... .......... ..........  7%  407K 38s\n",
            "  5300K .......... .......... .......... .......... ..........  7% 4.44M 38s\n",
            "  5350K .......... .......... .......... .......... ..........  7% 7.34M 38s\n",
            "  5400K .......... .......... .......... .......... ..........  7% 4.40M 38s\n",
            "  5450K .......... .......... .......... .......... ..........  8% 8.44M 37s\n",
            "  5500K .......... .......... .......... .......... ..........  8% 4.04M 37s\n",
            "  5550K .......... .......... .......... .......... ..........  8%  526K 38s\n",
            "  5600K .......... .......... .......... .......... ..........  8% 4.35M 38s\n",
            "  5650K .......... .......... .......... .......... ..........  8% 8.86M 37s\n",
            "  5700K .......... .......... .......... .......... ..........  8%  512K 38s\n",
            "  5750K .......... .......... .......... .......... ..........  8% 4.24M 38s\n",
            "  5800K .......... .......... .......... .......... ..........  8% 9.12M 37s\n",
            "  5850K .......... .......... .......... .......... ..........  8% 3.49M 37s\n",
            "  5900K .......... .......... .......... .......... ..........  8% 12.7M 37s\n",
            "  5950K .......... .......... .......... .......... ..........  8% 4.38M 37s\n",
            "  6000K .......... .......... .......... .......... ..........  8%  208K 39s\n",
            "  6050K .......... .......... .......... .......... ..........  8% 4.29M 39s\n",
            "  6100K .......... .......... .......... .......... ..........  9% 3.36M 38s\n",
            "  6150K .......... .......... .......... .......... ..........  9% 8.41M 38s\n",
            "  6200K .......... .......... .......... .......... ..........  9% 4.39M 38s\n",
            "  6250K .......... .......... .......... .......... ..........  9% 1.62M 38s\n",
            "  6300K .......... .......... .......... .......... ..........  9% 4.37M 38s\n",
            "  6350K .......... .......... .......... .......... ..........  9% 8.66M 37s\n",
            "  6400K .......... .......... .......... .......... ..........  9% 4.00M 37s\n",
            "  6450K .......... .......... .......... .......... ..........  9% 8.58M 37s\n",
            "  6500K .......... .......... .......... .......... ..........  9% 4.36M 37s\n",
            "  6550K .......... .......... .......... .......... ..........  9%  319K 38s\n",
            "  6600K .......... .......... .......... .......... ..........  9% 7.40M 38s\n",
            "  6650K .......... .......... .......... .......... ..........  9% 1.48M 38s\n",
            "  6700K .......... .......... .......... .......... ..........  9% 8.81M 37s\n",
            "  6750K .......... .......... .......... .......... ..........  9% 4.03M 37s\n",
            "  6800K .......... .......... .......... .......... .......... 10% 2.03M 37s\n",
            "  6850K .......... .......... .......... .......... .......... 10%  249M 37s\n",
            "  6900K .......... .......... .......... .......... .......... 10% 5.77M 37s\n",
            "  6950K .......... .......... .......... .......... .......... 10%  332K 38s\n",
            "  7000K .......... .......... .......... .......... .......... 10% 4.24M 37s\n",
            "  7050K .......... .......... .......... .......... .......... 10% 8.55M 37s\n",
            "  7100K .......... .......... .......... .......... .......... 10% 1.59M 37s\n",
            "  7150K .......... .......... .......... .......... .......... 10% 8.44M 37s\n",
            "  7200K .......... .......... .......... .......... .......... 10% 3.22M 37s\n",
            "  7250K .......... .......... .......... .......... .......... 10% 18.2M 36s\n",
            "  7300K .......... .......... .......... .......... .......... 10% 1.56M 36s\n",
            "  7350K .......... .......... .......... .......... .......... 10% 4.56M 36s\n",
            "  7400K .......... .......... .......... .......... .......... 10%  360K 37s\n",
            "  7450K .......... .......... .......... .......... .......... 10% 4.33M 37s\n",
            "  7500K .......... .......... .......... .......... .......... 11% 7.14M 37s\n",
            "  7550K .......... .......... .......... .......... .......... 11% 1.30M 37s\n",
            "  7600K .......... .......... .......... .......... .......... 11% 8.63M 36s\n",
            "  7650K .......... .......... .......... .......... .......... 11% 4.39M 36s\n",
            "  7700K .......... .......... .......... .......... .......... 11% 2.38M 36s\n",
            "  7750K .......... .......... .......... .......... .......... 11% 8.31M 36s\n",
            "  7800K .......... .......... .......... .......... .......... 11% 4.46M 36s\n",
            "  7850K .......... .......... .......... .......... .......... 11%  357K 37s\n",
            "  7900K .......... .......... .......... .......... .......... 11% 4.42M 36s\n",
            "  7950K .......... .......... .......... .......... .......... 11% 8.60M 36s\n",
            "  8000K .......... .......... .......... .......... .......... 11% 1.26M 36s\n",
            "  8050K .......... .......... .......... .......... .......... 11% 8.81M 36s\n",
            "  8100K .......... .......... .......... .......... .......... 11% 4.29M 36s\n",
            "  8150K .......... .......... .......... .......... .......... 12% 2.48M 36s\n",
            "  8200K .......... .......... .......... .......... .......... 12% 8.82M 36s\n",
            "  8250K .......... .......... .......... .......... .......... 12%  346K 36s\n",
            "  8300K .......... .......... .......... .......... .......... 12% 7.46M 36s\n",
            "  8350K .......... .......... .......... .......... .......... 12% 3.73M 36s\n",
            "  8400K .......... .......... .......... .......... .......... 12% 11.3M 36s\n",
            "  8450K .......... .......... .......... .......... .......... 12% 1.31M 36s\n",
            "  8500K .......... .......... .......... .......... .......... 12% 4.49M 36s\n",
            "  8550K .......... .......... .......... .......... .......... 12% 3.35M 36s\n",
            "  8600K .......... .......... .......... .......... .......... 12% 4.37M 35s\n",
            "  8650K .......... .......... .......... .......... .......... 12% 8.74M 35s\n",
            "  8700K .......... .......... .......... .......... .......... 12%  343K 36s\n",
            "  8750K .......... .......... .......... .......... .......... 12% 8.71M 36s\n",
            "  8800K .......... .......... .......... .......... .......... 12% 4.01M 36s\n",
            "  8850K .......... .......... .......... .......... .......... 13% 8.74M 35s\n",
            "  8900K .......... .......... .......... .......... .......... 13% 1.19M 35s\n",
            "  8950K .......... .......... .......... .......... .......... 13% 3.70M 35s\n",
            "  9000K .......... .......... .......... .......... .......... 13% 4.10M 35s\n",
            "  9050K .......... .......... .......... .......... .......... 13% 3.21M 35s\n",
            "  9100K .......... .......... .......... .......... .......... 13% 24.0M 35s\n",
            "  9150K .......... .......... .......... .......... .......... 13%  347K 36s\n",
            "  9200K .......... .......... .......... .......... .......... 13% 12.4M 35s\n",
            "  9250K .......... .......... .......... .......... .......... 13% 4.37M 35s\n",
            "  9300K .......... .......... .......... .......... .......... 13% 1.17M 35s\n",
            "  9350K .......... .......... .......... .......... .......... 13% 8.42M 35s\n",
            "  9400K .......... .......... .......... .......... .......... 13% 4.28M 35s\n",
            "  9450K .......... .......... .......... .......... .......... 13% 3.55M 35s\n",
            "  9500K .......... .......... .......... .......... .......... 14% 4.58M 35s\n",
            "  9550K .......... .......... .......... .......... .......... 14% 8.74M 34s\n",
            "  9600K .......... .......... .......... .......... .......... 14%  341K 35s\n",
            "  9650K .......... .......... .......... .......... .......... 14% 8.54M 35s\n",
            "  9700K .......... .......... .......... .......... .......... 14% 3.90M 35s\n",
            "  9750K .......... .......... .......... .......... .......... 14% 1.27M 35s\n",
            "  9800K .......... .......... .......... .......... .......... 14% 7.15M 35s\n",
            "  9850K .......... .......... .......... .......... .......... 14% 4.91M 35s\n",
            "  9900K .......... .......... .......... .......... .......... 14% 2.91M 34s\n",
            "  9950K .......... .......... .......... .......... .......... 14% 4.36M 34s\n",
            " 10000K .......... .......... .......... .......... .......... 14% 6.76M 34s\n",
            " 10050K .......... .......... .......... .......... .......... 14%  354K 35s\n",
            " 10100K .......... .......... .......... .......... .......... 14% 4.46M 35s\n",
            " 10150K .......... .......... .......... .......... .......... 14% 8.12M 34s\n",
            " 10200K .......... .......... .......... .......... .......... 15% 1.19M 34s\n",
            " 10250K .......... .......... .......... .......... .......... 15% 8.97M 34s\n",
            " 10300K .......... .......... .......... .......... .......... 15% 3.99M 34s\n",
            " 10350K .......... .......... .......... .......... .......... 15% 3.42M 34s\n",
            " 10400K .......... .......... .......... .......... .......... 15% 4.53M 34s\n",
            " 10450K .......... .......... .......... .......... .......... 15% 8.53M 34s\n",
            " 10500K .......... .......... .......... .......... .......... 15%  340K 34s\n",
            " 10550K .......... .......... .......... .......... .......... 15% 4.70M 34s\n",
            " 10600K .......... .......... .......... .......... .......... 15% 8.10M 34s\n",
            " 10650K .......... .......... .......... .......... .......... 15% 1.31M 34s\n",
            " 10700K .......... .......... .......... .......... .......... 15% 5.41M 34s\n",
            " 10750K .......... .......... .......... .......... .......... 15% 2.87M 34s\n",
            " 10800K .......... .......... .......... .......... .......... 15% 9.66M 34s\n",
            " 10850K .......... .......... .......... .......... .......... 15% 4.34M 34s\n",
            " 10900K .......... .......... .......... .......... .......... 16%  343K 34s\n",
            " 10950K .......... .......... .......... .......... .......... 16% 7.99M 34s\n",
            " 11000K .......... .......... .......... .......... .......... 16% 4.33M 34s\n",
            " 11050K .......... .......... .......... .......... .......... 16% 7.37M 34s\n",
            " 11100K .......... .......... .......... .......... .......... 16% 1.36M 34s\n",
            " 11150K .......... .......... .......... .......... .......... 16% 6.92M 34s\n",
            " 11200K .......... .......... .......... .......... .......... 16% 2.58M 34s\n",
            " 11250K .......... .......... .......... .......... .......... 16% 7.98M 33s\n",
            " 11300K .......... .......... .......... .......... .......... 16% 4.48M 33s\n",
            " 11350K .......... .......... .......... .......... .......... 16%  341K 34s\n",
            " 11400K .......... .......... .......... .......... .......... 16% 8.43M 34s\n",
            " 11450K .......... .......... .......... .......... .......... 16% 4.46M 34s\n",
            " 11500K .......... .......... .......... .......... .......... 16% 1.26M 34s\n",
            " 11550K .......... .......... .......... .......... .......... 17% 4.21M 33s\n",
            " 11600K .......... .......... .......... .......... .......... 17% 4.70M 33s\n",
            " 11650K .......... .......... .......... .......... .......... 17% 4.02M 33s\n",
            " 11700K .......... .......... .......... .......... .......... 17% 4.35M 33s\n",
            " 11750K .......... .......... .......... .......... .......... 17% 8.89M 33s\n",
            " 11800K .......... .......... .......... .......... .......... 17%  351K 33s\n",
            " 11850K .......... .......... .......... .......... .......... 17% 8.91M 33s\n",
            " 11900K .......... .......... .......... .......... .......... 17% 4.09M 33s\n",
            " 11950K .......... .......... .......... .......... .......... 17% 1.18M 33s\n",
            " 12000K .......... .......... .......... .......... .......... 17% 4.35M 33s\n",
            " 12050K .......... .......... .......... .......... .......... 17% 8.39M 33s\n",
            " 12100K .......... .......... .......... .......... .......... 17% 1.98M 33s\n",
            " 12150K .......... .......... .......... .......... .......... 17% 3.67M 33s\n",
            " 12200K .......... .......... .......... .......... .......... 17% 13.4M 33s\n",
            " 12250K .......... .......... .......... .......... .......... 18%  374K 33s\n",
            " 12300K .......... .......... .......... .......... .......... 18% 8.53M 33s\n",
            " 12350K .......... .......... .......... .......... .......... 18% 4.01M 33s\n",
            " 12400K .......... .......... .......... .......... .......... 18% 1.00M 33s\n",
            " 12450K .......... .......... .......... .......... .......... 18% 4.32M 33s\n",
            " 12500K .......... .......... .......... .......... .......... 18% 3.70M 33s\n",
            " 12550K .......... .......... .......... .......... .......... 18% 7.82M 33s\n",
            " 12600K .......... .......... .......... .......... .......... 18% 4.35M 32s\n",
            " 12650K .......... .......... .......... .......... .......... 18% 7.83M 32s\n",
            " 12700K .......... .......... .......... .......... .......... 18%  363K 33s\n",
            " 12750K .......... .......... .......... .......... .......... 18% 22.9M 33s\n",
            " 12800K .......... .......... .......... .......... .......... 18% 4.09M 33s\n",
            " 12850K .......... .......... .......... .......... .......... 18%  948K 33s\n",
            " 12900K .......... .......... .......... .......... .......... 18% 5.08M 32s\n",
            " 12950K .......... .......... .......... .......... .......... 19% 2.71M 32s\n",
            " 13000K .......... .......... .......... .......... .......... 19% 8.99M 32s\n",
            " 13050K .......... .......... .......... .......... .......... 19% 4.41M 32s\n",
            " 13100K .......... .......... .......... .......... .......... 19% 7.41M 32s\n",
            " 13150K .......... .......... .......... .......... .......... 19%  390K 32s\n",
            " 13200K .......... .......... .......... .......... .......... 19% 8.46M 32s\n",
            " 13250K .......... .......... .......... .......... .......... 19%  882K 32s\n",
            " 13300K .......... .......... .......... .......... .......... 19% 4.30M 32s\n",
            " 13350K .......... .......... .......... .......... .......... 19% 7.94M 32s\n",
            " 13400K .......... .......... .......... .......... .......... 19% 2.20M 32s\n",
            " 13450K .......... .......... .......... .......... .......... 19%  207M 32s\n",
            " 13500K .......... .......... .......... .......... .......... 19% 3.83M 32s\n",
            " 13550K .......... .......... .......... .......... .......... 19%  368K 32s\n",
            " 13600K .......... .......... .......... .......... .......... 20% 4.37M 32s\n",
            " 13650K .......... .......... .......... .......... .......... 20% 4.18M 32s\n",
            " 13700K .......... .......... .......... .......... .......... 20% 1.08M 32s\n",
            " 13750K .......... .......... .......... .......... .......... 20% 4.96M 32s\n",
            " 13800K .......... .......... .......... .......... .......... 20% 7.95M 32s\n",
            " 13850K .......... .......... .......... .......... .......... 20% 1.93M 32s\n",
            " 13900K .......... .......... .......... .......... .......... 20% 8.52M 32s\n",
            " 13950K .......... .......... .......... .......... .......... 20% 4.45M 32s\n",
            " 14000K .......... .......... .......... .......... .......... 20%  389K 32s\n",
            " 14050K .......... .......... .......... .......... .......... 20% 4.34M 32s\n",
            " 14100K .......... .......... .......... .......... .......... 20% 3.55M 32s\n",
            " 14150K .......... .......... .......... .......... .......... 20% 1.25M 32s\n",
            " 14200K .......... .......... .......... .......... .......... 20% 4.87M 32s\n",
            " 14250K .......... .......... .......... .......... .......... 20% 8.09M 32s\n",
            " 14300K .......... .......... .......... .......... .......... 21% 1.55M 32s\n",
            " 14350K .......... .......... .......... .......... .......... 21% 9.33M 31s\n",
            " 14400K .......... .......... .......... .......... .......... 21% 3.23M 31s\n",
            " 14450K .......... .......... .......... .......... .......... 21%  425K 32s\n",
            " 14500K .......... .......... .......... .......... .......... 21% 4.54M 32s\n",
            " 14550K .......... .......... .......... .......... .......... 21% 1.02M 32s\n",
            " 14600K .......... .......... .......... .......... .......... 21% 16.7M 31s\n",
            " 14650K .......... .......... .......... .......... .......... 21% 4.37M 31s\n",
            " 14700K .......... .......... .......... .......... .......... 21% 5.03M 31s\n",
            " 14750K .......... .......... .......... .......... .......... 21% 1.45M 31s\n",
            " 14800K .......... .......... .......... .......... .......... 21% 12.8M 31s\n",
            " 14850K .......... .......... .......... .......... .......... 21%  402K 31s\n",
            " 14900K .......... .......... .......... .......... .......... 21% 3.75M 31s\n",
            " 14950K .......... .......... .......... .......... .......... 21% 11.3M 31s\n",
            " 15000K .......... .......... .......... .......... .......... 22% 1.15M 31s\n",
            " 15050K .......... .......... .......... .......... .......... 22% 8.33M 31s\n",
            " 15100K .......... .......... .......... .......... .......... 22% 4.38M 31s\n",
            " 15150K .......... .......... .......... .......... .......... 22% 7.26M 31s\n",
            " 15200K .......... .......... .......... .......... .......... 22% 1.24M 31s\n",
            " 15250K .......... .......... .......... .......... .......... 22% 5.73M 31s\n",
            " 15300K .......... .......... .......... .......... .......... 22%  391K 31s\n",
            " 15350K .......... .......... .......... .......... .......... 22% 5.22M 31s\n",
            " 15400K .......... .......... .......... .......... .......... 22% 7.18M 31s\n",
            " 15450K .......... .......... .......... .......... .......... 22% 1.24M 31s\n",
            " 15500K .......... .......... .......... .......... .......... 22% 8.27M 31s\n",
            " 15550K .......... .......... .......... .......... .......... 22% 4.00M 31s\n",
            " 15600K .......... .......... .......... .......... .......... 22% 1.71M 31s\n",
            " 15650K .......... .......... .......... .......... .......... 23% 4.44M 31s\n",
            " 15700K .......... .......... .......... .......... .......... 23% 2.57M 31s\n",
            " 15750K .......... .......... .......... .......... .......... 23%  437K 31s\n",
            " 15800K .......... .......... .......... .......... .......... 23% 4.71M 31s\n",
            " 15850K .......... .......... .......... .......... .......... 23% 5.28M 31s\n",
            " 15900K .......... .......... .......... .......... .......... 23% 1.23M 31s\n",
            " 15950K .......... .......... .......... .......... .......... 23% 8.40M 31s\n",
            " 16000K .......... .......... .......... .......... .......... 23% 4.32M 30s\n",
            " 16050K .......... .......... .......... .......... .......... 23% 1.77M 30s\n",
            " 16100K .......... .......... .......... .......... .......... 23% 4.28M 30s\n",
            " 16150K .......... .......... .......... .......... .......... 23%  390K 31s\n",
            " 16200K .......... .......... .......... .......... .......... 23% 9.42M 30s\n",
            " 16250K .......... .......... .......... .......... .......... 23% 4.07M 30s\n",
            " 16300K .......... .......... .......... .......... .......... 23% 8.61M 30s\n",
            " 16350K .......... .......... .......... .......... .......... 24% 1.05M 30s\n",
            " 16400K .......... .......... .......... .......... .......... 24% 42.1M 30s\n",
            " 16450K .......... .......... .......... .......... .......... 24% 4.32M 30s\n",
            " 16500K .......... .......... .......... .......... .......... 24% 1.37M 30s\n",
            " 16550K .......... .......... .......... .......... .......... 24% 6.19M 30s\n",
            " 16600K .......... .......... .......... .......... .......... 24%  395K 30s\n",
            " 16650K .......... .......... .......... .......... .......... 24% 21.2M 30s\n",
            " 16700K .......... .......... .......... .......... .......... 24% 4.59M 30s\n",
            " 16750K .......... .......... .......... .......... .......... 24% 7.95M 30s\n",
            " 16800K .......... .......... .......... .......... .......... 24% 1.16M 30s\n",
            " 16850K .......... .......... .......... .......... .......... 24% 8.59M 30s\n",
            " 16900K .......... .......... .......... .......... .......... 24% 1.37M 30s\n",
            " 16950K .......... .......... .......... .......... .......... 24% 3.99M 30s\n",
            " 17000K .......... .......... .......... .......... .......... 25% 7.36M 30s\n",
            " 17050K .......... .......... .......... .......... .......... 25%  404K 30s\n",
            " 17100K .......... .......... .......... .......... .......... 25% 8.50M 30s\n",
            " 17150K .......... .......... .......... .......... .......... 25% 4.46M 30s\n",
            " 17200K .......... .......... .......... .......... .......... 25% 1.16M 30s\n",
            " 17250K .......... .......... .......... .......... .......... 25% 4.53M 30s\n",
            " 17300K .......... .......... .......... .......... .......... 25% 3.11M 30s\n",
            " 17350K .......... .......... .......... .......... .......... 25% 1.99M 30s\n",
            " 17400K .......... .......... .......... .......... .......... 25% 6.54M 30s\n",
            " 17450K .......... .......... .......... .......... .......... 25% 7.43M 29s\n",
            " 17500K .......... .......... .......... .......... .......... 25%  393K 30s\n",
            " 17550K .......... .......... .......... .......... .......... 25% 8.72M 30s\n",
            " 17600K .......... .......... .......... .......... .......... 25% 4.35M 29s\n",
            " 17650K .......... .......... .......... .......... .......... 25% 1.16M 29s\n",
            " 17700K .......... .......... .......... .......... .......... 26% 4.23M 29s\n",
            " 17750K .......... .......... .......... .......... .......... 26% 4.44M 29s\n",
            " 17800K .......... .......... .......... .......... .......... 26% 1.99M 29s\n",
            " 17850K .......... .......... .......... .......... .......... 26% 5.05M 29s\n",
            " 17900K .......... .......... .......... .......... .......... 26% 8.76M 29s\n",
            " 17950K .......... .......... .......... .......... .......... 26%  395K 29s\n",
            " 18000K .......... .......... .......... .......... .......... 26% 8.63M 29s\n",
            " 18050K .......... .......... .......... .......... .......... 26% 3.15M 29s\n",
            " 18100K .......... .......... .......... .......... .......... 26% 1.06M 29s\n",
            " 18150K .......... .......... .......... .......... .......... 26% 8.60M 29s\n",
            " 18200K .......... .......... .......... .......... .......... 26% 3.81M 29s\n",
            " 18250K .......... .......... .......... .......... .......... 26% 2.25M 29s\n",
            " 18300K .......... .......... .......... .......... .......... 26% 5.33M 29s\n",
            " 18350K .......... .......... .......... .......... .......... 26% 8.33M 29s\n",
            " 18400K .......... .......... .......... .......... .......... 27%  397K 29s\n",
            " 18450K .......... .......... .......... .......... .......... 27% 8.75M 29s\n",
            " 18500K .......... .......... .......... .......... .......... 27% 4.06M 29s\n",
            " 18550K .......... .......... .......... .......... .......... 27%  994K 29s\n",
            " 18600K .......... .......... .......... .......... .......... 27% 8.71M 29s\n",
            " 18650K .......... .......... .......... .......... .......... 27% 1.71M 29s\n",
            " 18700K .......... .......... .......... .......... .......... 27% 7.85M 29s\n",
            " 18750K .......... .......... .......... .......... .......... 27% 4.02M 29s\n",
            " 18800K .......... .......... .......... .......... .......... 27% 9.94M 29s\n",
            " 18850K .......... .......... .......... .......... .......... 27%  405K 29s\n",
            " 18900K .......... .......... .......... .......... .......... 27% 4.17M 29s\n",
            " 18950K .......... .......... .......... .......... .......... 27% 7.67M 29s\n",
            " 19000K .......... .......... .......... .......... .......... 27% 1000K 29s\n",
            " 19050K .......... .......... .......... .......... .......... 28% 8.87M 29s\n",
            " 19100K .......... .......... .......... .......... .......... 28% 1.23M 29s\n",
            " 19150K .......... .......... .......... .......... .......... 28% 8.83M 28s\n",
            " 19200K .......... .......... .......... .......... .......... 28% 4.35M 28s\n",
            " 19250K .......... .......... .......... .......... .......... 28% 5.63M 28s\n",
            " 19300K .......... .......... .......... .......... .......... 28% 5.83M 28s\n",
            " 19350K .......... .......... .......... .......... .......... 28% 2.32M 28s\n",
            " 19400K .......... .......... .......... .......... .......... 28% 11.7M 28s\n",
            " 19450K .......... .......... .......... .......... .......... 28% 3.69M 28s\n",
            " 19500K .......... .......... .......... .......... .......... 28% 13.7M 28s\n",
            " 19550K .......... .......... .......... .......... .......... 28% 3.98M 28s\n",
            " 19600K .......... .......... .......... .......... .......... 28% 8.89M 28s\n",
            " 19650K .......... .......... .......... .......... .......... 28% 4.01M 28s\n",
            " 19700K .......... .......... .......... .......... .......... 28% 4.11M 28s\n",
            " 19750K .......... .......... .......... .......... .......... 29% 7.56M 28s\n",
            " 19800K .......... .......... .......... .......... .......... 29% 4.52M 27s\n",
            " 19850K .......... .......... .......... .......... .......... 29% 6.09M 27s\n",
            " 19900K .......... .......... .......... .......... .......... 29% 5.02M 27s\n",
            " 19950K .......... .......... .......... .......... .......... 29% 8.56M 27s\n",
            " 20000K .......... .......... .......... .......... .......... 29% 4.41M 27s\n",
            " 20050K .......... .......... .......... .......... .......... 29% 8.36M 27s\n",
            " 20100K .......... .......... .......... .......... .......... 29% 4.32M 27s\n",
            " 20150K .......... .......... .......... .......... .......... 29% 4.10M 27s\n",
            " 20200K .......... .......... .......... .......... .......... 29% 8.57M 27s\n",
            " 20250K .......... .......... .......... .......... .......... 29% 4.38M 27s\n",
            " 20300K .......... .......... .......... .......... .......... 29% 8.32M 27s\n",
            " 20350K .......... .......... .......... .......... .......... 29% 4.05M 27s\n",
            " 20400K .......... .......... .......... .......... .......... 29% 8.78M 27s\n",
            " 20450K .......... .......... .......... .......... .......... 30% 4.38M 26s\n",
            " 20500K .......... .......... .......... .......... .......... 30% 4.04M 26s\n",
            " 20550K .......... .......... .......... .......... .......... 30% 8.48M 26s\n",
            " 20600K .......... .......... .......... .......... .......... 30% 3.53M 26s\n",
            " 20650K .......... .......... .......... .......... .......... 30% 17.3M 26s\n",
            " 20700K .......... .......... .......... .......... .......... 30% 4.12M 26s\n",
            " 20750K .......... .......... .......... .......... .......... 30% 8.70M 26s\n",
            " 20800K .......... .......... .......... .......... .......... 30% 4.89M 26s\n",
            " 20850K .......... .......... .......... .......... .......... 30% 9.52M 26s\n",
            " 20900K .......... .......... .......... .......... .......... 30% 2.59M 26s\n",
            " 20950K .......... .......... .......... .......... .......... 30% 57.7M 26s\n",
            " 21000K .......... .......... .......... .......... .......... 30% 10.7M 26s\n",
            " 21050K .......... .......... .......... .......... .......... 30% 3.26M 26s\n",
            " 21100K .......... .......... .......... .......... .......... 31%  181M 26s\n",
            " 21150K .......... .......... .......... .......... .......... 31% 5.89M 26s\n",
            " 21200K .......... .......... .......... .......... .......... 31% 12.5M 25s\n",
            " 21250K .......... .......... .......... .......... .......... 31% 10.3M 25s\n",
            " 21300K .......... .......... .......... .......... .......... 31% 5.54M 25s\n",
            " 21350K .......... .......... .......... .......... .......... 31%  191M 25s\n",
            " 21400K .......... .......... .......... .......... .......... 31% 9.92M 25s\n",
            " 21450K .......... .......... .......... .......... .......... 31% 9.94M 25s\n",
            " 21500K .......... .......... .......... .......... .......... 31% 8.24M 25s\n",
            " 21550K .......... .......... .......... .......... .......... 31% 44.8M 25s\n",
            " 21600K .......... .......... .......... .......... .......... 31% 7.98M 25s\n",
            " 21650K .......... .......... .......... .......... .......... 31% 19.6M 25s\n",
            " 21700K .......... .......... .......... .......... .......... 31% 8.80M 25s\n",
            " 21750K .......... .......... .......... .......... .......... 31% 9.40M 25s\n",
            " 21800K .......... .......... .......... .......... .......... 32% 15.7M 25s\n",
            " 21850K .......... .......... .......... .......... .......... 32% 10.3M 24s\n",
            " 21900K .......... .......... .......... .......... .......... 32% 16.6M 24s\n",
            " 21950K .......... .......... .......... .......... .......... 32% 7.53M 24s\n",
            " 22000K .......... .......... .......... .......... .......... 32% 35.4M 24s\n",
            " 22050K .......... .......... .......... .......... .......... 32% 10.5M 24s\n",
            " 22100K .......... .......... .......... .......... .......... 32% 10.7M 24s\n",
            " 22150K .......... .......... .......... .......... .......... 32% 16.9M 24s\n",
            " 22200K .......... .......... .......... .......... .......... 32% 10.8M 24s\n",
            " 22250K .......... .......... .......... .......... .......... 32% 28.3M 24s\n",
            " 22300K .......... .......... .......... .......... .......... 32% 10.1M 24s\n",
            " 22350K .......... .......... .......... .......... .......... 32% 8.42M 24s\n",
            " 22400K .......... .......... .......... .......... .......... 32% 33.5M 24s\n",
            " 22450K .......... .......... .......... .......... .......... 32% 9.86M 24s\n",
            " 22500K .......... .......... .......... .......... .......... 33% 18.9M 24s\n",
            " 22550K .......... .......... .......... .......... .......... 33% 10.9M 23s\n",
            " 22600K .......... .......... .......... .......... .......... 33% 7.67M 23s\n",
            " 22650K .......... .......... .......... .......... .......... 33% 65.4M 23s\n",
            " 22700K .......... .......... .......... .......... .......... 33% 13.1M 23s\n",
            " 22750K .......... .......... .......... .......... .......... 33% 26.1M 23s\n",
            " 22800K .......... .......... .......... .......... .......... 33% 20.9M 23s\n",
            " 22850K .......... .......... .......... .......... .......... 33% 13.0M 23s\n",
            " 22900K .......... .......... .......... .......... .......... 33% 8.45M 23s\n",
            " 22950K .......... .......... .......... .......... .......... 33% 12.5M 23s\n",
            " 23000K .......... .......... .......... .......... .......... 33% 19.9M 23s\n",
            " 23050K .......... .......... .......... .......... .......... 33% 60.3M 23s\n",
            " 23100K .......... .......... .......... .......... .......... 33% 5.95M 23s\n",
            " 23150K .......... .......... .......... .......... .......... 34%  205M 23s\n",
            " 23200K .......... .......... .......... .......... .......... 34% 25.0M 23s\n",
            " 23250K .......... .......... .......... .......... .......... 34% 12.3M 22s\n",
            " 23300K .......... .......... .......... .......... .......... 34% 10.9M 22s\n",
            " 23350K .......... .......... .......... .......... .......... 34% 34.5M 22s\n",
            " 23400K .......... .......... .......... .......... .......... 34% 15.8M 22s\n",
            " 23450K .......... .......... .......... .......... .......... 34% 12.6M 22s\n",
            " 23500K .......... .......... .......... .......... .......... 34% 10.5M 22s\n",
            " 23550K .......... .......... .......... .......... .......... 34% 18.8M 22s\n",
            " 23600K .......... .......... .......... .......... .......... 34% 9.02M 22s\n",
            " 23650K .......... .......... .......... .......... .......... 34% 20.8M 22s\n",
            " 23700K .......... .......... .......... .......... .......... 34% 9.09M 22s\n",
            " 23750K .......... .......... .......... .......... .......... 34% 22.4M 22s\n",
            " 23800K .......... .......... .......... .......... .......... 34% 10.3M 22s\n",
            " 23850K .......... .......... .......... .......... .......... 35% 6.54M 22s\n",
            " 23900K .......... .......... .......... .......... .......... 35% 38.9M 22s\n",
            " 23950K .......... .......... .......... .......... .......... 35% 25.1M 22s\n",
            " 24000K .......... .......... .......... .......... .......... 35% 10.5M 22s\n",
            " 24050K .......... .......... .......... .......... .......... 35% 11.9M 21s\n",
            " 24100K .......... .......... .......... .......... .......... 35% 9.34M 21s\n",
            " 24150K .......... .......... .......... .......... .......... 35% 25.8M 21s\n",
            " 24200K .......... .......... .......... .......... .......... 35% 29.8M 21s\n",
            " 24250K .......... .......... .......... .......... .......... 35% 11.3M 21s\n",
            " 24300K .......... .......... .......... .......... .......... 35% 6.41M 21s\n",
            " 24350K .......... .......... .......... .......... .......... 35%  243M 21s\n",
            " 24400K .......... .......... .......... .......... .......... 35% 56.0M 21s\n",
            " 24450K .......... .......... .......... .......... .......... 35% 12.5M 21s\n",
            " 24500K .......... .......... .......... .......... .......... 36% 12.2M 21s\n",
            " 24550K .......... .......... .......... .......... .......... 36% 5.45M 21s\n",
            " 24600K .......... .......... .......... .......... .......... 36%  133M 21s\n",
            " 24650K .......... .......... .......... .......... .......... 36% 45.5M 21s\n",
            " 24700K .......... .......... .......... .......... .......... 36% 37.6M 21s\n",
            " 24750K .......... .......... .......... .......... .......... 36% 15.2M 21s\n",
            " 24800K .......... .......... .......... .......... .......... 36% 43.3M 21s\n",
            " 24850K .......... .......... .......... .......... .......... 36% 12.3M 20s\n",
            " 24900K .......... .......... .......... .......... .......... 36% 41.0M 20s\n",
            " 24950K .......... .......... .......... .......... .......... 36% 11.9M 20s\n",
            " 25000K .......... .......... .......... .......... .......... 36% 38.3M 20s\n",
            " 25050K .......... .......... .......... .......... .......... 36% 17.2M 20s\n",
            " 25100K .......... .......... .......... .......... .......... 36% 20.0M 20s\n",
            " 25150K .......... .......... .......... .......... .......... 36% 17.8M 20s\n",
            " 25200K .......... .......... .......... .......... .......... 37% 19.5M 20s\n",
            " 25250K .......... .......... .......... .......... .......... 37% 18.0M 20s\n",
            " 25300K .......... .......... .......... .......... .......... 37% 12.7M 20s\n",
            " 25350K .......... .......... .......... .......... .......... 37% 35.8M 20s\n",
            " 25400K .......... .......... .......... .......... .......... 37% 20.5M 20s\n",
            " 25450K .......... .......... .......... .......... .......... 37% 20.7M 20s\n",
            " 25500K .......... .......... .......... .......... .......... 37% 17.2M 20s\n",
            " 25550K .......... .......... .......... .......... .......... 37% 22.1M 20s\n",
            " 25600K .......... .......... .......... .......... .......... 37% 18.7M 20s\n",
            " 25650K .......... .......... .......... .......... .......... 37% 28.1M 20s\n",
            " 25700K .......... .......... .......... .......... .......... 37% 9.46M 19s\n",
            " 25750K .......... .......... .......... .......... .......... 37% 52.7M 19s\n",
            " 25800K .......... .......... .......... .......... .......... 37% 56.2M 19s\n",
            " 25850K .......... .......... .......... .......... .......... 37% 19.1M 19s\n",
            " 25900K .......... .......... .......... .......... .......... 38% 18.2M 19s\n",
            " 25950K .......... .......... .......... .......... .......... 38% 20.6M 19s\n",
            " 26000K .......... .......... .......... .......... .......... 38% 19.5M 19s\n",
            " 26050K .......... .......... .......... .......... .......... 38% 21.1M 19s\n",
            " 26100K .......... .......... .......... .......... .......... 38% 18.9M 19s\n",
            " 26150K .......... .......... .......... .......... .......... 38% 61.8M 19s\n",
            " 26200K .......... .......... .......... .......... .......... 38% 13.3M 19s\n",
            " 26250K .......... .......... .......... .......... .......... 38% 27.7M 19s\n",
            " 26300K .......... .......... .......... .......... .......... 38% 21.8M 19s\n",
            " 26350K .......... .......... .......... .......... .......... 38% 13.4M 19s\n",
            " 26400K .......... .......... .......... .......... .......... 38%  135M 19s\n",
            " 26450K .......... .......... .......... .......... .......... 38% 36.7M 19s\n",
            " 26500K .......... .......... .......... .......... .......... 38% 11.7M 19s\n",
            " 26550K .......... .......... .......... .......... .......... 39% 78.8M 19s\n",
            " 26600K .......... .......... .......... .......... .......... 39% 35.7M 18s\n",
            " 26650K .......... .......... .......... .......... .......... 39% 8.41M 18s\n",
            " 26700K .......... .......... .......... .......... .......... 39% 70.2M 18s\n",
            " 26750K .......... .......... .......... .......... .......... 39%  296M 18s\n",
            " 26800K .......... .......... .......... .......... .......... 39% 34.8M 18s\n",
            " 26850K .......... .......... .......... .......... .......... 39% 19.2M 18s\n",
            " 26900K .......... .......... .......... .......... .......... 39% 28.0M 18s\n",
            " 26950K .......... .......... .......... .......... .......... 39% 36.5M 18s\n",
            " 27000K .......... .......... .......... .......... .......... 39% 24.2M 18s\n",
            " 27050K .......... .......... .......... .......... .......... 39% 22.3M 18s\n",
            " 27100K .......... .......... .......... .......... .......... 39% 34.7M 18s\n",
            " 27150K .......... .......... .......... .......... .......... 39% 18.5M 18s\n",
            " 27200K .......... .......... .......... .......... .......... 39% 41.3M 18s\n",
            " 27250K .......... .......... .......... .......... .......... 40% 5.99M 18s\n",
            " 27300K .......... .......... .......... .......... .......... 40%  241M 18s\n",
            " 27350K .......... .......... .......... .......... .......... 40%  286M 18s\n",
            " 27400K .......... .......... .......... .......... .......... 40%  270M 18s\n",
            " 27450K .......... .......... .......... .......... .......... 40%  297M 18s\n",
            " 27500K .......... .......... .......... .......... .......... 40% 20.6M 18s\n",
            " 27550K .......... .......... .......... .......... .......... 40% 23.7M 17s\n",
            " 27600K .......... .......... .......... .......... .......... 40% 50.7M 17s\n",
            " 27650K .......... .......... .......... .......... .......... 40% 13.9M 17s\n",
            " 27700K .......... .......... .......... .......... .......... 40% 21.7M 17s\n",
            " 27750K .......... .......... .......... .......... .......... 40% 36.1M 17s\n",
            " 27800K .......... .......... .......... .......... .......... 40% 10.5M 17s\n",
            " 27850K .......... .......... .......... .......... .......... 40%  114M 17s\n",
            " 27900K .......... .......... .......... .......... .......... 40% 64.9M 17s\n",
            " 27950K .......... .......... .......... .......... .......... 41% 15.4M 17s\n",
            " 28000K .......... .......... .......... .......... .......... 41% 95.7M 17s\n",
            " 28050K .......... .......... .......... .......... .......... 41% 37.1M 17s\n",
            " 28100K .......... .......... .......... .......... .......... 41% 30.2M 17s\n",
            " 28150K .......... .......... .......... .......... .......... 41% 43.6M 17s\n",
            " 28200K .......... .......... .......... .......... .......... 41% 43.1M 17s\n",
            " 28250K .......... .......... .......... .......... .......... 41% 27.0M 17s\n",
            " 28300K .......... .......... .......... .......... .......... 41% 26.9M 17s\n",
            " 28350K .......... .......... .......... .......... .......... 41% 16.8M 17s\n",
            " 28400K .......... .......... .......... .......... .......... 41% 65.6M 17s\n",
            " 28450K .......... .......... .......... .......... .......... 41% 10.1M 17s\n",
            " 28500K .......... .......... .......... .......... .......... 41%  212M 17s\n",
            " 28550K .......... .......... .......... .......... .......... 41%  299M 17s\n",
            " 28600K .......... .......... .......... .......... .......... 42%  121M 16s\n",
            " 28650K .......... .......... .......... .......... .......... 42% 39.2M 16s\n",
            " 28700K .......... .......... .......... .......... .......... 42% 26.1M 16s\n",
            " 28750K .......... .......... .......... .......... .......... 42% 38.4M 16s\n",
            " 28800K .......... .......... .......... .......... .......... 42% 33.2M 16s\n",
            " 28850K .......... .......... .......... .......... .......... 42% 24.9M 16s\n",
            " 28900K .......... .......... .......... .......... .......... 42% 51.6M 16s\n",
            " 28950K .......... .......... .......... .......... .......... 42% 29.7M 16s\n",
            " 29000K .......... .......... .......... .......... .......... 42% 35.8M 16s\n",
            " 29050K .......... .......... .......... .......... .......... 42% 35.1M 16s\n",
            " 29100K .......... .......... .......... .......... .......... 42% 35.0M 16s\n",
            " 29150K .......... .......... .......... .......... .......... 42% 30.2M 16s\n",
            " 29200K .......... .......... .......... .......... .......... 42% 45.1M 16s\n",
            " 29250K .......... .......... .......... .......... .......... 42% 29.9M 16s\n",
            " 29300K .......... .......... .......... .......... .......... 43% 21.0M 16s\n",
            " 29350K .......... .......... .......... .......... .......... 43% 55.0M 16s\n",
            " 29400K .......... .......... .......... .......... .......... 43% 9.22M 16s\n",
            " 29450K .......... .......... .......... .......... .......... 43% 89.3M 16s\n",
            " 29500K .......... .......... .......... .......... .......... 43%  265M 16s\n",
            " 29550K .......... .......... .......... .......... .......... 43%  232M 16s\n",
            " 29600K .......... .......... .......... .......... .......... 43% 39.3M 16s\n",
            " 29650K .......... .......... .......... .......... .......... 43% 46.3M 15s\n",
            " 29700K .......... .......... .......... .......... .......... 43% 30.3M 15s\n",
            " 29750K .......... .......... .......... .......... .......... 43% 25.1M 15s\n",
            " 29800K .......... .......... .......... .......... .......... 43% 43.4M 15s\n",
            " 29850K .......... .......... .......... .......... .......... 43% 37.9M 15s\n",
            " 29900K .......... .......... .......... .......... .......... 43% 19.3M 15s\n",
            " 29950K .......... .......... .......... .......... .......... 43%  132M 15s\n",
            " 30000K .......... .......... .......... .......... .......... 44% 30.8M 15s\n",
            " 30050K .......... .......... .......... .......... .......... 44% 11.2M 15s\n",
            " 30100K .......... .......... .......... .......... .......... 44% 66.8M 15s\n",
            " 30150K .......... .......... .......... .......... .......... 44%  286M 15s\n",
            " 30200K .......... .......... .......... .......... .......... 44%  262M 15s\n",
            " 30250K .......... .......... .......... .......... .......... 44% 41.9M 15s\n",
            " 30300K .......... .......... .......... .......... .......... 44% 32.0M 15s\n",
            " 30350K .......... .......... .......... .......... .......... 44% 34.8M 15s\n",
            " 30400K .......... .......... .......... .......... .......... 44% 36.1M 15s\n",
            " 30450K .......... .......... .......... .......... .......... 44% 56.0M 15s\n",
            " 30500K .......... .......... .......... .......... .......... 44% 26.1M 15s\n",
            " 30550K .......... .......... .......... .......... .......... 44% 3.25M 15s\n",
            " 30600K .......... .......... .......... .......... .......... 44% 56.7M 15s\n",
            " 30650K .......... .......... .......... .......... .......... 45%  241M 15s\n",
            " 30700K .......... .......... .......... .......... .......... 45% 58.9M 15s\n",
            " 30750K .......... .......... .......... .......... .......... 45%  145M 15s\n",
            " 30800K .......... .......... .......... .......... .......... 45%  238M 15s\n",
            " 30850K .......... .......... .......... .......... .......... 45%  240M 14s\n",
            " 30900K .......... .......... .......... .......... .......... 45%  189M 14s\n",
            " 30950K .......... .......... .......... .......... .......... 45%  248M 14s\n",
            " 31000K .......... .......... .......... .......... .......... 45%  255M 14s\n",
            " 31050K .......... .......... .......... .......... .......... 45%  253M 14s\n",
            " 31100K .......... .......... .......... .......... .......... 45%  259M 14s\n",
            " 31150K .......... .......... .......... .......... .......... 45%  275M 14s\n",
            " 31200K .......... .......... .......... .......... .......... 45% 62.1M 14s\n",
            " 31250K .......... .......... .......... .......... .......... 45% 52.5M 14s\n",
            " 31300K .......... .......... .......... .......... .......... 45% 29.2M 14s\n",
            " 31350K .......... .......... .......... .......... .......... 46% 35.1M 14s\n",
            " 31400K .......... .......... .......... .......... .......... 46% 31.1M 14s\n",
            " 31450K .......... .......... .......... .......... .......... 46% 19.3M 14s\n",
            " 31500K .......... .......... .......... .......... .......... 46% 46.1M 14s\n",
            " 31550K .......... .......... .......... .......... .......... 46% 39.8M 14s\n",
            " 31600K .......... .......... .......... .......... .......... 46% 58.5M 14s\n",
            " 31650K .......... .......... .......... .......... .......... 46% 39.9M 14s\n",
            " 31700K .......... .......... .......... .......... .......... 46% 10.3M 14s\n",
            " 31750K .......... .......... .......... .......... .......... 46%  182M 14s\n",
            " 31800K .......... .......... .......... .......... .......... 46% 84.0M 14s\n",
            " 31850K .......... .......... .......... .......... .......... 46% 23.9M 14s\n",
            " 31900K .......... .......... .......... .......... .......... 46% 19.8M 14s\n",
            " 31950K .......... .......... .......... .......... .......... 46%  207M 14s\n",
            " 32000K .......... .......... .......... .......... .......... 47%  205M 14s\n",
            " 32050K .......... .......... .......... .......... .......... 47%  214M 14s\n",
            " 32100K .......... .......... .......... .......... .......... 47% 15.7M 13s\n",
            " 32150K .......... .......... .......... .......... .......... 47% 39.9M 13s\n",
            " 32200K .......... .......... .......... .......... .......... 47% 42.3M 13s\n",
            " 32250K .......... .......... .......... .......... .......... 47% 35.1M 13s\n",
            " 32300K .......... .......... .......... .......... .......... 47% 25.5M 13s\n",
            " 32350K .......... .......... .......... .......... .......... 47% 89.4M 13s\n",
            " 32400K .......... .......... .......... .......... .......... 47% 66.1M 13s\n",
            " 32450K .......... .......... .......... .......... .......... 47% 36.0M 13s\n",
            " 32500K .......... .......... .......... .......... .......... 47% 34.0M 13s\n",
            " 32550K .......... .......... .......... .......... .......... 47% 43.8M 13s\n",
            " 32600K .......... .......... .......... .......... .......... 47% 27.7M 13s\n",
            " 32650K .......... .......... .......... .......... .......... 47%  104M 13s\n",
            " 32700K .......... .......... .......... .......... .......... 48% 39.4M 13s\n",
            " 32750K .......... .......... .......... .......... .......... 48% 48.0M 13s\n",
            " 32800K .......... .......... .......... .......... .......... 48% 11.7M 13s\n",
            " 32850K .......... .......... .......... .......... .......... 48% 57.1M 13s\n",
            " 32900K .......... .......... .......... .......... .......... 48% 33.6M 13s\n",
            " 32950K .......... .......... .......... .......... .......... 48% 58.0M 13s\n",
            " 33000K .......... .......... .......... .......... .......... 48% 48.3M 13s\n",
            " 33050K .......... .......... .......... .......... .......... 48% 29.6M 13s\n",
            " 33100K .......... .......... .......... .......... .......... 48% 45.8M 13s\n",
            " 33150K .......... .......... .......... .......... .......... 48% 34.8M 13s\n",
            " 33200K .......... .......... .......... .......... .......... 48% 46.3M 13s\n",
            " 33250K .......... .......... .......... .......... .......... 48% 58.0M 13s\n",
            " 33300K .......... .......... .......... .......... .......... 48% 31.6M 13s\n",
            " 33350K .......... .......... .......... .......... .......... 48%  135M 13s\n",
            " 33400K .......... .......... .......... .......... .......... 49% 14.0M 13s\n",
            " 33450K .......... .......... .......... .......... .......... 49% 56.0M 12s\n",
            " 33500K .......... .......... .......... .......... .......... 49% 38.7M 12s\n",
            " 33550K .......... .......... .......... .......... .......... 49% 54.6M 12s\n",
            " 33600K .......... .......... .......... .......... .......... 49% 36.1M 12s\n",
            " 33650K .......... .......... .......... .......... .......... 49% 58.2M 12s\n",
            " 33700K .......... .......... .......... .......... .......... 49% 25.7M 12s\n",
            " 33750K .......... .......... .......... .......... .......... 49% 48.3M 12s\n",
            " 33800K .......... .......... .......... .......... .......... 49% 56.7M 12s\n",
            " 33850K .......... .......... .......... .......... .......... 49% 50.8M 12s\n",
            " 33900K .......... .......... .......... .......... .......... 49% 43.9M 12s\n",
            " 33950K .......... .......... .......... .......... .......... 49% 16.1M 12s\n",
            " 34000K .......... .......... .......... .......... .......... 49%  258M 12s\n",
            " 34050K .......... .......... .......... .......... .......... 50%  293M 12s\n",
            " 34100K .......... .......... .......... .......... .......... 50% 23.8M 12s\n",
            " 34150K .......... .......... .......... .......... .......... 50% 48.8M 12s\n",
            " 34200K .......... .......... .......... .......... .......... 50% 61.1M 12s\n",
            " 34250K .......... .......... .......... .......... .......... 50%  270M 12s\n",
            " 34300K .......... .......... .......... .......... .......... 50% 42.2M 12s\n",
            " 34350K .......... .......... .......... .......... .......... 50% 62.3M 12s\n",
            " 34400K .......... .......... .......... .......... .......... 50% 27.5M 12s\n",
            " 34450K .......... .......... .......... .......... .......... 50% 72.1M 12s\n",
            " 34500K .......... .......... .......... .......... .......... 50% 49.2M 12s\n",
            " 34550K .......... .......... .......... .......... .......... 50% 43.8M 12s\n",
            " 34600K .......... .......... .......... .......... .......... 50% 42.2M 12s\n",
            " 34650K .......... .......... .......... .......... .......... 50% 70.1M 12s\n",
            " 34700K .......... .......... .......... .......... .......... 50% 39.7M 12s\n",
            " 34750K .......... .......... .......... .......... .......... 51% 45.9M 12s\n",
            " 34800K .......... .......... .......... .......... .......... 51% 61.7M 12s\n",
            " 34850K .......... .......... .......... .......... .......... 51% 30.5M 12s\n",
            " 34900K .......... .......... .......... .......... .......... 51% 33.1M 12s\n",
            " 34950K .......... .......... .......... .......... .......... 51%  127M 11s\n",
            " 35000K .......... .......... .......... .......... .......... 51% 27.9M 11s\n",
            " 35050K .......... .......... .......... .......... .......... 51% 76.5M 11s\n",
            " 35100K .......... .......... .......... .......... .......... 51% 5.16M 11s\n",
            " 35150K .......... .......... .......... .......... .......... 51% 42.1M 11s\n",
            " 35200K .......... .......... .......... .......... .......... 51%  296M 11s\n",
            " 35250K .......... .......... .......... .......... .......... 51%  298M 11s\n",
            " 35300K .......... .......... .......... .......... .......... 51%  224M 11s\n",
            " 35350K .......... .......... .......... .......... .......... 51%  210M 11s\n",
            " 35400K .......... .......... .......... .......... .......... 51%  226M 11s\n",
            " 35450K .......... .......... .......... .......... .......... 52%  189M 11s\n",
            " 35500K .......... .......... .......... .......... .......... 52% 41.5M 11s\n",
            " 35550K .......... .......... .......... .......... .......... 52% 45.7M 11s\n",
            " 35600K .......... .......... .......... .......... .......... 52% 51.4M 11s\n",
            " 35650K .......... .......... .......... .......... .......... 52% 51.0M 11s\n",
            " 35700K .......... .......... .......... .......... .......... 52% 54.6M 11s\n",
            " 35750K .......... .......... .......... .......... .......... 52% 5.54M 11s\n",
            " 35800K .......... .......... .......... .......... .......... 52% 83.6M 11s\n",
            " 35850K .......... .......... .......... .......... .......... 52%  320M 11s\n",
            " 35900K .......... .......... .......... .......... .......... 52%  230M 11s\n",
            " 35950K .......... .......... .......... .......... .......... 52%  284M 11s\n",
            " 36000K .......... .......... .......... .......... .......... 52%  272M 11s\n",
            " 36050K .......... .......... .......... .......... .......... 52%  192M 11s\n",
            " 36100K .......... .......... .......... .......... .......... 53%  148M 11s\n",
            " 36150K .......... .......... .......... .......... .......... 53% 35.4M 11s\n",
            " 36200K .......... .......... .......... .......... .......... 53% 52.8M 11s\n",
            " 36250K .......... .......... .......... .......... .......... 53% 50.2M 11s\n",
            " 36300K .......... .......... .......... .......... .......... 53% 48.5M 11s\n",
            " 36350K .......... .......... .......... .......... .......... 53% 56.4M 11s\n",
            " 36400K .......... .......... .......... .......... .......... 53% 48.2M 11s\n",
            " 36450K .......... .......... .......... .......... .......... 53% 48.9M 11s\n",
            " 36500K .......... .......... .......... .......... .......... 53% 62.5M 11s\n",
            " 36550K .......... .......... .......... .......... .......... 53%  227M 10s\n",
            " 36600K .......... .......... .......... .......... .......... 53%  277M 10s\n",
            " 36650K .......... .......... .......... .......... .......... 53% 13.9M 10s\n",
            " 36700K .......... .......... .......... .......... .......... 53%  203M 10s\n",
            " 36750K .......... .......... .......... .......... .......... 53%  204M 10s\n",
            " 36800K .......... .......... .......... .......... .......... 54%  213M 10s\n",
            " 36850K .......... .......... .......... .......... .......... 54% 42.2M 10s\n",
            " 36900K .......... .......... .......... .......... .......... 54% 42.5M 10s\n",
            " 36950K .......... .......... .......... .......... .......... 54% 7.44M 10s\n",
            " 37000K .......... .......... .......... .......... .......... 54% 42.4M 10s\n",
            " 37050K .......... .......... .......... .......... .......... 54% 47.9M 10s\n",
            " 37100K .......... .......... .......... .......... .......... 54% 38.8M 10s\n",
            " 37150K .......... .......... .......... .......... .......... 54% 57.2M 10s\n",
            " 37200K .......... .......... .......... .......... .......... 54% 51.9M 10s\n",
            " 37250K .......... .......... .......... .......... .......... 54% 46.4M 10s\n",
            " 37300K .......... .......... .......... .......... .......... 54% 39.7M 10s\n",
            " 37350K .......... .......... .......... .......... .......... 54% 52.2M 10s\n",
            " 37400K .......... .......... .......... .......... .......... 54% 55.1M 10s\n",
            " 37450K .......... .......... .......... .......... .......... 54% 51.3M 10s\n",
            " 37500K .......... .......... .......... .......... .......... 55% 54.2M 10s\n",
            " 37550K .......... .......... .......... .......... .......... 55%  196M 10s\n",
            " 37600K .......... .......... .......... .......... .......... 55%  243M 10s\n",
            " 37650K .......... .......... .......... .......... .......... 55%  299M 10s\n",
            " 37700K .......... .......... .......... .......... .......... 55%  239M 10s\n",
            " 37750K .......... .......... .......... .......... .......... 55%  266M 10s\n",
            " 37800K .......... .......... .......... .......... .......... 55%  227M 10s\n",
            " 37850K .......... .......... .......... .......... .......... 55%  279M 10s\n",
            " 37900K .......... .......... .......... .......... .......... 55%  236M 10s\n",
            " 37950K .......... .......... .......... .......... .......... 55%  216M 10s\n",
            " 38000K .......... .......... .......... .......... .......... 55%  252M 10s\n",
            " 38050K .......... .......... .......... .......... .......... 55% 11.1M 10s\n",
            " 38100K .......... .......... .......... .......... .......... 55% 44.1M 10s\n",
            " 38150K .......... .......... .......... .......... .......... 56% 52.9M 10s\n",
            " 38200K .......... .......... .......... .......... .......... 56% 51.7M 10s\n",
            " 38250K .......... .......... .......... .......... .......... 56% 37.7M 9s\n",
            " 38300K .......... .......... .......... .......... .......... 56% 22.3M 9s\n",
            " 38350K .......... .......... .......... .......... .......... 56% 59.1M 9s\n",
            " 38400K .......... .......... .......... .......... .......... 56% 51.6M 9s\n",
            " 38450K .......... .......... .......... .......... .......... 56%  215M 9s\n",
            " 38500K .......... .......... .......... .......... .......... 56%  179M 9s\n",
            " 38550K .......... .......... .......... .......... .......... 56%  240M 9s\n",
            " 38600K .......... .......... .......... .......... .......... 56%  296M 9s\n",
            " 38650K .......... .......... .......... .......... .......... 56%  281M 9s\n",
            " 38700K .......... .......... .......... .......... .......... 56%  206M 9s\n",
            " 38750K .......... .......... .......... .......... .......... 56%  291M 9s\n",
            " 38800K .......... .......... .......... .......... .......... 56%  277M 9s\n",
            " 38850K .......... .......... .......... .......... .......... 57%  262M 9s\n",
            " 38900K .......... .......... .......... .......... .......... 57%  207M 9s\n",
            " 38950K .......... .......... .......... .......... .......... 57%  195M 9s\n",
            " 39000K .......... .......... .......... .......... .......... 57% 31.8M 9s\n",
            " 39050K .......... .......... .......... .......... .......... 57% 33.6M 9s\n",
            " 39100K .......... .......... .......... .......... .......... 57% 40.0M 9s\n",
            " 39150K .......... .......... .......... .......... .......... 57% 63.8M 9s\n",
            " 39200K .......... .......... .......... .......... .......... 57%  220M 9s\n",
            " 39250K .......... .......... .......... .......... .......... 57%  290M 9s\n",
            " 39300K .......... .......... .......... .......... .......... 57%  198M 9s\n",
            " 39350K .......... .......... .......... .......... .......... 57% 24.9M 9s\n",
            " 39400K .......... .......... .......... .......... .......... 57% 35.4M 9s\n",
            " 39450K .......... .......... .......... .......... .......... 57% 57.8M 9s\n",
            " 39500K .......... .......... .......... .......... .......... 57% 48.8M 9s\n",
            " 39550K .......... .......... .......... .......... .......... 58%  228M 9s\n",
            " 39600K .......... .......... .......... .......... .......... 58% 63.1M 9s\n",
            " 39650K .......... .......... .......... .......... .......... 58% 71.3M 9s\n",
            " 39700K .......... .......... .......... .......... .......... 58% 39.2M 9s\n",
            " 39750K .......... .......... .......... .......... .......... 58% 54.3M 9s\n",
            " 39800K .......... .......... .......... .......... .......... 58% 14.2M 9s\n",
            " 39850K .......... .......... .......... .......... .......... 58%  295M 9s\n",
            " 39900K .......... .......... .......... .......... .......... 58%  262M 9s\n",
            " 39950K .......... .......... .......... .......... .......... 58%  294M 9s\n",
            " 40000K .......... .......... .......... .......... .......... 58%  309M 9s\n",
            " 40050K .......... .......... .......... .......... .......... 58% 91.4M 9s\n",
            " 40100K .......... .......... .......... .......... .......... 58% 17.5M 9s\n",
            " 40150K .......... .......... .......... .......... .......... 58% 58.1M 8s\n",
            " 40200K .......... .......... .......... .......... .......... 59% 51.7M 8s\n",
            " 40250K .......... .......... .......... .......... .......... 59%  143M 8s\n",
            " 40300K .......... .......... .......... .......... .......... 59%  246M 8s\n",
            " 40350K .......... .......... .......... .......... .......... 59% 43.2M 8s\n",
            " 40400K .......... .......... .......... .......... .......... 59% 55.6M 8s\n",
            " 40450K .......... .......... .......... .......... .......... 59%  299M 8s\n",
            " 40500K .......... .......... .......... .......... .......... 59%  185M 8s\n",
            " 40550K .......... .......... .......... .......... .......... 59% 52.0M 8s\n",
            " 40600K .......... .......... .......... .......... .......... 59% 42.1M 8s\n",
            " 40650K .......... .......... .......... .......... .......... 59%  119M 8s\n",
            " 40700K .......... .......... .......... .......... .......... 59%  251M 8s\n",
            " 40750K .......... .......... .......... .......... .......... 59%  294M 8s\n",
            " 40800K .......... .......... .......... .......... .......... 59%  262M 8s\n",
            " 40850K .......... .......... .......... .......... .......... 59%  103M 8s\n",
            " 40900K .......... .......... .......... .......... .......... 60% 67.1M 8s\n",
            " 40950K .......... .......... .......... .......... .......... 60%  125M 8s\n",
            " 41000K .......... .......... .......... .......... .......... 60% 5.06M 8s\n",
            " 41050K .......... .......... .......... .......... .......... 60%  198M 8s\n",
            " 41100K .......... .......... .......... .......... .......... 60%  183M 8s\n",
            " 41150K .......... .......... .......... .......... .......... 60%  220M 8s\n",
            " 41200K .......... .......... .......... .......... .......... 60%  255M 8s\n",
            " 41250K .......... .......... .......... .......... .......... 60%  186M 8s\n",
            " 41300K .......... .......... .......... .......... .......... 60%  211M 8s\n",
            " 41350K .......... .......... .......... .......... .......... 60%  265M 8s\n",
            " 41400K .......... .......... .......... .......... .......... 60%  178M 8s\n",
            " 41450K .......... .......... .......... .......... .......... 60%  218M 8s\n",
            " 41500K .......... .......... .......... .......... .......... 60%  168M 8s\n",
            " 41550K .......... .......... .......... .......... .......... 61%  258M 8s\n",
            " 41600K .......... .......... .......... .......... .......... 61%  215M 8s\n",
            " 41650K .......... .......... .......... .......... .......... 61%  174M 8s\n",
            " 41700K .......... .......... .......... .......... .......... 61%  195M 8s\n",
            " 41750K .......... .......... .......... .......... .......... 61% 6.17M 8s\n",
            " 41800K .......... .......... .......... .......... .......... 61% 54.4M 8s\n",
            " 41850K .......... .......... .......... .......... .......... 61% 58.0M 8s\n",
            " 41900K .......... .......... .......... .......... .......... 61% 50.8M 8s\n",
            " 41950K .......... .......... .......... .......... .......... 61% 58.3M 8s\n",
            " 42000K .......... .......... .......... .......... .......... 61% 76.6M 8s\n",
            " 42050K .......... .......... .......... .......... .......... 61% 65.5M 8s\n",
            " 42100K .......... .......... .......... .......... .......... 61% 47.6M 8s\n",
            " 42150K .......... .......... .......... .......... .......... 61% 56.5M 8s\n",
            " 42200K .......... .......... .......... .......... .......... 61% 12.4M 8s\n",
            " 42250K .......... .......... .......... .......... .......... 62%  180M 7s\n",
            " 42300K .......... .......... .......... .......... .......... 62%  220M 7s\n",
            " 42350K .......... .......... .......... .......... .......... 62%  229M 7s\n",
            " 42400K .......... .......... .......... .......... .......... 62%  220M 7s\n",
            " 42450K .......... .......... .......... .......... .......... 62%  245M 7s\n",
            " 42500K .......... .......... .......... .......... .......... 62%  134M 7s\n",
            " 42550K .......... .......... .......... .......... .......... 62%  253M 7s\n",
            " 42600K .......... .......... .......... .......... .......... 62%  149M 7s\n",
            " 42650K .......... .......... .......... .......... .......... 62%  248M 7s\n",
            " 42700K .......... .......... .......... .......... .......... 62%  216M 7s\n",
            " 42750K .......... .......... .......... .......... .......... 62%  244M 7s\n",
            " 42800K .......... .......... .......... .......... .......... 62%  238M 7s\n",
            " 42850K .......... .......... .......... .......... .......... 62%  234M 7s\n",
            " 42900K .......... .......... .......... .......... .......... 62%  201M 7s\n",
            " 42950K .......... .......... .......... .......... .......... 63%  244M 7s\n",
            " 43000K .......... .......... .......... .......... .......... 63% 10.6M 7s\n",
            " 43050K .......... .......... .......... .......... .......... 63%  222M 7s\n",
            " 43100K .......... .......... .......... .......... .......... 63%  210M 7s\n",
            " 43150K .......... .......... .......... .......... .......... 63%  241M 7s\n",
            " 43200K .......... .......... .......... .......... .......... 63%  247M 7s\n",
            " 43250K .......... .......... .......... .......... .......... 63%  233M 7s\n",
            " 43300K .......... .......... .......... .......... .......... 63%  192M 7s\n",
            " 43350K .......... .......... .......... .......... .......... 63%  247M 7s\n",
            " 43400K .......... .......... .......... .......... .......... 63%  239M 7s\n",
            " 43450K .......... .......... .......... .......... .......... 63%  239M 7s\n",
            " 43500K .......... .......... .......... .......... .......... 63%  222M 7s\n",
            " 43550K .......... .......... .......... .......... .......... 63%  237M 7s\n",
            " 43600K .......... .......... .......... .......... .......... 64%  238M 7s\n",
            " 43650K .......... .......... .......... .......... .......... 64% 18.1M 7s\n",
            " 43700K .......... .......... .......... .......... .......... 64% 4.93M 7s\n",
            " 43750K .......... .......... .......... .......... .......... 64% 58.0M 7s\n",
            " 43800K .......... .......... .......... .......... .......... 64% 53.5M 7s\n",
            " 43850K .......... .......... .......... .......... .......... 64% 48.4M 7s\n",
            " 43900K .......... .......... .......... .......... .......... 64% 44.1M 7s\n",
            " 43950K .......... .......... .......... .......... .......... 64% 55.6M 7s\n",
            " 44000K .......... .......... .......... .......... .......... 64% 59.1M 7s\n",
            " 44050K .......... .......... .......... .......... .......... 64% 63.2M 7s\n",
            " 44100K .......... .......... .......... .......... .......... 64% 38.9M 7s\n",
            " 44150K .......... .......... .......... .......... .......... 64%  127M 7s\n",
            " 44200K .......... .......... .......... .......... .......... 64% 11.3M 7s\n",
            " 44250K .......... .......... .......... .......... .......... 64%  281M 7s\n",
            " 44300K .......... .......... .......... .......... .......... 65% 57.5M 7s\n",
            " 44350K .......... .......... .......... .......... .......... 65%  220M 7s\n",
            " 44400K .......... .......... .......... .......... .......... 65% 56.3M 7s\n",
            " 44450K .......... .......... .......... .......... .......... 65%  178M 7s\n",
            " 44500K .......... .......... .......... .......... .......... 65%  244M 7s\n",
            " 44550K .......... .......... .......... .......... .......... 65%  294M 6s\n",
            " 44600K .......... .......... .......... .......... .......... 65%  253M 6s\n",
            " 44650K .......... .......... .......... .......... .......... 65%  289M 6s\n",
            " 44700K .......... .......... .......... .......... .......... 65%  230M 6s\n",
            " 44750K .......... .......... .......... .......... .......... 65%  293M 6s\n",
            " 44800K .......... .......... .......... .......... .......... 65%  270M 6s\n",
            " 44850K .......... .......... .......... .......... .......... 65%  296M 6s\n",
            " 44900K .......... .......... .......... .......... .......... 65% 27.4M 6s\n",
            " 44950K .......... .......... .......... .......... .......... 65% 56.4M 6s\n",
            " 45000K .......... .......... .......... .......... .......... 66% 53.4M 6s\n",
            " 45050K .......... .......... .......... .......... .......... 66% 50.7M 6s\n",
            " 45100K .......... .......... .......... .......... .......... 66% 48.7M 6s\n",
            " 45150K .......... .......... .......... .......... .......... 66% 61.2M 6s\n",
            " 45200K .......... .......... .......... .......... .......... 66% 53.2M 6s\n",
            " 45250K .......... .......... .......... .......... .......... 66% 56.3M 6s\n",
            " 45300K .......... .......... .......... .......... .......... 66% 89.4M 6s\n",
            " 45350K .......... .......... .......... .......... .......... 66%  267M 6s\n",
            " 45400K .......... .......... .......... .......... .......... 66%  303M 6s\n",
            " 45450K .......... .......... .......... .......... .......... 66%  301M 6s\n",
            " 45500K .......... .......... .......... .......... .......... 66% 44.1M 6s\n",
            " 45550K .......... .......... .......... .......... .......... 66% 58.9M 6s\n",
            " 45600K .......... .......... .......... .......... .......... 66% 18.2M 6s\n",
            " 45650K .......... .......... .......... .......... .......... 67% 52.6M 6s\n",
            " 45700K .......... .......... .......... .......... .......... 67% 55.6M 6s\n",
            " 45750K .......... .......... .......... .......... .......... 67%  289M 6s\n",
            " 45800K .......... .......... .......... .......... .......... 67%  285M 6s\n",
            " 45850K .......... .......... .......... .......... .......... 67%  290M 6s\n",
            " 45900K .......... .......... .......... .......... .......... 67%  260M 6s\n",
            " 45950K .......... .......... .......... .......... .......... 67% 15.7M 6s\n",
            " 46000K .......... .......... .......... .......... .......... 67% 54.9M 6s\n",
            " 46050K .......... .......... .......... .......... .......... 67% 56.5M 6s\n",
            " 46100K .......... .......... .......... .......... .......... 67% 47.5M 6s\n",
            " 46150K .......... .......... .......... .......... .......... 67%  108M 6s\n",
            " 46200K .......... .......... .......... .......... .......... 67%  300M 6s\n",
            " 46250K .......... .......... .......... .......... .......... 67%  295M 6s\n",
            " 46300K .......... .......... .......... .......... .......... 67%  241M 6s\n",
            " 46350K .......... .......... .......... .......... .......... 68%  295M 6s\n",
            " 46400K .......... .......... .......... .......... .......... 68%  241M 6s\n",
            " 46450K .......... .......... .......... .......... .......... 68%  304M 6s\n",
            " 46500K .......... .......... .......... .......... .......... 68%  212M 6s\n",
            " 46550K .......... .......... .......... .......... .......... 68%  246M 6s\n",
            " 46600K .......... .......... .......... .......... .......... 68%  285M 6s\n",
            " 46650K .......... .......... .......... .......... .......... 68%  252M 6s\n",
            " 46700K .......... .......... .......... .......... .......... 68%  262M 6s\n",
            " 46750K .......... .......... .......... .......... .......... 68%  311M 6s\n",
            " 46800K .......... .......... .......... .......... .......... 68%  284M 6s\n",
            " 46850K .......... .......... .......... .......... .......... 68%  272M 6s\n",
            " 46900K .......... .......... .......... .......... .......... 68% 62.3M 6s\n",
            " 46950K .......... .......... .......... .......... .......... 68% 29.4M 6s\n",
            " 47000K .......... .......... .......... .......... .......... 68% 73.6M 6s\n",
            " 47050K .......... .......... .......... .......... .......... 69%  165M 6s\n",
            " 47100K .......... .......... .......... .......... .......... 69%  209M 5s\n",
            " 47150K .......... .......... .......... .......... .......... 69%  268M 5s\n",
            " 47200K .......... .......... .......... .......... .......... 69% 85.5M 5s\n",
            " 47250K .......... .......... .......... .......... .......... 69% 52.7M 5s\n",
            " 47300K .......... .......... .......... .......... .......... 69%  157M 5s\n",
            " 47350K .......... .......... .......... .......... .......... 69%  290M 5s\n",
            " 47400K .......... .......... .......... .......... .......... 69% 71.0M 5s\n",
            " 47450K .......... .......... .......... .......... .......... 69% 52.6M 5s\n",
            " 47500K .......... .......... .......... .......... .......... 69% 47.0M 5s\n",
            " 47550K .......... .......... .......... .......... .......... 69%  182M 5s\n",
            " 47600K .......... .......... .......... .......... .......... 69%  263M 5s\n",
            " 47650K .......... .......... .......... .......... .......... 69%  277M 5s\n",
            " 47700K .......... .......... .......... .......... .......... 70%  191M 5s\n",
            " 47750K .......... .......... .......... .......... .......... 70% 59.8M 5s\n",
            " 47800K .......... .......... .......... .......... .......... 70% 51.1M 5s\n",
            " 47850K .......... .......... .......... .......... .......... 70% 52.2M 5s\n",
            " 47900K .......... .......... .......... .......... .......... 70% 44.1M 5s\n",
            " 47950K .......... .......... .......... .......... .......... 70% 53.5M 5s\n",
            " 48000K .......... .......... .......... .......... .......... 70%  134M 5s\n",
            " 48050K .......... .......... .......... .......... .......... 70%  265M 5s\n",
            " 48100K .......... .......... .......... .......... .......... 70%  238M 5s\n",
            " 48150K .......... .......... .......... .......... .......... 70%  289M 5s\n",
            " 48200K .......... .......... .......... .......... .......... 70%  290M 5s\n",
            " 48250K .......... .......... .......... .......... .......... 70%  227M 5s\n",
            " 48300K .......... .......... .......... .......... .......... 70% 48.6M 5s\n",
            " 48350K .......... .......... .......... .......... .......... 70% 49.2M 5s\n",
            " 48400K .......... .......... .......... .......... .......... 71% 53.5M 5s\n",
            " 48450K .......... .......... .......... .......... .......... 71% 44.5M 5s\n",
            " 48500K .......... .......... .......... .......... .......... 71% 41.3M 5s\n",
            " 48550K .......... .......... .......... .......... .......... 71% 52.9M 5s\n",
            " 48600K .......... .......... .......... .......... .......... 71% 79.4M 5s\n",
            " 48650K .......... .......... .......... .......... .......... 71%  243M 5s\n",
            " 48700K .......... .......... .......... .......... .......... 71%  245M 5s\n",
            " 48750K .......... .......... .......... .......... .......... 71%  271M 5s\n",
            " 48800K .......... .......... .......... .......... .......... 71%  285M 5s\n",
            " 48850K .......... .......... .......... .......... .......... 71%  233M 5s\n",
            " 48900K .......... .......... .......... .......... .......... 71%  181M 5s\n",
            " 48950K .......... .......... .......... .......... .......... 71%  276M 5s\n",
            " 49000K .......... .......... .......... .......... .......... 71%  292M 5s\n",
            " 49050K .......... .......... .......... .......... .......... 72%  277M 5s\n",
            " 49100K .......... .......... .......... .......... .......... 72% 62.3M 5s\n",
            " 49150K .......... .......... .......... .......... .......... 72% 52.3M 5s\n",
            " 49200K .......... .......... .......... .......... .......... 72% 52.0M 5s\n",
            " 49250K .......... .......... .......... .......... .......... 72% 56.5M 5s\n",
            " 49300K .......... .......... .......... .......... .......... 72% 4.77M 5s\n",
            " 49350K .......... .......... .......... .......... .......... 72% 54.9M 5s\n",
            " 49400K .......... .......... .......... .......... .......... 72% 55.2M 5s\n",
            " 49450K .......... .......... .......... .......... .......... 72% 55.2M 5s\n",
            " 49500K .......... .......... .......... .......... .......... 72% 49.6M 5s\n",
            " 49550K .......... .......... .......... .......... .......... 72% 58.5M 5s\n",
            " 49600K .......... .......... .......... .......... .......... 72%  235M 5s\n",
            " 49650K .......... .......... .......... .......... .......... 72%  259M 5s\n",
            " 49700K .......... .......... .......... .......... .......... 72%  246M 5s\n",
            " 49750K .......... .......... .......... .......... .......... 73%  262M 5s\n",
            " 49800K .......... .......... .......... .......... .......... 73%  275M 5s\n",
            " 49850K .......... .......... .......... .......... .......... 73%  227M 5s\n",
            " 49900K .......... .......... .......... .......... .......... 73%  241M 5s\n",
            " 49950K .......... .......... .......... .......... .......... 73%  266M 4s\n",
            " 50000K .......... .......... .......... .......... .......... 73%  288M 4s\n",
            " 50050K .......... .......... .......... .......... .......... 73% 6.41M 4s\n",
            " 50100K .......... .......... .......... .......... .......... 73% 60.0M 4s\n",
            " 50150K .......... .......... .......... .......... .......... 73% 31.0M 4s\n",
            " 50200K .......... .......... .......... .......... .......... 73% 7.29M 4s\n",
            " 50250K .......... .......... .......... .......... .......... 73% 51.1M 4s\n",
            " 50300K .......... .......... .......... .......... .......... 73% 5.62M 4s\n",
            " 50350K .......... .......... .......... .......... .......... 73% 80.2M 4s\n",
            " 50400K .......... .......... .......... .......... .......... 73%  274M 4s\n",
            " 50450K .......... .......... .......... .......... .......... 74%  282M 4s\n",
            " 50500K .......... .......... .......... .......... .......... 74%  187M 4s\n",
            " 50550K .......... .......... .......... .......... .......... 74%  298M 4s\n",
            " 50600K .......... .......... .......... .......... .......... 74%  309M 4s\n",
            " 50650K .......... .......... .......... .......... .......... 74%  300M 4s\n",
            " 50700K .......... .......... .......... .......... .......... 74%  265M 4s\n",
            " 50750K .......... .......... .......... .......... .......... 74% 91.1M 4s\n",
            " 50800K .......... .......... .......... .......... .......... 74% 59.0M 4s\n",
            " 50850K .......... .......... .......... .......... .......... 74% 55.4M 4s\n",
            " 50900K .......... .......... .......... .......... .......... 74% 50.1M 4s\n",
            " 50950K .......... .......... .......... .......... .......... 74% 58.1M 4s\n",
            " 51000K .......... .......... .......... .......... .......... 74% 56.6M 4s\n",
            " 51050K .......... .......... .......... .......... .......... 74% 61.5M 4s\n",
            " 51100K .......... .......... .......... .......... .......... 75%  212M 4s\n",
            " 51150K .......... .......... .......... .......... .......... 75%  240M 4s\n",
            " 51200K .......... .......... .......... .......... .......... 75%  286M 4s\n",
            " 51250K .......... .......... .......... .......... .......... 75%  265M 4s\n",
            " 51300K .......... .......... .......... .......... .......... 75%  255M 4s\n",
            " 51350K .......... .......... .......... .......... .......... 75%  293M 4s\n",
            " 51400K .......... .......... .......... .......... .......... 75%  289M 4s\n",
            " 51450K .......... .......... .......... .......... .......... 75%  280M 4s\n",
            " 51500K .......... .......... .......... .......... .......... 75%  283M 4s\n",
            " 51550K .......... .......... .......... .......... .......... 75%  309M 4s\n",
            " 51600K .......... .......... .......... .......... .......... 75%  327M 4s\n",
            " 51650K .......... .......... .......... .......... .......... 75%  292M 4s\n",
            " 51700K .......... .......... .......... .......... .......... 75%  242M 4s\n",
            " 51750K .......... .......... .......... .......... .......... 75% 4.60M 4s\n",
            " 51800K .......... .......... .......... .......... .......... 76% 65.8M 4s\n",
            " 51850K .......... .......... .......... .......... .......... 76% 68.7M 4s\n",
            " 51900K .......... .......... .......... .......... .......... 76% 56.1M 4s\n",
            " 51950K .......... .......... .......... .......... .......... 76% 8.65M 4s\n",
            " 52000K .......... .......... .......... .......... .......... 76% 54.2M 4s\n",
            " 52050K .......... .......... .......... .......... .......... 76% 53.3M 4s\n",
            " 52100K .......... .......... .......... .......... .......... 76% 47.0M 4s\n",
            " 52150K .......... .......... .......... .......... .......... 76% 56.7M 4s\n",
            " 52200K .......... .......... .......... .......... .......... 76% 56.0M 4s\n",
            " 52250K .......... .......... .......... .......... .......... 76% 57.8M 4s\n",
            " 52300K .......... .......... .......... .......... .......... 76%  245M 4s\n",
            " 52350K .......... .......... .......... .......... .......... 76%  299M 4s\n",
            " 52400K .......... .......... .......... .......... .......... 76%  294M 4s\n",
            " 52450K .......... .......... .......... .......... .......... 76%  289M 4s\n",
            " 52500K .......... .......... .......... .......... .......... 77%  262M 4s\n",
            " 52550K .......... .......... .......... .......... .......... 77%  280M 4s\n",
            " 52600K .......... .......... .......... .......... .......... 77%  269M 4s\n",
            " 52650K .......... .......... .......... .......... .......... 77%  298M 4s\n",
            " 52700K .......... .......... .......... .......... .......... 77%  268M 4s\n",
            " 52750K .......... .......... .......... .......... .......... 77%  313M 4s\n",
            " 52800K .......... .......... .......... .......... .......... 77%  313M 4s\n",
            " 52850K .......... .......... .......... .......... .......... 77% 13.9M 4s\n",
            " 52900K .......... .......... .......... .......... .......... 77% 9.59M 4s\n",
            " 52950K .......... .......... .......... .......... .......... 77% 66.3M 4s\n",
            " 53000K .......... .......... .......... .......... .......... 77% 54.7M 4s\n",
            " 53050K .......... .......... .......... .......... .......... 77% 9.60M 4s\n",
            " 53100K .......... .......... .......... .......... .......... 77% 43.9M 4s\n",
            " 53150K .......... .......... .......... .......... .......... 78% 50.8M 4s\n",
            " 53200K .......... .......... .......... .......... .......... 78% 51.9M 3s\n",
            " 53250K .......... .......... .......... .......... .......... 78% 54.5M 3s\n",
            " 53300K .......... .......... .......... .......... .......... 78% 70.0M 3s\n",
            " 53350K .......... .......... .......... .......... .......... 78%  308M 3s\n",
            " 53400K .......... .......... .......... .......... .......... 78%  238M 3s\n",
            " 53450K .......... .......... .......... .......... .......... 78%  279M 3s\n",
            " 53500K .......... .......... .......... .......... .......... 78%  209M 3s\n",
            " 53550K .......... .......... .......... .......... .......... 78%  250M 3s\n",
            " 53600K .......... .......... .......... .......... .......... 78%  294M 3s\n",
            " 53650K .......... .......... .......... .......... .......... 78%  279M 3s\n",
            " 53700K .......... .......... .......... .......... .......... 78%  232M 3s\n",
            " 53750K .......... .......... .......... .......... .......... 78%  315M 3s\n",
            " 53800K .......... .......... .......... .......... .......... 78%  308M 3s\n",
            " 53850K .......... .......... .......... .......... .......... 79%  312M 3s\n",
            " 53900K .......... .......... .......... .......... .......... 79%  277M 3s\n",
            " 53950K .......... .......... .......... .......... .......... 79% 6.35M 3s\n",
            " 54000K .......... .......... .......... .......... .......... 79% 53.2M 3s\n",
            " 54050K .......... .......... .......... .......... .......... 79% 8.37M 3s\n",
            " 54100K .......... .......... .......... .......... .......... 79% 46.0M 3s\n",
            " 54150K .......... .......... .......... .......... .......... 79% 55.8M 3s\n",
            " 54200K .......... .......... .......... .......... .......... 79% 60.1M 3s\n",
            " 54250K .......... .......... .......... .......... .......... 79% 60.6M 3s\n",
            " 54300K .......... .......... .......... .......... .......... 79% 52.9M 3s\n",
            " 54350K .......... .......... .......... .......... .......... 79% 57.6M 3s\n",
            " 54400K .......... .......... .......... .......... .......... 79% 57.5M 3s\n",
            " 54450K .......... .......... .......... .......... .......... 79% 61.8M 3s\n",
            " 54500K .......... .......... .......... .......... .......... 79%  178M 3s\n",
            " 54550K .......... .......... .......... .......... .......... 80%  317M 3s\n",
            " 54600K .......... .......... .......... .......... .......... 80%  309M 3s\n",
            " 54650K .......... .......... .......... .......... .......... 80%  270M 3s\n",
            " 54700K .......... .......... .......... .......... .......... 80%  262M 3s\n",
            " 54750K .......... .......... .......... .......... .......... 80%  303M 3s\n",
            " 54800K .......... .......... .......... .......... .......... 80%  306M 3s\n",
            " 54850K .......... .......... .......... .......... .......... 80%  269M 3s\n",
            " 54900K .......... .......... .......... .......... .......... 80%  223M 3s\n",
            " 54950K .......... .......... .......... .......... .......... 80%  270M 3s\n",
            " 55000K .......... .......... .......... .......... .......... 80%  261M 3s\n",
            " 55050K .......... .......... .......... .......... .......... 80%  294M 3s\n",
            " 55100K .......... .......... .......... .......... .......... 80%  254M 3s\n",
            " 55150K .......... .......... .......... .......... .......... 80%  311M 3s\n",
            " 55200K .......... .......... .......... .......... .......... 81% 6.53M 3s\n",
            " 55250K .......... .......... .......... .......... .......... 81% 58.5M 3s\n",
            " 55300K .......... .......... .......... .......... .......... 81% 50.8M 3s\n",
            " 55350K .......... .......... .......... .......... .......... 81% 59.7M 3s\n",
            " 55400K .......... .......... .......... .......... .......... 81% 54.6M 3s\n",
            " 55450K .......... .......... .......... .......... .......... 81% 39.0M 3s\n",
            " 55500K .......... .......... .......... .......... .......... 81% 45.4M 3s\n",
            " 55550K .......... .......... .......... .......... .......... 81% 57.1M 3s\n",
            " 55600K .......... .......... .......... .......... .......... 81% 60.8M 3s\n",
            " 55650K .......... .......... .......... .......... .......... 81% 58.0M 3s\n",
            " 55700K .......... .......... .......... .......... .......... 81% 48.8M 3s\n",
            " 55750K .......... .......... .......... .......... .......... 81% 56.2M 3s\n",
            " 55800K .......... .......... .......... .......... .......... 81% 86.0M 3s\n",
            " 55850K .......... .......... .......... .......... .......... 81%  309M 3s\n",
            " 55900K .......... .......... .......... .......... .......... 82%  279M 3s\n",
            " 55950K .......... .......... .......... .......... .......... 82%  292M 3s\n",
            " 56000K .......... .......... .......... .......... .......... 82%  307M 3s\n",
            " 56050K .......... .......... .......... .......... .......... 82%  197M 3s\n",
            " 56100K .......... .......... .......... .......... .......... 82%  205M 3s\n",
            " 56150K .......... .......... .......... .......... .......... 82%  257M 3s\n",
            " 56200K .......... .......... .......... .......... .......... 82%  256M 3s\n",
            " 56250K .......... .......... .......... .......... .......... 82%  231M 3s\n",
            " 56300K .......... .......... .......... .......... .......... 82%  219M 3s\n",
            " 56350K .......... .......... .......... .......... .......... 82%  254M 3s\n",
            " 56400K .......... .......... .......... .......... .......... 82%  244M 3s\n",
            " 56450K .......... .......... .......... .......... .......... 82%  262M 3s\n",
            " 56500K .......... .......... .......... .......... .......... 82%  221M 3s\n",
            " 56550K .......... .......... .......... .......... .......... 83% 6.38M 3s\n",
            " 56600K .......... .......... .......... .......... .......... 83% 60.7M 3s\n",
            " 56650K .......... .......... .......... .......... .......... 83% 62.8M 3s\n",
            " 56700K .......... .......... .......... .......... .......... 83% 58.7M 3s\n",
            " 56750K .......... .......... .......... .......... .......... 83% 67.2M 3s\n",
            " 56800K .......... .......... .......... .......... .......... 83% 60.8M 2s\n",
            " 56850K .......... .......... .......... .......... .......... 83% 54.0M 2s\n",
            " 56900K .......... .......... .......... .......... .......... 83% 50.5M 2s\n",
            " 56950K .......... .......... .......... .......... .......... 83% 60.0M 2s\n",
            " 57000K .......... .......... .......... .......... .......... 83% 62.2M 2s\n",
            " 57050K .......... .......... .......... .......... .......... 83% 57.0M 2s\n",
            " 57100K .......... .......... .......... .......... .......... 83% 52.2M 2s\n",
            " 57150K .......... .......... .......... .......... .......... 83% 57.5M 2s\n",
            " 57200K .......... .......... .......... .......... .......... 83% 57.6M 2s\n",
            " 57250K .......... .......... .......... .......... .......... 84% 58.4M 2s\n",
            " 57300K .......... .......... .......... .......... .......... 84% 77.5M 2s\n",
            " 57350K .......... .......... .......... .......... .......... 84%  299M 2s\n",
            " 57400K .......... .......... .......... .......... .......... 84%  305M 2s\n",
            " 57450K .......... .......... .......... .......... .......... 84%  263M 2s\n",
            " 57500K .......... .......... .......... .......... .......... 84%  267M 2s\n",
            " 57550K .......... .......... .......... .......... .......... 84%  301M 2s\n",
            " 57600K .......... .......... .......... .......... .......... 84%  282M 2s\n",
            " 57650K .......... .......... .......... .......... .......... 84%  228M 2s\n",
            " 57700K .......... .......... .......... .......... .......... 84%  239M 2s\n",
            " 57750K .......... .......... .......... .......... .......... 84%  291M 2s\n",
            " 57800K .......... .......... .......... .......... .......... 84%  278M 2s\n",
            " 57850K .......... .......... .......... .......... .......... 84%  277M 2s\n",
            " 57900K .......... .......... .......... .......... .......... 84% 8.63M 2s\n",
            " 57950K .......... .......... .......... .......... .......... 85% 8.72M 2s\n",
            " 58000K .......... .......... .......... .......... .......... 85% 53.3M 2s\n",
            " 58050K .......... .......... .......... .......... .......... 85% 53.8M 2s\n",
            " 58100K .......... .......... .......... .......... .......... 85% 45.8M 2s\n",
            " 58150K .......... .......... .......... .......... .......... 85% 61.4M 2s\n",
            " 58200K .......... .......... .......... .......... .......... 85% 56.3M 2s\n",
            " 58250K .......... .......... .......... .......... .......... 85% 57.8M 2s\n",
            " 58300K .......... .......... .......... .......... .......... 85% 54.9M 2s\n",
            " 58350K .......... .......... .......... .......... .......... 85% 60.7M 2s\n",
            " 58400K .......... .......... .......... .......... .......... 85% 77.5M 2s\n",
            " 58450K .......... .......... .......... .......... .......... 85% 83.5M 2s\n",
            " 58500K .......... .......... .......... .......... .......... 85% 83.3M 2s\n",
            " 58550K .......... .......... .......... .......... .......... 85%  263M 2s\n",
            " 58600K .......... .......... .......... .......... .......... 86%  305M 2s\n",
            " 58650K .......... .......... .......... .......... .......... 86%  288M 2s\n",
            " 58700K .......... .......... .......... .......... .......... 86%  225M 2s\n",
            " 58750K .......... .......... .......... .......... .......... 86%  305M 2s\n",
            " 58800K .......... .......... .......... .......... .......... 86% 4.61M 2s\n",
            " 58850K .......... .......... .......... .......... .......... 86% 54.1M 2s\n",
            " 58900K .......... .......... .......... .......... .......... 86% 46.0M 2s\n",
            " 58950K .......... .......... .......... .......... .......... 86% 78.0M 2s\n",
            " 59000K .......... .......... .......... .......... .......... 86% 57.3M 2s\n",
            " 59050K .......... .......... .......... .......... .......... 86% 70.9M 2s\n",
            " 59100K .......... .......... .......... .......... .......... 86%  201M 2s\n",
            " 59150K .......... .......... .......... .......... .......... 86%  237M 2s\n",
            " 59200K .......... .......... .......... .......... .......... 86%  232M 2s\n",
            " 59250K .......... .......... .......... .......... .......... 86%  198M 2s\n",
            " 59300K .......... .......... .......... .......... .......... 87%  215M 2s\n",
            " 59350K .......... .......... .......... .......... .......... 87%  269M 2s\n",
            " 59400K .......... .......... .......... .......... .......... 87%  229M 2s\n",
            " 59450K .......... .......... .......... .......... .......... 87%  239M 2s\n",
            " 59500K .......... .......... .......... .......... .......... 87%  198M 2s\n",
            " 59550K .......... .......... .......... .......... .......... 87%  229M 2s\n",
            " 59600K .......... .......... .......... .......... .......... 87% 32.4M 2s\n",
            " 59650K .......... .......... .......... .......... .......... 87% 59.4M 2s\n",
            " 59700K .......... .......... .......... .......... .......... 87% 14.5M 2s\n",
            " 59750K .......... .......... .......... .......... .......... 87% 13.0M 2s\n",
            " 59800K .......... .......... .......... .......... .......... 87% 55.6M 2s\n",
            " 59850K .......... .......... .......... .......... .......... 87% 51.7M 2s\n",
            " 59900K .......... .......... .......... .......... .......... 87% 9.57M 2s\n",
            " 59950K .......... .......... .......... .......... .......... 87% 15.4M 2s\n",
            " 60000K .......... .......... .......... .......... .......... 88% 16.9M 2s\n",
            " 60050K .......... .......... .......... .......... .......... 88% 58.1M 2s\n",
            " 60100K .......... .......... .......... .......... .......... 88% 5.44M 2s\n",
            " 60150K .......... .......... .......... .......... .......... 88% 82.0M 2s\n",
            " 60200K .......... .......... .......... .......... .......... 88% 10.2M 2s\n",
            " 60250K .......... .......... .......... .......... .......... 88%  173M 2s\n",
            " 60300K .......... .......... .......... .......... .......... 88%  274M 2s\n",
            " 60350K .......... .......... .......... .......... .......... 88% 56.4M 2s\n",
            " 60400K .......... .......... .......... .......... .......... 88% 52.8M 2s\n",
            " 60450K .......... .......... .......... .......... .......... 88%  271M 2s\n",
            " 60500K .......... .......... .......... .......... .......... 88%  185M 2s\n",
            " 60550K .......... .......... .......... .......... .......... 88%  264M 2s\n",
            " 60600K .......... .......... .......... .......... .......... 88%  275M 2s\n",
            " 60650K .......... .......... .......... .......... .......... 89%  272M 2s\n",
            " 60700K .......... .......... .......... .......... .......... 89%  239M 2s\n",
            " 60750K .......... .......... .......... .......... .......... 89% 13.6M 2s\n",
            " 60800K .......... .......... .......... .......... .......... 89%  233M 2s\n",
            " 60850K .......... .......... .......... .......... .......... 89%  221M 2s\n",
            " 60900K .......... .......... .......... .......... .......... 89%  192M 1s\n",
            " 60950K .......... .......... .......... .......... .......... 89%  246M 1s\n",
            " 61000K .......... .......... .......... .......... .......... 89%  174M 1s\n",
            " 61050K .......... .......... .......... .......... .......... 89%  230M 1s\n",
            " 61100K .......... .......... .......... .......... .......... 89%  136M 1s\n",
            " 61150K .......... .......... .......... .......... .......... 89%  179M 1s\n",
            " 61200K .......... .......... .......... .......... .......... 89%  248M 1s\n",
            " 61250K .......... .......... .......... .......... .......... 89%  177M 1s\n",
            " 61300K .......... .......... .......... .......... .......... 89%  172M 1s\n",
            " 61350K .......... .......... .......... .......... .......... 90%  232M 1s\n",
            " 61400K .......... .......... .......... .......... .......... 90%  190M 1s\n",
            " 61450K .......... .......... .......... .......... .......... 90%  239M 1s\n",
            " 61500K .......... .......... .......... .......... .......... 90%  140M 1s\n",
            " 61550K .......... .......... .......... .......... .......... 90%  181M 1s\n",
            " 61600K .......... .......... .......... .......... .......... 90%  173M 1s\n",
            " 61650K .......... .......... .......... .......... .......... 90%  198M 1s\n",
            " 61700K .......... .......... .......... .......... .......... 90%  173M 1s\n",
            " 61750K .......... .......... .......... .......... .......... 90%  169M 1s\n",
            " 61800K .......... .......... .......... .......... .......... 90% 2.17M 1s\n",
            " 61850K .......... .......... .......... .......... .......... 90%  156M 1s\n",
            " 61900K .......... .......... .......... .......... .......... 90%  215M 1s\n",
            " 61950K .......... .......... .......... .......... .......... 90%  195M 1s\n",
            " 62000K .......... .......... .......... .......... .......... 90%  247M 1s\n",
            " 62050K .......... .......... .......... .......... .......... 91%  241M 1s\n",
            " 62100K .......... .......... .......... .......... .......... 91%  194M 1s\n",
            " 62150K .......... .......... .......... .......... .......... 91%  244M 1s\n",
            " 62200K .......... .......... .......... .......... .......... 91%  218M 1s\n",
            " 62250K .......... .......... .......... .......... .......... 91%  160M 1s\n",
            " 62300K .......... .......... .......... .......... .......... 91%  139M 1s\n",
            " 62350K .......... .......... .......... .......... .......... 91%  183M 1s\n",
            " 62400K .......... .......... .......... .......... .......... 91%  243M 1s\n",
            " 62450K .......... .......... .......... .......... .......... 91%  152M 1s\n",
            " 62500K .......... .......... .......... .......... .......... 91%  146M 1s\n",
            " 62550K .......... .......... .......... .......... .......... 91%  149M 1s\n",
            " 62600K .......... .......... .......... .......... .......... 91%  181M 1s\n",
            " 62650K .......... .......... .......... .......... .......... 91%  277M 1s\n",
            " 62700K .......... .......... .......... .......... .......... 92%  182M 1s\n",
            " 62750K .......... .......... .......... .......... .......... 92%  196M 1s\n",
            " 62800K .......... .......... .......... .......... .......... 92%  225M 1s\n",
            " 62850K .......... .......... .......... .......... .......... 92%  244M 1s\n",
            " 62900K .......... .......... .......... .......... .......... 92%  261M 1s\n",
            " 62950K .......... .......... .......... .......... .......... 92%  300M 1s\n",
            " 63000K .......... .......... .......... .......... .......... 92%  181M 1s\n",
            " 63050K .......... .......... .......... .......... .......... 92%  233M 1s\n",
            " 63100K .......... .......... .......... .......... .......... 92%  199M 1s\n",
            " 63150K .......... .......... .......... .......... .......... 92%  199M 1s\n",
            " 63200K .......... .......... .......... .......... .......... 92%  264M 1s\n",
            " 63250K .......... .......... .......... .......... .......... 92%  240M 1s\n",
            " 63300K .......... .......... .......... .......... .......... 92%  253M 1s\n",
            " 63350K .......... .......... .......... .......... .......... 92%  262M 1s\n",
            " 63400K .......... .......... .......... .......... .......... 93%  302M 1s\n",
            " 63450K .......... .......... .......... .......... .......... 93%  283M 1s\n",
            " 63500K .......... .......... .......... .......... .......... 93%  260M 1s\n",
            " 63550K .......... .......... .......... .......... .......... 93%  300M 1s\n",
            " 63600K .......... .......... .......... .......... .......... 93%  295M 1s\n",
            " 63650K .......... .......... .......... .......... .......... 93%  294M 1s\n",
            " 63700K .......... .......... .......... .......... .......... 93%  258M 1s\n",
            " 63750K .......... .......... .......... .......... .......... 93%  288M 1s\n",
            " 63800K .......... .......... .......... .......... .......... 93%  252M 1s\n",
            " 63850K .......... .......... .......... .......... .......... 93%  257M 1s\n",
            " 63900K .......... .......... .......... .......... .......... 93%  208M 1s\n",
            " 63950K .......... .......... .......... .......... .......... 93%  183M 1s\n",
            " 64000K .......... .......... .......... .......... .......... 93%  232M 1s\n",
            " 64050K .......... .......... .......... .......... .......... 94%  253M 1s\n",
            " 64100K .......... .......... .......... .......... .......... 94%  218M 1s\n",
            " 64150K .......... .......... .......... .......... .......... 94%  247M 1s\n",
            " 64200K .......... .......... .......... .......... .......... 94%  244M 1s\n",
            " 64250K .......... .......... .......... .......... .......... 94%  234M 1s\n",
            " 64300K .......... .......... .......... .......... .......... 94%  207M 1s\n",
            " 64350K .......... .......... .......... .......... .......... 94%  239M 1s\n",
            " 64400K .......... .......... .......... .......... .......... 94%  230M 1s\n",
            " 64450K .......... .......... .......... .......... .......... 94%  213M 1s\n",
            " 64500K .......... .......... .......... .......... .......... 94%  213M 1s\n",
            " 64550K .......... .......... .......... .......... .......... 94%  242M 1s\n",
            " 64600K .......... .......... .......... .......... .......... 94%  214M 1s\n",
            " 64650K .......... .......... .......... .......... .......... 94%  234M 1s\n",
            " 64700K .......... .......... .......... .......... .......... 94%  194M 1s\n",
            " 64750K .......... .......... .......... .......... .......... 95%  219M 1s\n",
            " 64800K .......... .......... .......... .......... .......... 95%  218M 1s\n",
            " 64850K .......... .......... .......... .......... .......... 95%  229M 1s\n",
            " 64900K .......... .......... .......... .......... .......... 95%  176M 1s\n",
            " 64950K .......... .......... .......... .......... .......... 95%  229M 1s\n",
            " 65000K .......... .......... .......... .......... .......... 95%  195M 1s\n",
            " 65050K .......... .......... .......... .......... .......... 95%  200M 1s\n",
            " 65100K .......... .......... .......... .......... .......... 95%  179M 1s\n",
            " 65150K .......... .......... .......... .......... .......... 95%  219M 1s\n",
            " 65200K .......... .......... .......... .......... .......... 95%  240M 1s\n",
            " 65250K .......... .......... .......... .......... .......... 95%  237M 1s\n",
            " 65300K .......... .......... .......... .......... .......... 95%  216M 1s\n",
            " 65350K .......... .......... .......... .......... .......... 95%  230M 1s\n",
            " 65400K .......... .......... .......... .......... .......... 95%  239M 1s\n",
            " 65450K .......... .......... .......... .......... .......... 96%  234M 1s\n",
            " 65500K .......... .......... .......... .......... .......... 96%  200M 1s\n",
            " 65550K .......... .......... .......... .......... .......... 96%  232M 0s\n",
            " 65600K .......... .......... .......... .......... .......... 96%  226M 0s\n",
            " 65650K .......... .......... .......... .......... .......... 96%  236M 0s\n",
            " 65700K .......... .......... .......... .......... .......... 96%  201M 0s\n",
            " 65750K .......... .......... .......... .......... .......... 96%  244M 0s\n",
            " 65800K .......... .......... .......... .......... .......... 96%  227M 0s\n",
            " 65850K .......... .......... .......... .......... .......... 96%  245M 0s\n",
            " 65900K .......... .......... .......... .......... .......... 96%  196M 0s\n",
            " 65950K .......... .......... .......... .......... .......... 96%  242M 0s\n",
            " 66000K .......... .......... .......... .......... .......... 96%  244M 0s\n",
            " 66050K .......... .......... .......... .......... .......... 96%  222M 0s\n",
            " 66100K .......... .......... .......... .......... .......... 97%  217M 0s\n",
            " 66150K .......... .......... .......... .......... .......... 97%  229M 0s\n",
            " 66200K .......... .......... .......... .......... .......... 97%  238M 0s\n",
            " 66250K .......... .......... .......... .......... .......... 97%  232M 0s\n",
            " 66300K .......... .......... .......... .......... .......... 97%  200M 0s\n",
            " 66350K .......... .......... .......... .......... .......... 97%  245M 0s\n",
            " 66400K .......... .......... .......... .......... .......... 97%  230M 0s\n",
            " 66450K .......... .......... .......... .......... .......... 97%  239M 0s\n",
            " 66500K .......... .......... .......... .......... .......... 97%  206M 0s\n",
            " 66550K .......... .......... .......... .......... .......... 97%  242M 0s\n",
            " 66600K .......... .......... .......... .......... .......... 97%  238M 0s\n",
            " 66650K .......... .......... .......... .......... .......... 97%  239M 0s\n",
            " 66700K .......... .......... .......... .......... .......... 97%  244M 0s\n",
            " 66750K .......... .......... .......... .......... .......... 97%  247M 0s\n",
            " 66800K .......... .......... .......... .......... .......... 98%  236M 0s\n",
            " 66850K .......... .......... .......... .......... .......... 98%  239M 0s\n",
            " 66900K .......... .......... .......... .......... .......... 98%  218M 0s\n",
            " 66950K .......... .......... .......... .......... .......... 98%  247M 0s\n",
            " 67000K .......... .......... .......... .......... .......... 98%  237M 0s\n",
            " 67050K .......... .......... .......... .......... .......... 98%  247M 0s\n",
            " 67100K .......... .......... .......... .......... .......... 98%  191M 0s\n",
            " 67150K .......... .......... .......... .......... .......... 98%  238M 0s\n",
            " 67200K .......... .......... .......... .......... .......... 98%  222M 0s\n",
            " 67250K .......... .......... .......... .......... .......... 98%  248M 0s\n",
            " 67300K .......... .......... .......... .......... .......... 98%  220M 0s\n",
            " 67350K .......... .......... .......... .......... .......... 98%  228M 0s\n",
            " 67400K .......... .......... .......... .......... .......... 98%  243M 0s\n",
            " 67450K .......... .......... .......... .......... .......... 98%  226M 0s\n",
            " 67500K .......... .......... .......... .......... .......... 99%  203M 0s\n",
            " 67550K .......... .......... .......... .......... .......... 99%  211M 0s\n",
            " 67600K .......... .......... .......... .......... .......... 99%  229M 0s\n",
            " 67650K .......... .......... .......... .......... .......... 99%  226M 0s\n",
            " 67700K .......... .......... .......... .......... .......... 99%  260M 0s\n",
            " 67750K .......... .......... .......... .......... .......... 99%  300M 0s\n",
            " 67800K .......... .......... .......... .......... .......... 99%  281M 0s\n",
            " 67850K .......... .......... .......... .......... .......... 99%  299M 0s\n",
            " 67900K .......... .......... .......... .......... .......... 99%  252M 0s\n",
            " 67950K .......... .......... .......... .......... .......... 99%  280M 0s\n",
            " 68000K .......... .......... .......... .......... .......... 99%  288M 0s\n",
            " 68050K .......... .......... .......... .......... .......... 99%  306M 0s\n",
            " 68100K .......... .......... .......... .......... .......... 99%  260M 0s\n",
            " 68150K .......... .......... .......... ..........           100%  298M=13s\n",
            "\n",
            "2022-10-10 20:10:21 (5.27 MB/s) - ‘Miniconda3-4.5.12-Linux-x86_64.sh’ saved [69826864/69826864]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Mini-conda installation\n",
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.12-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-vVa3oASIjo"
      },
      "outputs": [],
      "source": [
        "#!pip install -q condacolab\n",
        "#import condacolab\n",
        "#condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTJ1j3sr81Jl",
        "outputId": "2133be41-bd8d-4f05-aa90-4fa6a4f017de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/conda\n"
          ]
        }
      ],
      "source": [
        "!which conda # should return /usr/local/bin/conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk40GO658-Vx",
        "outputId": "6a4ac17a-6369-4e4f-abdc-96a298be99b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 4.5.12\n"
          ]
        }
      ],
      "source": [
        "!conda --version "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0xe9qjy9F78",
        "outputId": "5290df24-0a18-4673-9825-a72ca0513506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python # still returns /usr/local/bin/python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg5_K8RE9Mrx",
        "outputId": "66089d1a-6c4a-401a-abf1-884bf8358842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.1\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSLvHy3A3Gjz",
        "outputId": "1b6f0658-5f88-42cd-f342-834fbf04932e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "channels:\n",
            "  - defaults\n"
          ]
        }
      ],
      "source": [
        "!conda config --show channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9HweU1TF6KX"
      },
      "outputs": [],
      "source": [
        "#!conda config --append channels defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM4EEvuW8r47",
        "outputId": "91216215-a355-41ee-ad0d-056988c4239e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.7\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cryptography-37.0.1        |   py37h9ce1e76_0         1.5 MB\n",
            "    cffi-1.15.1                |   py37h74dc2b5_0         228 KB\n",
            "    setuptools-63.4.1          |   py37h06a4308_0         1.4 MB\n",
            "    requests-2.28.1            |   py37h06a4308_0          91 KB\n",
            "    ruamel_yaml-0.15.100       |   py37h27cfd23_0         267 KB\n",
            "    python-3.7.13              |       h12debd9_0        53.5 MB\n",
            "    wheel-0.37.1               |     pyhd3eb1b0_0          31 KB\n",
            "    conda-22.9.0               |   py37h06a4308_0         958 KB\n",
            "    tk-8.6.12                  |       h1ccaba5_0         3.3 MB\n",
            "    zlib-1.2.12                |       h5eee18b_3         124 KB\n",
            "    pysocks-1.7.1              |           py37_1          27 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    readline-8.1.2             |       h7f8727e_1         423 KB\n",
            "    xz-5.2.6                   |       h5eee18b_0         475 KB\n",
            "    sqlite-3.39.3              |       h5082296_0         1.5 MB\n",
            "    pyopenssl-22.0.0           |     pyhd3eb1b0_0          49 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         732 KB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    openssl-1.1.1q             |       h7f8727e_0         3.8 MB\n",
            "    urllib3-1.26.11            |   py37h06a4308_0         178 KB\n",
            "    tqdm-4.64.1                |   py37h06a4308_0         122 KB\n",
            "    pycparser-2.21             |     pyhd3eb1b0_0          94 KB\n",
            "    toolz-0.11.2               |     pyhd3eb1b0_0          48 KB\n",
            "    idna-3.3                   |     pyhd3eb1b0_0          55 KB\n",
            "    certifi-2022.9.24          |   py37h06a4308_0         157 KB\n",
            "    brotlipy-0.7.0             |py37h27cfd23_1003         350 KB\n",
            "    conda-package-handling-1.9.0|   py37h5eee18b_0         959 KB\n",
            "    pip-22.2.2                 |   py37h06a4308_0         2.7 MB\n",
            "    pycosat-0.6.3              |   py37h27cfd23_0         108 KB\n",
            "    ca-certificates-2022.07.19 |       h06a4308_0         131 KB\n",
            "    charset-normalizer-2.0.4   |     pyhd3eb1b0_0          33 KB\n",
            "    ncurses-6.3                |       h5eee18b_3         1.1 MB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         8.5 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        82.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    brotlipy:               0.7.0-py37h27cfd23_1003\n",
            "    charset-normalizer:     2.0.4-pyhd3eb1b0_0     \n",
            "    conda-package-handling: 1.9.0-py37h5eee18b_0   \n",
            "    ld_impl_linux-64:       2.38-h1181459_1        \n",
            "    toolz:                  0.11.2-pyhd3eb1b0_0    \n",
            "    tqdm:                   4.64.1-py37h06a4308_0  \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2022.07.19-h06a4308_0   \n",
            "    certifi:                2018.11.29-py37_0       --> 2022.9.24-py37h06a4308_0\n",
            "    cffi:                   1.11.5-py37he75722e_1   --> 1.15.1-py37h74dc2b5_0   \n",
            "    conda:                  4.5.12-py37_0           --> 22.9.0-py37h06a4308_0   \n",
            "    cryptography:           2.4.2-py37h1ba5d50_0    --> 37.0.1-py37h9ce1e76_0   \n",
            "    idna:                   2.8-py37_0              --> 3.3-pyhd3eb1b0_0        \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              8.2.0-hdf63c60_1        --> 11.2.0-h1234567_1       \n",
            "    ncurses:                6.1-he6710b0_1          --> 6.3-h5eee18b_3          \n",
            "    openssl:                1.1.1a-h7b6447c_0       --> 1.1.1q-h7f8727e_0       \n",
            "    pip:                    18.1-py37_0             --> 22.2.2-py37h06a4308_0   \n",
            "    pycosat:                0.6.3-py37h14c3975_0    --> 0.6.3-py37h27cfd23_0    \n",
            "    pycparser:              2.19-py37_0             --> 2.21-pyhd3eb1b0_0       \n",
            "    pyopenssl:              18.0.0-py37_0           --> 22.0.0-pyhd3eb1b0_0     \n",
            "    pysocks:                1.6.8-py37_0            --> 1.7.1-py37_1            \n",
            "    python:                 3.7.1-h0371630_7        --> 3.7.13-h12debd9_0       \n",
            "    readline:               7.0-h7b6447c_5          --> 8.1.2-h7f8727e_1        \n",
            "    requests:               2.21.0-py37_0           --> 2.28.1-py37h06a4308_0   \n",
            "    ruamel_yaml:            0.15.46-py37h14c3975_0  --> 0.15.100-py37h27cfd23_0 \n",
            "    setuptools:             40.6.3-py37_0           --> 63.4.1-py37h06a4308_0   \n",
            "    sqlite:                 3.26.0-h7b6447c_0       --> 3.39.3-h5082296_0       \n",
            "    tk:                     8.6.8-hbc83047_0        --> 8.6.12-h1ccaba5_0       \n",
            "    urllib3:                1.24.1-py37_0           --> 1.26.11-py37h06a4308_0  \n",
            "    wheel:                  0.32.3-py37_0           --> 0.37.1-pyhd3eb1b0_0     \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.6-h5eee18b_0        \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n",
            "    zlib:                   1.2.11-h7b6447c_3       --> 1.2.12-h5eee18b_3       \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "cryptography-37.0.1  | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.62it/s]              \n",
            "cffi-1.15.1          | 228 KB    | : 100% 1.0/1 [00:00<00:00, 15.43it/s]\n",
            "setuptools-63.4.1    | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.36it/s]               \n",
            "requests-2.28.1      | 91 KB     | : 100% 1.0/1 [00:00<00:00, 23.66it/s]\n",
            "ruamel_yaml-0.15.100 | 267 KB    | : 100% 1.0/1 [00:00<00:00,  4.89s/it]                 \n",
            "python-3.7.13        | 53.5 MB   | : 100% 1.0/1 [00:06<00:00,  6.16s/it]               \n",
            "wheel-0.37.1         | 31 KB     | : 100% 1.0/1 [00:00<00:00, 39.57it/s]\n",
            "conda-22.9.0         | 958 KB    | : 100% 1.0/1 [00:00<00:00,  2.95it/s]               \n",
            "tk-8.6.12            | 3.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.57it/s]               \n",
            "zlib-1.2.12          | 124 KB    | : 100% 1.0/1 [00:00<00:00, 23.87it/s]\n",
            "pysocks-1.7.1        | 27 KB     | : 100% 1.0/1 [00:00<00:00, 45.71it/s]\n",
            "yaml-0.2.5           | 87 KB     | : 100% 1.0/1 [00:00<00:00, 29.29it/s]\n",
            "readline-8.1.2       | 423 KB    | : 100% 1.0/1 [00:00<00:00, 10.04it/s]\n",
            "xz-5.2.6             | 475 KB    | : 100% 1.0/1 [00:00<00:00,  7.36it/s]               \n",
            "sqlite-3.39.3        | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  4.56it/s]              \n",
            "pyopenssl-22.0.0     | 49 KB     | : 100% 1.0/1 [00:00<00:00, 32.34it/s]\n",
            "ld_impl_linux-64-2.3 | 732 KB    | : 100% 1.0/1 [00:00<00:00,  7.26it/s]               \n",
            "libffi-3.3           | 54 KB     | : 100% 1.0/1 [00:00<00:00, 34.76it/s]\n",
            "openssl-1.1.1q       | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.75it/s]               \n",
            "urllib3-1.26.11      | 178 KB    | : 100% 1.0/1 [00:00<00:00, 14.70it/s]\n",
            "tqdm-4.64.1          | 122 KB    | : 100% 1.0/1 [00:00<00:00, 17.19it/s]\n",
            "pycparser-2.21       | 94 KB     | : 100% 1.0/1 [00:00<00:00, 23.52it/s]\n",
            "toolz-0.11.2         | 48 KB     | : 100% 1.0/1 [00:00<00:00, 29.84it/s]\n",
            "idna-3.3             | 55 KB     | : 100% 1.0/1 [00:00<00:00, 36.75it/s]\n",
            "certifi-2022.9.24    | 157 KB    | : 100% 1.0/1 [00:00<00:00, 26.27it/s]\n",
            "brotlipy-0.7.0       | 350 KB    | : 100% 1.0/1 [00:00<00:00, 15.64it/s]\n",
            "conda-package-handli | 959 KB    | : 100% 1.0/1 [00:00<00:00,  1.53it/s]               \n",
            "pip-22.2.2           | 2.7 MB    | : 100% 1.0/1 [00:00<00:00,  1.45it/s]               \n",
            "pycosat-0.6.3        | 108 KB    | : 100% 1.0/1 [00:00<00:00,  2.90it/s]               \n",
            "ca-certificates-2022 | 131 KB    | : 100% 1.0/1 [00:00<00:00, 32.57it/s]\n",
            "charset-normalizer-2 | 33 KB     | : 100% 1.0/1 [00:00<00:00, 39.05it/s]\n",
            "ncurses-6.3          | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.32it/s]               \n",
            "libgcc-ng-11.2.0     | 8.5 MB    | : 100% 1.0/1 [00:01<00:00,  1.18s/it]               \n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\b\b/ \n",
            "\n",
            "  - defaults/linux-64::conda==22.9.0=py37h06a4308_0\n",
            "  - defaults/noarch::idna==3.3=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::libgcc-ng==11.2.0=h1234567_1\n",
            "  - defaults/linux-64::libffi==3.3=he6710b0_2\n",
            "  - defaults/linux-64::conda-package-handling==1.9.0=py37h5eee18b_0\n",
            "  - defaults/linux-64::sqlite==3.39.3=h5082296_0\n",
            "  - defaults/linux-64::zlib==1.2.12=h5eee18b_3\n",
            "  - defaults/linux-64::chardet==3.0.4=py37_1\n",
            "  - defaults/linux-64::pip==22.2.2=py37h06a4308_0\n",
            "  - defaults/linux-64::six==1.12.0=py37_0\n",
            "  - defaults/linux-64::certifi==2022.9.24=py37h06a4308_0\n",
            "  - defaults/linux-64::tk==8.6.12=h1ccaba5_0\n",
            "  - defaults/linux-64::xz==5.2.6=h5eee18b_0\n",
            "  - defaults/noarch::toolz==0.11.2=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::asn1crypto==0.24.0=py37_0\n",
            "  - defaults/linux-64::readline==8.1.2=h7f8727e_1\n",
            "  - defaults/linux-64::pycosat==0.6.3=py37h27cfd23_0\n",
            "  - defaults/linux-64::libedit==3.1.20170329=h6b74fdf_2\n",
            "  - defaults/linux-64::openssl==1.1.1q=h7f8727e_0\n",
            "  - defaults/linux-64::requests==2.28.1=py37h06a4308_0\n",
            "  - defaults/noarch::charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::tqdm==4.64.1=py37h06a4308_0\n",
            "  - defaults/noarch::wheel==0.37.1=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::yaml==0.2.5=h7b6447c_0\n",
            "  - defaults/linux-64::cryptography==37.0.1=py37h9ce1e76_0\n",
            "  - defaults/noarch::pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::ruamel_yaml==0.15.100=py37h27cfd23_0\n",
            "  - defaults/linux-64::setuptools==63.4.1=py37h06a4308_0\n",
            "  - defaults/linux-64::pysocks==1.7.1=py37_1\n",
            "  - defaults/linux-64::brotlipy==0.7.0=py37h27cfd23_1003\n",
            "  - defaults/linux-64::cffi==1.15.1=py37h74dc2b5_0\n",
            "  - defaults/linux-64::python==3.7.13=h12debd9_0\n",
            "  - defaults/linux-64::urllib3==1.26.11=py37h06a4308_0\n",
            "  - defaults/noarch::pycparser==2.21=pyhd3eb1b0_0\n",
            "  - defaults/linux-64::ncurses==6.3=h5eee18b_3\n",
            "\b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         5.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main None\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu None\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 None\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  libstdcxx-ng                             8.2.0-hdf63c60_1 --> 11.2.0-h1234567_1 None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00, 12.55it/s]\n",
            "_libgcc_mutex-0.1    | 3 KB      | : 100% 1.0/1 [00:00<00:00, 27.49it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  7.03it/s]\n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00, 27.35it/s]\n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\bdone\n",
            "Executing transaction: / \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!conda install --channel defaults conda python=3.7 --yes\n",
        "!conda update --channel defaults --all --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UwLjxGt-JQe",
        "outputId": "ac8955f9-bb7e-44f8-8534-5bec37eda72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDy1JjLX1ERT",
        "outputId": "46da8e33-b842-43f3-e93b-4a360c9eeace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/conda\n",
            "conda 22.9.0\n"
          ]
        }
      ],
      "source": [
        "!which conda # should return /usr/local/bin/conda\n",
        "!conda --version\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acukhjzYlxFq",
        "outputId": "db60f921-4417-4325-9f8e-7668ec19ff55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Drive installation and edit permission \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP6T2S_-3J9I"
      },
      "source": [
        "# First environment for running RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVds1YeyiuXD",
        "outputId": "26e5be2e-3434-4589-c91f-045e29d80a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/maskrcnn_benchmark\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         1.8 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         788 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        35.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main None\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu None\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.07.19-h06a4308_0 None\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0 None\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 None\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2 None\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 None\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 None\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 None\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h5eee18b_3 None\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1q-h7f8727e_0 None\n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0 None\n",
            "  python             pkgs/main/linux-64::python-3.6.13-h12debd9_1 None\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1 None\n",
            "  setuptools         pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0 None\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.39.2-h5082296_0 None\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0 None\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0 None\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7f8727e_1 None\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h5eee18b_3 None\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  4.50it/s]\n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00, 18.85it/s]\n",
            "setuptools-58.0.4    | 788 KB    | : 100% 1.0/1 [00:00<00:00,  9.94it/s]\n",
            "python-3.6.13        | 32.5 MB   | : 100% 1.0/1 [00:04<00:00,  4.19s/it]               \n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate maskrcnn_benchmark\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "#Creation of the first conda environment for the RCNN model\n",
        "!conda create --name maskrcnn_benchmark -y python=3.6 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eca3hpmZoXsL"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "python\n",
        "import sys\n",
        "sys.path.append('/usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyvSG_7-i4Yu",
        "outputId": "936f06c8-f10b-4399-e9b1-6512bb6d9252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/maskrcnn_benchmark\n",
            "\n",
            "  added / updated specs:\n",
            "    - ipython\n",
            "    - pip\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    backcall-0.2.0             |     pyhd3eb1b0_0          13 KB\n",
            "    decorator-5.1.1            |     pyhd3eb1b0_0          12 KB\n",
            "    ipython-7.16.1             |   py36h5ca1d4c_0         999 KB\n",
            "    ipython_genutils-0.2.0     |     pyhd3eb1b0_1          27 KB\n",
            "    jedi-0.17.0                |           py36_0         780 KB\n",
            "    parso-0.8.3                |     pyhd3eb1b0_0          70 KB\n",
            "    pexpect-4.8.0              |     pyhd3eb1b0_3          53 KB\n",
            "    pickleshare-0.7.5          |  pyhd3eb1b0_1003          13 KB\n",
            "    prompt-toolkit-3.0.20      |     pyhd3eb1b0_0         259 KB\n",
            "    ptyprocess-0.7.0           |     pyhd3eb1b0_2          17 KB\n",
            "    pygments-2.11.2            |     pyhd3eb1b0_0         759 KB\n",
            "    six-1.16.0                 |     pyhd3eb1b0_1          18 KB\n",
            "    traitlets-4.3.3            |   py36h06a4308_0         138 KB\n",
            "    wcwidth-0.2.5              |     pyhd3eb1b0_0          26 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         3.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  backcall           pkgs/main/noarch::backcall-0.2.0-pyhd3eb1b0_0 None\n",
            "  decorator          pkgs/main/noarch::decorator-5.1.1-pyhd3eb1b0_0 None\n",
            "  ipython            pkgs/main/linux-64::ipython-7.16.1-py36h5ca1d4c_0 None\n",
            "  ipython_genutils   pkgs/main/noarch::ipython_genutils-0.2.0-pyhd3eb1b0_1 None\n",
            "  jedi               pkgs/main/linux-64::jedi-0.17.0-py36_0 None\n",
            "  parso              pkgs/main/noarch::parso-0.8.3-pyhd3eb1b0_0 None\n",
            "  pexpect            pkgs/main/noarch::pexpect-4.8.0-pyhd3eb1b0_3 None\n",
            "  pickleshare        pkgs/main/noarch::pickleshare-0.7.5-pyhd3eb1b0_1003 None\n",
            "  prompt-toolkit     pkgs/main/noarch::prompt-toolkit-3.0.20-pyhd3eb1b0_0 None\n",
            "  ptyprocess         pkgs/main/noarch::ptyprocess-0.7.0-pyhd3eb1b0_2 None\n",
            "  pygments           pkgs/main/noarch::pygments-2.11.2-pyhd3eb1b0_0 None\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1 None\n",
            "  traitlets          pkgs/main/linux-64::traitlets-4.3.3-py36h06a4308_0 None\n",
            "  wcwidth            pkgs/main/noarch::wcwidth-0.2.5-pyhd3eb1b0_0 None\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? \n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\ripython_genutils-0.2 | 27 KB     |            |   0% \ripython_genutils-0.2 | 27 KB     | ########## | 100% \n",
            "\rptyprocess-0.7.0     | 17 KB     |            |   0% \rptyprocess-0.7.0     | 17 KB     | ########## | 100% \n",
            "\rbackcall-0.2.0       | 13 KB     |            |   0% \rbackcall-0.2.0       | 13 KB     | ########## | 100% \n",
            "\rprompt-toolkit-3.0.2 | 259 KB    |            |   0% \rprompt-toolkit-3.0.2 | 259 KB    | ########## | 100% \n",
            "\rpexpect-4.8.0        | 53 KB     |            |   0% \rpexpect-4.8.0        | 53 KB     | ########## | 100% \n",
            "\ripython-7.16.1       | 999 KB    |            |   0% \ripython-7.16.1       | 999 KB    | ########## | 100% \ripython-7.16.1       | 999 KB    | ########## | 100% \n",
            "\rpickleshare-0.7.5    | 13 KB     |            |   0% \rpickleshare-0.7.5    | 13 KB     | ########## | 100% \n",
            "\rdecorator-5.1.1      | 12 KB     |            |   0% \rdecorator-5.1.1      | 12 KB     | ########## | 100% \n",
            "\rsix-1.16.0           | 18 KB     |            |   0% \rsix-1.16.0           | 18 KB     | ########## | 100% \n",
            "\rjedi-0.17.0          | 780 KB    |            |   0% \rjedi-0.17.0          | 780 KB    | ########## | 100% \rjedi-0.17.0          | 780 KB    | ########## | 100% \n",
            "\rtraitlets-4.3.3      | 138 KB    |            |   0% \rtraitlets-4.3.3      | 138 KB    | ########## | 100% \n",
            "\rpygments-2.11.2      | 759 KB    |            |   0% \rpygments-2.11.2      | 759 KB    | ########## | 100% \n",
            "\rwcwidth-0.2.5        | 26 KB     |            |   0% \rwcwidth-0.2.5        | 26 KB     | ########## | 100% \n",
            "\rparso-0.8.3          | 70 KB     |            |   0% \rparso-0.8.3          | 70 KB     | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "conda install ipython pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBUGQk9L2VEH",
        "outputId": "d0b9e985-4724-487c-e932-6a1958c4af58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/maskrcnn_benchmark\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=10.0\n",
            "    - pytorch=1.1.0\n",
            "    - torchvision\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    cffi-1.14.6                |   py36h400218f_0         220 KB\n",
            "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
            "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
            "    freetype-2.11.0            |       h70c0345_0         618 KB\n",
            "    intel-openmp-2022.1.0      |    h9e868ea_3769         4.5 MB\n",
            "    jpeg-9e                    |       h7f8727e_0         240 KB\n",
            "    lcms2-2.12                 |       h3be6417_0         312 KB\n",
            "    lerc-3.0                   |       h295c915_0         196 KB\n",
            "    libdeflate-1.8             |       h7f8727e_5          51 KB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libtiff-4.4.0              |       hecacb30_0         471 KB\n",
            "    libwebp-base-1.2.2         |       h7f8727e_0         440 KB\n",
            "    lz4-c-1.9.3                |       h295c915_1         185 KB\n",
            "    mkl-2020.2                 |              256       138.3 MB\n",
            "    mkl-service-2.3.0          |   py36he8ac12f_0          52 KB\n",
            "    mkl_fft-1.3.0              |   py36h54f3939_0         170 KB\n",
            "    mkl_random-1.1.1           |   py36h0573a6f_0         327 KB\n",
            "    ninja-1.10.2               |       h06a4308_5           8 KB\n",
            "    ninja-base-1.10.2          |       hd09550d_5         109 KB\n",
            "    numpy-1.19.2               |   py36h54aff64_0          22 KB\n",
            "    numpy-base-1.19.2          |   py36hfa32c7d_0         4.1 MB\n",
            "    olefile-0.46               |           py36_0          48 KB\n",
            "    openjpeg-2.4.0             |       h3ad879b_0         331 KB\n",
            "    pillow-8.3.1               |   py36h2c7a002_0         637 KB\n",
            "    pytorch-1.1.0              |cuda100py36he554f03_0       196.2 MB\n",
            "    torchvision-0.3.0          |cuda100py36h72fc40a_0         1.9 MB\n",
            "    zstd-1.5.2                 |       ha4553b6_0         488 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       776.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl None\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.6-py36h400218f_0 None\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0 None\n",
            "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0 None\n",
            "  freetype           pkgs/main/linux-64::freetype-2.11.0-h70c0345_0 None\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2022.1.0-h9e868ea_3769 None\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9e-h7f8727e_0 None\n",
            "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0 None\n",
            "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 None\n",
            "  libdeflate         pkgs/main/linux-64::libdeflate-1.8-h7f8727e_5 None\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0 None\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.4.0-hecacb30_0 None\n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.2-h7f8727e_0 None\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h295c915_1 None\n",
            "  mkl                pkgs/main/linux-64::mkl-2020.2-256 None\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py36he8ac12f_0 None\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.0-py36h54f3939_0 None\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py36h0573a6f_0 None\n",
            "  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5 None\n",
            "  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5 None\n",
            "  numpy              pkgs/main/linux-64::numpy-1.19.2-py36h54aff64_0 None\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.2-py36hfa32c7d_0 None\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py36_0 None\n",
            "  openjpeg           pkgs/main/linux-64::openjpeg-2.4.0-h3ad879b_0 None\n",
            "  pillow             pkgs/main/linux-64::pillow-8.3.1-py36h2c7a002_0 None\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0 None\n",
            "  pytorch            pkgs/main/linux-64::pytorch-1.1.0-cuda100py36he554f03_0 None\n",
            "  torchvision        pkgs/main/linux-64::torchvision-0.3.0-cuda100py36h72fc40a_0 None\n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.2-ha4553b6_0 None\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? \n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\rlerc-3.0             | 196 KB    |            |   0% \rlerc-3.0             | 196 KB    | ########## | 100% \n",
            "\rjpeg-9e              | 240 KB    |            |   0% \rjpeg-9e              | 240 KB    | ########## | 100% \n",
            "\rolefile-0.46         | 48 KB     |            |   0% \rolefile-0.46         | 48 KB     | ########## | 100% \n",
            "\rcudatoolkit-10.0.130 | 261.2 MB  |            |   0% \rcudatoolkit-10.0.130 | 261.2 MB  | 3          |   3% \rcudatoolkit-10.0.130 | 261.2 MB  | 7          |   8% \rcudatoolkit-10.0.130 | 261.2 MB  | #2         |  12% \rcudatoolkit-10.0.130 | 261.2 MB  | #6         |  16% \rcudatoolkit-10.0.130 | 261.2 MB  | ##         |  21% \rcudatoolkit-10.0.130 | 261.2 MB  | ##5        |  25% \rcudatoolkit-10.0.130 | 261.2 MB  | ##9        |  29% \rcudatoolkit-10.0.130 | 261.2 MB  | ###3       |  34% \rcudatoolkit-10.0.130 | 261.2 MB  | ###7       |  38% \rcudatoolkit-10.0.130 | 261.2 MB  | ####2      |  42% \rcudatoolkit-10.0.130 | 261.2 MB  | ####6      |  46% \rcudatoolkit-10.0.130 | 261.2 MB  | #####      |  51% \rcudatoolkit-10.0.130 | 261.2 MB  | #####5     |  55% \rcudatoolkit-10.0.130 | 261.2 MB  | #####9     |  59% \rcudatoolkit-10.0.130 | 261.2 MB  | ######3    |  64% \rcudatoolkit-10.0.130 | 261.2 MB  | ######7    |  68% \rcudatoolkit-10.0.130 | 261.2 MB  | #######2   |  72% \rcudatoolkit-10.0.130 | 261.2 MB  | #######6   |  76% \rcudatoolkit-10.0.130 | 261.2 MB  | ########   |  80% \rcudatoolkit-10.0.130 | 261.2 MB  | ########4  |  85% \rcudatoolkit-10.0.130 | 261.2 MB  | ########9  |  89% \rcudatoolkit-10.0.130 | 261.2 MB  | #########3 |  93% \rcudatoolkit-10.0.130 | 261.2 MB  | #########7 |  97% \rcudatoolkit-10.0.130 | 261.2 MB  | ########## | 100% \n",
            "\ropenjpeg-2.4.0       | 331 KB    |            |   0% \ropenjpeg-2.4.0       | 331 KB    | ########## | 100% \n",
            "\rcudnn-7.6.5          | 165.0 MB  |            |   0% \rcudnn-7.6.5          | 165.0 MB  | 5          |   6% \rcudnn-7.6.5          | 165.0 MB  | #2         |  12% \rcudnn-7.6.5          | 165.0 MB  | #9         |  19% \rcudnn-7.6.5          | 165.0 MB  | ##6        |  26% \rcudnn-7.6.5          | 165.0 MB  | ###2       |  33% \rcudnn-7.6.5          | 165.0 MB  | ####       |  40% \rcudnn-7.6.5          | 165.0 MB  | ####7      |  47% \rcudnn-7.6.5          | 165.0 MB  | #####3     |  54% \rcudnn-7.6.5          | 165.0 MB  | ######     |  61% \rcudnn-7.6.5          | 165.0 MB  | ######7    |  68% \rcudnn-7.6.5          | 165.0 MB  | #######4   |  75% \rcudnn-7.6.5          | 165.0 MB  | ########1  |  82% \rcudnn-7.6.5          | 165.0 MB  | ########8  |  89% \rcudnn-7.6.5          | 165.0 MB  | #########5 |  96% \rcudnn-7.6.5          | 165.0 MB  | ########## | 100% \n",
            "\rnumpy-1.19.2         | 22 KB     |            |   0% \rnumpy-1.19.2         | 22 KB     | ########## | 100% \n",
            "\rtorchvision-0.3.0    | 1.9 MB    |            |   0% \rtorchvision-0.3.0    | 1.9 MB    | ########## | 100% \rtorchvision-0.3.0    | 1.9 MB    | ########## | 100% \n",
            "\rlibpng-1.6.37        | 278 KB    |            |   0% \rlibpng-1.6.37        | 278 KB    | ########## | 100% \n",
            "\rcffi-1.14.6          | 220 KB    |            |   0% \rcffi-1.14.6          | 220 KB    | ########## | 100% \n",
            "\rninja-1.10.2         | 8 KB      |            |   0% \rninja-1.10.2         | 8 KB      | ########## | 100% \n",
            "\rlz4-c-1.9.3          | 185 KB    |            |   0% \rlz4-c-1.9.3          | 185 KB    | ########## | 100% \n",
            "\rblas-1.0             | 6 KB      |            |   0% \rblas-1.0             | 6 KB      | ########## | 100% \n",
            "\rninja-base-1.10.2    | 109 KB    |            |   0% \rninja-base-1.10.2    | 109 KB    | ########## | 100% \n",
            "\rmkl_random-1.1.1     | 327 KB    |            |   0% \rmkl_random-1.1.1     | 327 KB    | ########## | 100% \n",
            "\rlibdeflate-1.8       | 51 KB     |            |   0% \rlibdeflate-1.8       | 51 KB     | ########## | 100% \n",
            "\rmkl_fft-1.3.0        | 170 KB    |            |   0% \rmkl_fft-1.3.0        | 170 KB    | ########## | 100% \n",
            "\rlibtiff-4.4.0        | 471 KB    |            |   0% \rlibtiff-4.4.0        | 471 KB    | ########## | 100% \n",
            "\rlcms2-2.12           | 312 KB    |            |   0% \rlcms2-2.12           | 312 KB    | ########## | 100% \n",
            "\rfreetype-2.11.0      | 618 KB    |            |   0% \rfreetype-2.11.0      | 618 KB    | ########## | 100% \n",
            "\rmkl-2020.2           | 138.3 MB  |            |   0% \rmkl-2020.2           | 138.3 MB  | 6          |   6% \rmkl-2020.2           | 138.3 MB  | #3         |  14% \rmkl-2020.2           | 138.3 MB  | ##1        |  21% \rmkl-2020.2           | 138.3 MB  | ##9        |  29% \rmkl-2020.2           | 138.3 MB  | ###6       |  37% \rmkl-2020.2           | 138.3 MB  | ####4      |  44% \rmkl-2020.2           | 138.3 MB  | #####2     |  52% \rmkl-2020.2           | 138.3 MB  | #####9     |  60% \rmkl-2020.2           | 138.3 MB  | ######7    |  68% \rmkl-2020.2           | 138.3 MB  | #######5   |  76% \rmkl-2020.2           | 138.3 MB  | ########3  |  83% \rmkl-2020.2           | 138.3 MB  | #########  |  91% \rmkl-2020.2           | 138.3 MB  | #########8 |  98% \rmkl-2020.2           | 138.3 MB  | ########## | 100% \n",
            "\rpytorch-1.1.0        | 196.2 MB  |            |   0% \rpytorch-1.1.0        | 196.2 MB  | 3          |   4% \rpytorch-1.1.0        | 196.2 MB  | 9          |   9% \rpytorch-1.1.0        | 196.2 MB  | #4         |  15% \rpytorch-1.1.0        | 196.2 MB  | ##         |  21% \rpytorch-1.1.0        | 196.2 MB  | ##6        |  26% \rpytorch-1.1.0        | 196.2 MB  | ###1       |  32% \rpytorch-1.1.0        | 196.2 MB  | ###7       |  37% \rpytorch-1.1.0        | 196.2 MB  | ####3      |  43% \rpytorch-1.1.0        | 196.2 MB  | ####9      |  49% \rpytorch-1.1.0        | 196.2 MB  | #####4     |  55% \rpytorch-1.1.0        | 196.2 MB  | ######     |  61% \rpytorch-1.1.0        | 196.2 MB  | ######6    |  66% \rpytorch-1.1.0        | 196.2 MB  | #######1   |  72% \rpytorch-1.1.0        | 196.2 MB  | #######7   |  77% \rpytorch-1.1.0        | 196.2 MB  | ########2  |  83% \rpytorch-1.1.0        | 196.2 MB  | ########8  |  88% \rpytorch-1.1.0        | 196.2 MB  | #########4 |  94% \rpytorch-1.1.0        | 196.2 MB  | ########## | 100% \rpytorch-1.1.0        | 196.2 MB  | ########## | 100% \n",
            "\rlibwebp-base-1.2.2   | 440 KB    |            |   0% \rlibwebp-base-1.2.2   | 440 KB    | ########## | 100% \n",
            "\rmkl-service-2.3.0    | 52 KB     |            |   0% \rmkl-service-2.3.0    | 52 KB     | ########## | 100% \n",
            "\rpillow-8.3.1         | 637 KB    |            |   0% \rpillow-8.3.1         | 637 KB    | ########## | 100% \n",
            "\rintel-openmp-2022.1. | 4.5 MB    |            |   0% \rintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \rintel-openmp-2022.1. | 4.5 MB    | ########## | 100% \n",
            "\rzstd-1.5.2           | 488 KB    |            |   0% \rzstd-1.5.2           | 488 KB    | ########## | 100% \n",
            "\rnumpy-base-1.19.2    | 4.1 MB    |            |   0% \rnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \rnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "#Pytorch version must be nightly\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "conda install pytorch=1.1.0 torchvision cudatoolkit=10.0 -c pytorch-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viPzx7-gugNz",
        "outputId": "d32d7f2a-9354-4db7-db3e-756edcd5de04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision==0.2.2\n",
            "  Downloading torchvision-0.2.2-py2.py3-none-any.whl (64 kB)\n",
            "Requirement already satisfied: torch in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from torchvision==0.2.2) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from torchvision==0.2.2) (8.3.1)\n",
            "Collecting tqdm==4.19.9\n",
            "  Downloading tqdm-4.19.9-py2.py3-none-any.whl (52 kB)\n",
            "Requirement already satisfied: six in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from torchvision==0.2.2) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from torchvision==0.2.2) (1.19.2)\n",
            "Installing collected packages: tqdm, torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.3.0\n",
            "    Uninstalling torchvision-0.3.0:\n",
            "      Successfully uninstalled torchvision-0.3.0\n",
            "Successfully installed torchvision-0.2.2 tqdm-4.19.9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "#Version torchvision 0.3.0 has a problem:\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark\n",
        "pip install torchvision==0.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIuGYwrjjPLR",
        "outputId": "381d091b-9a59-4a03-e927-4e34bbcc9bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting cython\n",
            "  Downloading Cython-0.29.32-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (2.0 MB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (4.19.9)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from matplotlib) (1.19.2)\n",
            "Collecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from matplotlib) (8.3.1)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n",
            "Installing collected packages: PyYAML, python-dateutil, pyparsing, kiwisolver, cycler, yacs, opencv-python, ninja, matplotlib, cython\n",
            "Successfully installed PyYAML-6.0 cycler-0.11.0 cython-0.29.32 kiwisolver-1.3.1 matplotlib-3.3.4 ninja-1.10.2.3 opencv-python-4.6.0.66 pyparsing-3.0.9 python-dateutil-2.8.2 yacs-0.1.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "pip install ninja yacs cython matplotlib tqdm opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUhFHwxbkXj9",
        "outputId": "dadf3696-1a81-4bdb-8012-412c794b1bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6319, 0.5998, 0.7093],\n",
            "        [0.8467, 0.3579, 0.7404],\n",
            "        [0.5184, 0.9784, 0.4934],\n",
            "        [0.9896, 0.4785, 0.5378],\n",
            "        [0.9638, 0.3244, 0.5257]])\n",
            "True\n",
            "1.1.0\n",
            "1.1.0\n",
            "Collecting environment information...\n",
            "PyTorch version: 1.1.0\n",
            "Is debug build: No\n",
            "CUDA used to build PyTorch: 10.0.130\n",
            "\n",
            "OS: Ubuntu 18.04.6 LTS\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "CMake version: version 3.22.6\n",
            "\n",
            "Python version: 3.6\n",
            "Is CUDA available: Yes\n",
            "CUDA runtime version: Could not collect\n",
            "GPU models and configuration: GPU 0: Tesla P100-PCIE-16GB\n",
            "Nvidia driver version: 460.32.03\n",
            "cuDNN version: Probably one of the following:\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.0.5\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.0.5\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.0.5\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.0.5\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.0.5\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.0.5\n",
            "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.0.5\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.19.2\n",
            "[pip3] torch==1.1.0\n",
            "[pip3] torchvision==0.2.2\n",
            "[conda] blas                      1.0                         mkl  \n",
            "[conda] mkl                       2020.2                      256  \n",
            "[conda] mkl-service               2.3.0            py36he8ac12f_0  \n",
            "[conda] mkl_fft                   1.3.0            py36h54f3939_0  \n",
            "[conda] mkl_random                1.1.1            py36h0573a6f_0  \n",
            "[conda] pytorch                   1.1.0           cuda100py36he554f03_0  \n",
            "[conda] torchvision               0.2.2                    pypi_0    pypi\n",
            "0.2.2\n"
          ]
        }
      ],
      "source": [
        "# Verification\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "python -c 'import torch;import torchvision;print(torch.rand(5, 3));print(torch.cuda.is_available());print(torch.__version__);print(torch.__version__)'\n",
        "python -c 'from torch.utils.collect_env import main;import torchvision; main();print(torchvision.__version__)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPMCamrWpl7o",
        "outputId": "77ffd916-dcdd-431c-a1e2-0923cebec217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [4, 4, 4],\n",
            "        [3, 3, 3]])\n",
            "tensor([[4, 5, 6],\n",
            "        [4, 5, 6],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "#Error: torch.meshgrid(x, y) fixée\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark &&\n",
        "python -c 'import torch;x = torch.tensor([1, 4, 3]);y = torch.tensor([4, 5, 6]);grid_x, grid_y = torch.meshgrid(x, y);print(grid_x);print(grid_y)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOzsyttqjvhj",
        "outputId": "94dd6bc5-a003-4fa6-e20b-59f8ca025cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing pycocotools.egg-info/PKG-INFO\n",
            "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
            "writing requirements to pycocotools.egg-info/requires.txt\n",
            "writing top-level names to pycocotools.egg-info/top_level.txt\n",
            "reading manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-36.pyc\n",
            "creating stub loader for pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating 'dist/pycocotools-2.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pycocotools-2.0-py3.6-linux-x86_64.egg\n",
            "creating /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages/pycocotools-2.0-py3.6-linux-x86_64.egg\n",
            "Extracting pycocotools-2.0-py3.6-linux-x86_64.egg to /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Adding pycocotools 2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages/pycocotools-2.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for pycocotools==2.0\n",
            "Searching for matplotlib==3.3.4\n",
            "Best match: matplotlib 3.3.4\n",
            "Adding matplotlib 3.3.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for Cython==0.29.32\n",
            "Best match: Cython 0.29.32\n",
            "Adding Cython 0.29.32 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/envs/maskrcnn_benchmark/bin\n",
            "Installing cython script to /usr/local/envs/maskrcnn_benchmark/bin\n",
            "Installing cythonize script to /usr/local/envs/maskrcnn_benchmark/bin\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for setuptools==58.0.4\n",
            "Best match: setuptools 58.0.4\n",
            "Adding setuptools 58.0.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for Pillow==8.3.1\n",
            "Best match: Pillow 8.3.1\n",
            "Adding Pillow 8.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for numpy==1.19.2\n",
            "Best match: numpy 1.19.2\n",
            "Adding numpy 1.19.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/envs/maskrcnn_benchmark/bin\n",
            "Installing f2py3 script to /usr/local/envs/maskrcnn_benchmark/bin\n",
            "Installing f2py3.6 script to /usr/local/envs/maskrcnn_benchmark/bin\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for kiwisolver==1.3.1\n",
            "Best match: kiwisolver 1.3.1\n",
            "Adding kiwisolver 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Searching for six==1.16.0\n",
            "Best match: six 1.16.0\n",
            "Adding six 1.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Finished processing dependencies for pycocotools==2.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "zip_safe flag not set; analyzing archive contents...\n",
            "pycocotools.__pycache__._mask.cpython-36: module references __file__\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "#rm -Rf cocoapi\n",
        "#git clone https://github.com/cocodataset/cocoapi.git\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/cocoapi/PythonAPI\n",
        "python setup.py build_ext install\n",
        "cd ..\n",
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYaZL_d_NE1x",
        "outputId": "bc4cbce5-ea8a-46c0-8a0b-e478f35b6022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tsungyi\n"
          ]
        }
      ],
      "source": [
        "#Verefication\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark\n",
        "python\n",
        "from pycocotools import mask as mask\n",
        "print(mask.__author__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C8mQqyNBy7A-",
        "outputId": "a8111344-114f-47e1-b9ce-2efcb8ce99c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using pip 21.2.2 from /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages/pip (python 3.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/apex\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py): started\n",
            "  Building wheel for apex (setup.py): finished with status 'done'\n",
            "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=339783 sha256=90344c95fe04908b4ebe12eacca6c977505995c8dddf56e577ecee8e94b716cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-911ti3pp/wheels/0f/d8/4c/0303f281f12f50143fc5ff1788b428e8c6771cecd8cb64fba0\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.1.0\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-80hkk91e/apex.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-80hkk91e/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-80hkk91e/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-80hkk91e/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-80hkk91e/apex.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-pip-egg-info-80hkk91e/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-80hkk91e/apex.egg-info/SOURCES.txt'\n",
            "  Running command /usr/local/envs/maskrcnn_benchmark/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-pwbtwmpq/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-pwbtwmpq/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-8b5akydn\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.1.0\n",
            "\n",
            "\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  copying apex/_autocast_utils.py -> build/lib/apex\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/transformer\n",
            "  copying apex/transformer/microbatches.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/log_util.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/parallel_state.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/utils.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/__init__.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/enums.py -> build/lib/apex/transformer\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/fused_dense\n",
            "  copying apex/fused_dense/fused_dense.py -> build/lib/apex/fused_dense\n",
            "  copying apex/fused_dense/__init__.py -> build/lib/apex/fused_dense\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_bert.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/arguments.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_gpt.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/global_vars.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/__init__.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/commons.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/distributed_test_base.py -> build/lib/apex/transformer/testing\n",
            "  creating build/lib/apex/transformer/functional\n",
            "  copying apex/transformer/functional/fused_softmax.py -> build/lib/apex/transformer/functional\n",
            "  copying apex/transformer/functional/__init__.py -> build/lib/apex/transformer/functional\n",
            "  creating build/lib/apex/transformer/amp\n",
            "  copying apex/transformer/amp/__init__.py -> build/lib/apex/transformer/amp\n",
            "  copying apex/transformer/amp/grad_scaler.py -> build/lib/apex/transformer/amp\n",
            "  creating build/lib/apex/transformer/layers\n",
            "  copying apex/transformer/layers/__init__.py -> build/lib/apex/transformer/layers\n",
            "  copying apex/transformer/layers/layer_norm.py -> build/lib/apex/transformer/layers\n",
            "  creating build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/utils.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  creating build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/data.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/random.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/mappings.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/utils.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/memory.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/layers.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/__init__.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  creating build/lib/apex/transformer/_data\n",
            "  copying apex/transformer/_data/_batchsampler.py -> build/lib/apex/transformer/_data\n",
            "  copying apex/transformer/_data/__init__.py -> build/lib/apex/transformer/_data\n",
            "  creating build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  creating build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/permutation_lib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "  creating build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  creating build/lib/apex/contrib/cudnn_gbn\n",
            "  copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib/apex/contrib/cudnn_gbn\n",
            "  copying apex/contrib/cudnn_gbn/__init__.py -> build/lib/apex/contrib/cudnn_gbn\n",
            "  creating build/lib/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_memory.py -> build/lib/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/__init__.py -> build/lib/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib/apex/contrib/peer_memory\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  creating build/lib/apex/contrib/clip_grad\n",
            "  copying apex/contrib/clip_grad/clip_grad.py -> build/lib/apex/contrib/clip_grad\n",
            "  copying apex/contrib/clip_grad/__init__.py -> build/lib/apex/contrib/clip_grad\n",
            "  creating build/lib/apex/contrib/test\n",
            "  copying apex/contrib/test/__init__.py -> build/lib/apex/contrib/test\n",
            "  creating build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
            "  creating build/lib/apex/contrib/index_mul_2d\n",
            "  copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib/apex/contrib/index_mul_2d\n",
            "  copying apex/contrib/index_mul_2d/__init__.py -> build/lib/apex/contrib/index_mul_2d\n",
            "  creating build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  creating build/lib/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/focal_loss.py -> build/lib/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/__init__.py -> build/lib/apex/contrib/focal_loss\n",
            "  creating build/lib/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib/apex/contrib/conv_bias_relu\n",
            "  creating build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/_transducer_ref.py -> build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
            "  creating build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
            "  creating build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  creating build/lib/apex/contrib/test/layer_norm\n",
            "  copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib/apex/contrib/test/layer_norm\n",
            "  copying apex/contrib/test/layer_norm/__init__.py -> build/lib/apex/contrib/test/layer_norm\n",
            "  creating build/lib/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/__init__.py -> build/lib/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib/apex/contrib/test/optimizers\n",
            "  creating build/lib/apex/contrib/test/cudnn_gbn\n",
            "  copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib/apex/contrib/test/cudnn_gbn\n",
            "  copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib/apex/contrib/test/cudnn_gbn\n",
            "  creating build/lib/apex/contrib/test/peer_memory\n",
            "  copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib/apex/contrib/test/peer_memory\n",
            "  copying apex/contrib/test/peer_memory/__init__.py -> build/lib/apex/contrib/test/peer_memory\n",
            "  creating build/lib/apex/contrib/test/xentropy\n",
            "  copying apex/contrib/test/xentropy/__init__.py -> build/lib/apex/contrib/test/xentropy\n",
            "  copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib/apex/contrib/test/xentropy\n",
            "  creating build/lib/apex/contrib/test/clip_grad\n",
            "  copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib/apex/contrib/test/clip_grad\n",
            "  copying apex/contrib/test/clip_grad/__init__.py -> build/lib/apex/contrib/test/clip_grad\n",
            "  creating build/lib/apex/contrib/test/bottleneck\n",
            "  copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib/apex/contrib/test/bottleneck\n",
            "  copying apex/contrib/test/bottleneck/__init__.py -> build/lib/apex/contrib/test/bottleneck\n",
            "  creating build/lib/apex/contrib/test/index_mul_2d\n",
            "  copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib/apex/contrib/test/index_mul_2d\n",
            "  copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib/apex/contrib/test/index_mul_2d\n",
            "  creating build/lib/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/__init__.py -> build/lib/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib/apex/contrib/test/multihead_attn\n",
            "  creating build/lib/apex/contrib/test/focal_loss\n",
            "  copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib/apex/contrib/test/focal_loss\n",
            "  copying apex/contrib/test/focal_loss/__init__.py -> build/lib/apex/contrib/test/focal_loss\n",
            "  creating build/lib/apex/contrib/test/conv_bias_relu\n",
            "  copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib/apex/contrib/test/conv_bias_relu\n",
            "  copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib/apex/contrib/test/conv_bias_relu\n",
            "  creating build/lib/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/__init__.py -> build/lib/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib/apex/contrib/test/transducer\n",
            "  creating build/lib/apex/contrib/test/fmha\n",
            "  copying apex/contrib/test/fmha/test_fmha.py -> build/lib/apex/contrib/test/fmha\n",
            "  copying apex/contrib/test/fmha/__init__.py -> build/lib/apex/contrib/test/fmha\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  copying build/lib/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  copying build/lib/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
            "  copying build/lib/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
            "  copying build/lib/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
            "  copying build/lib/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  copying build/lib/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  copying build/lib/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
            "  copying build/lib/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
            "  copying build/lib/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
            "  copying build/lib/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
            "  copying build/lib/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
            "  copying build/lib/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
            "  copying build/lib/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
            "  copying build/lib/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
            "  copying build/lib/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
            "  copying build/lib/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
            "  copying build/lib/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
            "  copying build/lib/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
            "  copying build/lib/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
            "  copying build/lib/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
            "  copying build/lib/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
            "  copying build/lib/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
            "  copying build/lib/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
            "  copying build/lib/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
            "  copying build/lib/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
            "  copying build/lib/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
            "  copying build/lib/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
            "  copying build/lib/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
            "  copying build/lib/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
            "  copying build/lib/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
            "  copying build/lib/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
            "  copying build/lib/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  copying build/lib/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  copying build/lib/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  copying build/lib/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
            "  copying build/lib/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
            "  copying build/lib/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
            "  copying build/lib/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
            "  copying build/lib/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  copying build/lib/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  copying build/lib/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  copying build/lib/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  copying build/lib/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  reading manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-8b5akydn/apex-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/_autocast_utils.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
            "  adding 'apex/contrib/bottleneck/halo_exchangers.py'\n",
            "  adding 'apex/contrib/bottleneck/test.py'\n",
            "  adding 'apex/contrib/clip_grad/__init__.py'\n",
            "  adding 'apex/contrib/clip_grad/clip_grad.py'\n",
            "  adding 'apex/contrib/conv_bias_relu/__init__.py'\n",
            "  adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'\n",
            "  adding 'apex/contrib/cudnn_gbn/__init__.py'\n",
            "  adding 'apex/contrib/cudnn_gbn/batch_norm.py'\n",
            "  adding 'apex/contrib/fmha/__init__.py'\n",
            "  adding 'apex/contrib/fmha/fmha.py'\n",
            "  adding 'apex/contrib/focal_loss/__init__.py'\n",
            "  adding 'apex/contrib/focal_loss/focal_loss.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/index_mul_2d/__init__.py'\n",
            "  adding 'apex/contrib/index_mul_2d/index_mul_2d.py'\n",
            "  adding 'apex/contrib/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/peer_memory/__init__.py'\n",
            "  adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'\n",
            "  adding 'apex/contrib/peer_memory/peer_memory.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_lib.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/channel_swap.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n",
            "  adding 'apex/contrib/test/__init__.py'\n",
            "  adding 'apex/contrib/test/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/test/bottleneck/test_bottleneck_module.py'\n",
            "  adding 'apex/contrib/test/clip_grad/__init__.py'\n",
            "  adding 'apex/contrib/test/clip_grad/test_clip_grad.py'\n",
            "  adding 'apex/contrib/test/conv_bias_relu/__init__.py'\n",
            "  adding 'apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py'\n",
            "  adding 'apex/contrib/test/cudnn_gbn/__init__.py'\n",
            "  adding 'apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'\n",
            "  adding 'apex/contrib/test/fmha/__init__.py'\n",
            "  adding 'apex/contrib/test/fmha/test_fmha.py'\n",
            "  adding 'apex/contrib/test/focal_loss/__init__.py'\n",
            "  adding 'apex/contrib/test/focal_loss/test_focal_loss.py'\n",
            "  adding 'apex/contrib/test/index_mul_2d/__init__.py'\n",
            "  adding 'apex/contrib/test/index_mul_2d/test_index_mul_2d.py'\n",
            "  adding 'apex/contrib/test/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/test/layer_norm/test_fast_layer_norm.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_mha_fused_softmax.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'\n",
            "  adding 'apex/contrib/test/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/test/optimizers/test_dist_adam.py'\n",
            "  adding 'apex/contrib/test/peer_memory/__init__.py'\n",
            "  adding 'apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py'\n",
            "  adding 'apex/contrib/test/transducer/__init__.py'\n",
            "  adding 'apex/contrib/test/transducer/test_transducer_joint.py'\n",
            "  adding 'apex/contrib/test/transducer/test_transducer_loss.py'\n",
            "  adding 'apex/contrib/test/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/test/xentropy/test_label_smoothing.py'\n",
            "  adding 'apex/contrib/transducer/__init__.py'\n",
            "  adding 'apex/contrib/transducer/_transducer_ref.py'\n",
            "  adding 'apex/contrib/transducer/transducer.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/fused_dense/__init__.py'\n",
            "  adding 'apex/fused_dense/fused_dense.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_mixed_precision_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/transformer/__init__.py'\n",
            "  adding 'apex/transformer/enums.py'\n",
            "  adding 'apex/transformer/log_util.py'\n",
            "  adding 'apex/transformer/microbatches.py'\n",
            "  adding 'apex/transformer/parallel_state.py'\n",
            "  adding 'apex/transformer/utils.py'\n",
            "  adding 'apex/transformer/_data/__init__.py'\n",
            "  adding 'apex/transformer/_data/_batchsampler.py'\n",
            "  adding 'apex/transformer/amp/__init__.py'\n",
            "  adding 'apex/transformer/amp/grad_scaler.py'\n",
            "  adding 'apex/transformer/functional/__init__.py'\n",
            "  adding 'apex/transformer/functional/fused_softmax.py'\n",
            "  adding 'apex/transformer/layers/__init__.py'\n",
            "  adding 'apex/transformer/layers/layer_norm.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/__init__.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/_timers.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/p2p_communication.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/utils.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/common.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n",
            "  adding 'apex/transformer/tensor_parallel/__init__.py'\n",
            "  adding 'apex/transformer/tensor_parallel/cross_entropy.py'\n",
            "  adding 'apex/transformer/tensor_parallel/data.py'\n",
            "  adding 'apex/transformer/tensor_parallel/layers.py'\n",
            "  adding 'apex/transformer/tensor_parallel/mappings.py'\n",
            "  adding 'apex/transformer/tensor_parallel/memory.py'\n",
            "  adding 'apex/transformer/tensor_parallel/random.py'\n",
            "  adding 'apex/transformer/tensor_parallel/utils.py'\n",
            "  adding 'apex/transformer/testing/__init__.py'\n",
            "  adding 'apex/transformer/testing/arguments.py'\n",
            "  adding 'apex/transformer/testing/commons.py'\n",
            "  adding 'apex/transformer/testing/distributed_test_base.py'\n",
            "  adding 'apex/transformer/testing/global_vars.py'\n",
            "  adding 'apex/transformer/testing/standalone_bert.py'\n",
            "  adding 'apex/transformer/testing/standalone_gpt.py'\n",
            "  adding 'apex/transformer/testing/standalone_transformer_lm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate maskrcnn_benchmark &&\n",
        "#export CUDA_HOME=/usr/local/cuda-10.1\n",
        "#rm -Rf apex\n",
        "#git clone https://github.com/NVIDIA/apex\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/apex\n",
        "pip install -v --disable-pip-version-check --no-cache-dir ./\n",
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5d3sFI2ACgl4",
        "outputId": "add80448-3efe-4799-a515-5fc82018bf25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "writing vilbert_multi_task.egg-info/PKG-INFO\n",
            "writing dependency_links to vilbert_multi_task.egg-info/dependency_links.txt\n",
            "writing top-level names to vilbert_multi_task.egg-info/top_level.txt\n",
            "reading manifest file 'vilbert_multi_task.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'vilbert_multi_task.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages/vilbert-multi-task.egg-link (link to .)\n",
            "Adding vilbert-multi-task 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vilbert-multi-task\n",
            "Processing dependencies for vilbert-multi-task==0.1.0\n",
            "Finished processing dependencies for vilbert-multi-task==0.1.0\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "#rm -Rf vilbert-multi-task\n",
        "#git clone --recursive https://github.com/facebookresearch/vilbert-multi-task.git\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vilbert-multi-task\n",
        "python setup.py develop\n",
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R4FZuFJyAxH5"
      },
      "outputs": [],
      "source": [
        "#Object detection model import\n",
        "#%%bash\n",
        "#source activate maskrcnn_benchmark && \n",
        "#cd vilbert-multi-task/data/\n",
        "#wget https://dl.fbaipublicfiles.com/vilbert-multi-task/detectron_model.pth\n",
        "#wget https://dl.fbaipublicfiles.com/vilbert-multi-task/detectron_config.yaml\n",
        "#cd ..\n",
        "#cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O72FEubxFJCu",
        "outputId": "47bf7118-ad53-4713-8f1c-10e0d119cfa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "running develop\n",
            "running egg_info\n",
            "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
            "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
            "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
            "reading manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.6/maskrcnn_benchmark/_C.cpython-36m-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
            "Creating /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages/maskrcnn-benchmark.egg-link (link to .)\n",
            "Adding maskrcnn-benchmark 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vqa-maskrcnn-benchmark\n",
            "Processing dependencies for maskrcnn-benchmark==0.1\n",
            "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
          ]
        }
      ],
      "source": [
        "#The old version of RCNN\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark\n",
        "#rm -Rf vqa-maskrcnn-benchmark\n",
        "#git clone https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark.git\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vqa-maskrcnn-benchmark\n",
        "# Compile custom layers and build rcnn backbone\n",
        "python setup.py build\n",
        "python setup.py develop\n",
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mzgthx8EG9yj",
        "outputId": "041b1691-3ccc-477d-8777-d2ee82be331d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.5.1\n",
            "  Downloading tensorflow-2.5.1-cp37-cp37m-manylinux2010_x86_64.whl (454.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 454.4/454.4 MB 3.0 MB/s eta 0:00:00\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 15.0 MB/s eta 0:00:00\n",
            "Collecting six~=1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 4.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.5.1) (0.37.1)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta~=0.2\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 7.1 MB/s eta 0:00:00\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.8/14.8 MB 55.7 MB/s eta 0:00:00\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 54.5 MB/s eta 0:00:00\n",
            "Collecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.0/4.0 MB 70.5 MB/s eta 0:00:00\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.0/4.0 MB 72.3 MB/s eta 0:00:00\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting astunparse~=1.6.3\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting protobuf>=3.9.2\n",
            "  Downloading protobuf-4.21.6-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 408.4/408.4 kB 34.4 MB/s eta 0:00:00\n",
            "Collecting opt-einsum~=3.3.0\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 7.3 MB/s eta 0:00:00\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 462.4/462.4 kB 36.6 MB/s eta 0:00:00\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 68.7 MB/s eta 0:00:00\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 11.0 MB/s eta 0:00:00\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.11.1-py2.py3-none-any.whl (167 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.1/167.1 kB 19.7 MB/s eta 0:00:00\n",
            "Collecting protobuf>=3.9.2\n",
            "  Downloading protobuf-3.19.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 52.0 MB/s eta 0:00:00\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (2.28.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 65.6 MB/s eta 0:00:00\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 kB 23.3 MB/s eta 0:00:00\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 45.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.1) (63.4.1)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 16.7 MB/s eta 0:00:00\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.1) (2022.9.14)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 9.3 MB/s eta 0:00:00\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 17.1 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=19a5d32f088b9a5c5797a5d38acd29fa9f49e734501499db8ead24b6da42e35b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for wrapt (setup.py): started\n",
            "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70822 sha256=08ead28517e31581bc28017ff6c8de8d0baa7eb0a6dbc1973331f934bad9c891\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, pyasn1, keras-nightly, flatbuffers, cached-property, zipp, tensorboard-data-server, six, rsa, pyasn1-modules, protobuf, oauthlib, numpy, MarkupSafe, gast, cachetools, werkzeug, requests-oauthlib, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, absl-py, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "Successfully installed MarkupSafe-2.1.1 absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.11.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 importlib-metadata-4.12.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.4.1 numpy-1.19.5 oauthlib-3.2.1 opt-einsum-3.3.0 protobuf-3.19.5 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 six-1.15.0 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.5.1 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-2.2.2 wrapt-1.12.1 zipp-3.8.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "# Error fixed with \"--default-timeout=100\"\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "sudo pip install --default-timeout=100 tensorflow==2.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "buYJeROyHHts",
        "outputId": "e3feee79-b697-490f-b6c8-fd58da1001c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting certifi\n",
            "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
            "Installing collected packages: certifi\n",
            "Successfully installed certifi-2022.9.24\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-transformers==1.0.0\n",
            "  Downloading pytorch_transformers-1.0.0-py3-none-any.whl (137 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from pytorch-transformers==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from pytorch-transformers==1.0.0) (1.19.2)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.23.10-py3-none-any.whl (132 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from pytorch-transformers==1.0.0) (4.19.9)\n",
            "Collecting regex\n",
            "  Downloading regex-2022.9.13-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (756 kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.27.0,>=1.26.10\n",
            "  Downloading botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3->pytorch-transformers==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.10->boto3->pytorch-transformers==1.0.0) (1.16.0)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from requests->pytorch-transformers==1.0.0) (2022.9.24)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, idna, charset-normalizer, sentencepiece, requests, regex, boto3, pytorch-transformers\n",
            "Successfully installed boto3-1.23.10 botocore-1.26.10 charset-normalizer-2.0.12 idna-3.4 jmespath-0.10.0 pytorch-transformers-1.0.0 regex-2022.9.13 requests-2.27.1 s3transfer-0.5.2 sentencepiece-0.1.97 urllib3-1.26.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "#Certifi version ignored\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "pip install certifi --ignore-installed\n",
        "pip install pytorch-transformers==1.0.0  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C8-kkyAPH4IH",
        "outputId": "7407babc-0c92-42b7-bc12-c2b9c052c85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.19.2 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (1.19.2)\n",
            "Collecting lmdb==0.94\n",
            "  Downloading lmdb-0.94.tar.gz (4.0 MB)\n",
            "Collecting tensorboardX==1.2\n",
            "  Downloading tensorboardX-1.2-py2.py3-none-any.whl (44 kB)\n",
            "Collecting tensorpack==0.9.4\n",
            "  Downloading tensorpack-0.9.4-py2.py3-none-any.whl (273 kB)\n",
            "Requirement already satisfied: tqdm==4.19.9 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (4.19.9)\n",
            "Collecting easydict==1.9\n",
            "  Downloading easydict-1.9.tar.gz (6.4 kB)\n",
            "Collecting PyYAML==5.4\n",
            "  Downloading PyYAML-5.4-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n",
            "Collecting jsonlines==1.2.0\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting json-lines==0.5.0\n",
            "  Downloading json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (3.3.4)\n",
            "Requirement already satisfied: Cython in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (0.29.32)\n",
            "Collecting msgpack\n",
            "  Downloading msgpack-1.0.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "Collecting msgpack-numpy\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting opencv-python==4.2.0.34\n",
            "  Downloading opencv_python-4.2.0.34-cp36-cp36m-manylinux1_x86_64.whl (28.2 MB)\n",
            "Collecting protobuf>=0.3.2\n",
            "  Downloading protobuf-3.19.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: six in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from tensorboardX==1.2) (1.16.0)\n",
            "Collecting tabulate>=0.7.7\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Collecting termcolor>=1.1\n",
            "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting pyzmq>=16\n",
            "  Downloading pyzmq-24.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from matplotlib) (8.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages (from matplotlib) (3.0.9)\n",
            "Building wheels for collected packages: lmdb, easydict, termcolor\n",
            "  Building wheel for lmdb (setup.py): started\n",
            "  Building wheel for lmdb (setup.py): finished with status 'done'\n",
            "  Created wheel for lmdb: filename=lmdb-0.94-cp36-cp36m-linux_x86_64.whl size=275172 sha256=f50049c2d2816e4c9f6190e6fbabc0168a2e6e03de0f89ac7f0544587a46c17e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/07/6a/dbf21232c94c3e174c73fc1647777bda92f8b210a02dab6ce7\n",
            "  Building wheel for easydict (setup.py): started\n",
            "  Building wheel for easydict (setup.py): finished with status 'done'\n",
            "  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6361 sha256=45d6d25a54194c9ac7a1d00c80050e4e12e20a9455ebcac2034e8bd36648e175\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/79/e4/4e55effe206295359b37e0f9db3e68a1197ba396682807dadb\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=633146a568426190b333eb389ee28aefc997ca02529d1174268922ce719f48d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "Successfully built lmdb easydict termcolor\n",
            "Installing collected packages: msgpack, termcolor, tabulate, pyzmq, protobuf, msgpack-numpy, tensorpack, tensorboardX, PyYAML, opencv-python, lmdb, jsonlines, json-lines, easydict\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.6.0.66\n",
            "    Uninstalling opencv-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-4.6.0.66\n",
            "Successfully installed PyYAML-5.4 easydict-1.9 json-lines-0.5.0 jsonlines-1.2.0 lmdb-0.94 msgpack-1.0.4 msgpack-numpy-0.4.8 opencv-python-4.2.0.34 protobuf-3.19.5 pyzmq-24.0.1 tabulate-0.8.10 tensorboardX-1.2 tensorpack-0.9.4 termcolor-1.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "pip install numpy==1.19.2 lmdb==0.94 tensorboardX==1.2  tensorpack==0.9.4 tqdm==4.19.9 easydict==1.9 PyYAML==5.4 jsonlines==1.2.0 json-lines==0.5.0 matplotlib Cython msgpack msgpack-numpy opencv-python==4.2.0.34  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zZyVsbnAIG6r",
        "outputId": "4ae6d22a-ba6a-468d-f0c0-8d223a8b822a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python3.6-dev is already the newest version (3.6.9-1~18.04ubuntu1.8).\n",
            "python3.6-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libcap-dev python3-pkg-resources python3-setuptools\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 370 kB of archives.\n",
            "After this operation, 1,944 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcap-dev amd64 1:2.25-1.2 [23.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Fetched 370 kB in 2s (207 kB/s)\n",
            "Selecting previously unselected package libcap-dev:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157604 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libcap-dev_1%3a2.25-1.2_amd64.deb ...\r\n",
            "Unpacking libcap-dev:amd64 (1:2.25-1.2) ...\r\n",
            "Selecting previously unselected package python3-pkg-resources.\r\n",
            "Preparing to unpack .../python3-pkg-resources_39.0.1-2_all.deb ...\r\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\r\n",
            "Selecting previously unselected package python3-setuptools.\r\n",
            "Preparing to unpack .../python3-setuptools_39.0.1-2_all.deb ...\r\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\r\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\r\n",
            "Setting up libcap-dev:amd64 (1:2.25-1.2) ...\r\n",
            "Setting up python3-setuptools (39.0.1-2) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n",
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing python_prctl.egg-info/PKG-INFO\n",
            "writing dependency_links to python_prctl.egg-info/dependency_links.txt\n",
            "writing top-level names to python_prctl.egg-info/top_level.txt\n",
            "reading manifest file 'python_prctl.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'COPYING'\n",
            "writing manifest file 'python_prctl.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "running build_ext\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/prctl.py -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/_prctl.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "byte-compiling build/bdist.linux-x86_64/egg/prctl.py to prctl.cpython-36.pyc\n",
            "creating stub loader for _prctl.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/_prctl.py to _prctl.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying python_prctl.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying python_prctl.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying python_prctl.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying python_prctl.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating 'dist/python_prctl-1.8.1-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing python_prctl-1.8.1-py3.6-linux-x86_64.egg\n",
            "creating /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages/python_prctl-1.8.1-py3.6-linux-x86_64.egg\n",
            "Extracting python_prctl-1.8.1-py3.6-linux-x86_64.egg to /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages\n",
            "Adding python-prctl 1.8.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/envs/maskrcnn_benchmark/lib/python3.6/site-packages/python_prctl-1.8.1-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for python-prctl==1.8.1\n",
            "Finished processing dependencies for python-prctl==1.8.1\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following packages will be REMOVED:\n",
            "  libnvidia-common-460\n",
            "0 upgraded, 0 newly installed, 1 to remove and 20 not upgraded.\n",
            "After this operation, 35.8 kB disk space will be freed.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157751 files and directories currently installed.)\r\n",
            "Removing libnvidia-common-460 (460.106.00-0ubuntu1) ...\r\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "Calculating upgrade...\n",
            "The following packages have been kept back:\n",
            "  libcudnn8 libcudnn8-dev libnccl-dev libnccl2\n",
            "The following packages will be upgraded:\n",
            "  dpkg e2fsprogs gnupg2 libc-bin libcom-err2 libcublas-dev libcublas10\n",
            "  libcudnn7 libcudnn7-dev libext2fs2 libgnutls30 libss2 linux-libc-dev login\n",
            "  openssl passwd\n",
            "16 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 446 MB of archives.\n",
            "After this operation, 69.7 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas10 10.2.3.254-1 [43.1 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 dpkg amd64 1.19.0.5ubuntu2.4 [1,137 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev 10.2.3.254-1 [42.4 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libcudnn7-dev 7.6.5.32-1+cuda10.2 [165 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libext2fs2 amd64 1.44.1-1ubuntu1.4 [156 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 e2fsprogs amd64 1.44.1-1ubuntu1.4 [390 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 login amd64 1:4.5-1ubuntu2.3 [307 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc-bin amd64 2.27-3ubuntu1.6 [640 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcom-err2 amd64 1.44.1-1ubuntu1.4 [8,696 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libss2 amd64 1.44.1-1ubuntu1.4 [11.2 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 passwd amd64 1:4.5-1ubuntu2.3 [818 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgnutls30 amd64 3.5.18-1ubuntu1.6 [646 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssl amd64 1.1.1-1ubuntu2.1~18.04.20 [614 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 linux-libc-dev amd64 4.15.0-193.204 [985 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gnupg2 all 2.2.4-1ubuntu1.6 [5,300 B]\n",
            "Get:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libcudnn7 7.6.5.32-1+cuda10.2 [189 MB]\n",
            "Fetched 446 MB in 8s (56.3 MB/s)\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../dpkg_1.19.0.5ubuntu2.4_amd64.deb ...\r\n",
            "Unpacking dpkg (1.19.0.5ubuntu2.4) over (1.19.0.5ubuntu2.3) ...\r\n",
            "Setting up dpkg (1.19.0.5ubuntu2.4) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libext2fs2_1.44.1-1ubuntu1.4_amd64.deb ...\r\n",
            "Unpacking libext2fs2:amd64 (1.44.1-1ubuntu1.4) over (1.44.1-1ubuntu1.3) ...\r\n",
            "Setting up libext2fs2:amd64 (1.44.1-1ubuntu1.4) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../e2fsprogs_1.44.1-1ubuntu1.4_amd64.deb ...\r\n",
            "Unpacking e2fsprogs (1.44.1-1ubuntu1.4) over (1.44.1-1ubuntu1.3) ...\r\n",
            "Setting up e2fsprogs (1.44.1-1ubuntu1.4) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../login_1%3a4.5-1ubuntu2.3_amd64.deb ...\r\n",
            "Unpacking login (1:4.5-1ubuntu2.3) over (1:4.5-1ubuntu2.2) ...\r\n",
            "Setting up login (1:4.5-1ubuntu2.3) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libc-bin_2.27-3ubuntu1.6_amd64.deb ...\r\n",
            "Unpacking libc-bin (2.27-3ubuntu1.6) over (2.27-3ubuntu1.5) ...\r\n",
            "Setting up libc-bin (2.27-3ubuntu1.6) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libcom-err2_1.44.1-1ubuntu1.4_amd64.deb ...\r\n",
            "Unpacking libcom-err2:amd64 (1.44.1-1ubuntu1.4) over (1.44.1-1ubuntu1.3) ...\r\n",
            "Setting up libcom-err2:amd64 (1.44.1-1ubuntu1.4) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libss2_1.44.1-1ubuntu1.4_amd64.deb ...\r\n",
            "Unpacking libss2:amd64 (1.44.1-1ubuntu1.4) over (1.44.1-1ubuntu1.3) ...\r\n",
            "Setting up libss2:amd64 (1.44.1-1ubuntu1.4) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../passwd_1%3a4.5-1ubuntu2.3_amd64.deb ...\r\n",
            "Unpacking passwd (1:4.5-1ubuntu2.3) over (1:4.5-1ubuntu2.2) ...\r\n",
            "Setting up passwd (1:4.5-1ubuntu2.3) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libgnutls30_3.5.18-1ubuntu1.6_amd64.deb ...\r\n",
            "Unpacking libgnutls30:amd64 (3.5.18-1ubuntu1.6) over (3.5.18-1ubuntu1.5) ...\r\n",
            "Setting up libgnutls30:amd64 (3.5.18-1ubuntu1.6) ...\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 157746 files and directories currently installed.)\r\n",
            "Preparing to unpack .../0-openssl_1.1.1-1ubuntu2.1~18.04.20_amd64.deb ...\r\n",
            "Unpacking openssl (1.1.1-1ubuntu2.1~18.04.20) over (1.1.1-1ubuntu2.1~18.04.17) ...\r\n",
            "Preparing to unpack .../1-libcublas10_10.2.3.254-1_amd64.deb ...\r\n",
            "Unpacking libcublas10 (10.2.3.254-1) over (10.2.1.243-1) ...\r\n",
            "Preparing to unpack .../2-libcublas-dev_10.2.3.254-1_amd64.deb ...\r\n",
            "Unpacking libcublas-dev (10.2.3.254-1) over (10.2.1.243-1) ...\r\n",
            "Preparing to unpack .../3-libcudnn7-dev_7.6.5.32-1+cuda10.2_amd64.deb ...\r\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\r\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v8.h to provide /usr/include/cudnn.h (libcudnn) in auto mode\r\n",
            "Unpacking libcudnn7-dev (7.6.5.32-1+cuda10.2) over (7.6.5.32-1+cuda10.1) ...\r\n",
            "Preparing to unpack .../4-libcudnn7_7.6.5.32-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libcudnn7 (7.6.5.32-1+cuda10.2) over (7.6.5.32-1+cuda10.1) ...\r\n",
            "Preparing to unpack .../5-linux-libc-dev_4.15.0-193.204_amd64.deb ...\r\n",
            "Unpacking linux-libc-dev:amd64 (4.15.0-193.204) over (4.15.0-180.189) ...\r\n",
            "Preparing to unpack .../6-gnupg2_2.2.4-1ubuntu1.6_all.deb ...\r\n",
            "Unpacking gnupg2 (2.2.4-1ubuntu1.6) over (2.2.4-1ubuntu1.4) ...\r\n",
            "Setting up libcudnn7 (7.6.5.32-1+cuda10.2) ...\r\n",
            "Setting up linux-libc-dev:amd64 (4.15.0-193.204) ...\r\n",
            "Setting up libcudnn7-dev (7.6.5.32-1+cuda10.2) ...\r\n",
            "update-alternatives: using /usr/include/x86_64-linux-gnu/cudnn_v7.h to provide /usr/include/cudnn.h (libcudnn) in manual mode\r\n",
            "Setting up gnupg2 (2.2.4-1ubuntu1.6) ...\r\n",
            "Setting up libcublas10 (10.2.3.254-1) ...\r\n",
            "Setting up libcublas-dev (10.2.3.254-1) ...\r\n",
            "Setting up openssl (1.1.1-1ubuntu2.1~18.04.20) ...\r\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__._prctl.cpython-36: module references __file__\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n"
          ]
        }
      ],
      "source": [
        "# Installation error fixed\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark && \n",
        "apt-get install python3.6-dev libcap-dev python3-setuptools \n",
        "#rm -Rf python-prctl\n",
        "#git clone http://github.com/seveas/python-prctl \n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/python-prctl \n",
        "python setup.py build \n",
        "python setup.py install \n",
        "sudo apt-get autoremove\n",
        "sudo apt-get upgrade\n",
        "cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgia-Ua1kDnV"
      },
      "source": [
        "# Second environment for vilbert features extraction and classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a3RpCBqXlFzE",
        "outputId": "d8355c12-31ee-43c5-ac97-f93579bd6e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pysocks-1.7.1        | 31 KB     | : 100% 1.0/1 [00:00<00:00, 14.96it/s]\n",
            "libgcc-ng-9.1.0      | 5.1 MB    | : 100% 1.0/1 [00:00<00:00,  4.98it/s]\n",
            "pillow-8.1.0         | 626 KB    | : 100% 1.0/1 [00:00<00:00, 13.25it/s]\n",
            "setuptools-51.1.2    | 730 KB    | : 100% 1.0/1 [00:00<00:00, 11.42it/s]\n",
            "click-7.1.2          | 71 KB     | : 100% 1.0/1 [00:00<00:00, 20.18it/s]\n",
            "ninja-1.10.2         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00, 11.20it/s]\n",
            "xz-5.2.5             | 341 KB    | : 100% 1.0/1 [00:00<00:00, 15.37it/s]\n",
            "libuv-1.40.0         | 736 KB    | : 100% 1.0/1 [00:00<00:00, 16.54it/s]\n",
            "freetype-2.10.4      | 596 KB    | : 100% 1.0/1 [00:00<00:00, 14.53it/s]\n",
            "python_abi-3.6       | 4 KB      | : 100% 1.0/1 [00:01<00:00,  1.30s/it]\n",
            "tokenizers-0.9.4     | 2.7 MB    | : 100% 1.0/1 [00:03<00:00,  3.41s/it]\n",
            "tqdm-4.55.1          | 77 KB     | : 100% 1.0/1 [00:00<00:00, 19.20it/s]\n",
            "zstd-1.4.5           | 619 KB    | : 100% 1.0/1 [00:00<00:00, 15.07it/s]\n",
            "readline-8.0         | 356 KB    | : 100% 1.0/1 [00:00<00:00, 16.38it/s]\n",
            "wheel-0.36.2         | 33 KB     | : 100% 1.0/1 [00:00<00:00, 23.45it/s]\n",
            "jpeg-9b              | 214 KB    | : 100% 1.0/1 [00:00<00:00, 21.33it/s]\n",
            "intel-openmp-2020.2  | 786 KB    | : 100% 1.0/1 [00:00<00:00, 16.15it/s]\n",
            "protobuf-3.13.0.1    | 633 KB    | : 100% 1.0/1 [00:00<00:00, 12.12it/s]\n",
            "python-3.6.12        | 29.7 MB   | : 100% 1.0/1 [00:00<00:00,  1.19it/s]               \n",
            "cffi-1.14.4          | 223 KB    | : 100% 1.0/1 [00:00<00:00, 16.47it/s]\n",
            "urllib3-1.26.2       | 105 KB    | : 100% 1.0/1 [00:00<00:00, 19.70it/s]\n",
            "libtiff-4.1.0        | 449 KB    | : 100% 1.0/1 [00:00<00:00, 13.73it/s]\n",
            "certifi-2020.12.5    | 140 KB    | : 100% 1.0/1 [00:00<00:00, 15.96it/s]\n",
            "cryptography-3.3.1   | 557 KB    | : 100% 1.0/1 [00:00<00:00, 10.71it/s]\n",
            "six-1.15.0           | 27 KB     | : 100% 1.0/1 [00:00<00:00, 20.69it/s]\n",
            "openssl-1.1.1i       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  7.62it/s]\n",
            "libprotobuf-3.13.0.1 | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  8.61it/s]\n",
            "lcms2-2.11           | 307 KB    | : 100% 1.0/1 [00:00<00:00, 15.91it/s]\n",
            "chardet-4.0.0        | 199 KB    | : 100% 1.0/1 [00:00<00:00, 13.96it/s]\n",
            "lz4-c-1.9.2          | 175 KB    | : 100% 1.0/1 [00:00<00:00, 15.73it/s]\n",
            "idna-2.10            | 50 KB     | : 100% 1.0/1 [00:00<00:00, 19.99it/s]\n",
            "ca-certificates-2020 | 121 KB    | : 100% 1.0/1 [00:00<00:00, 20.20it/s]\n",
            "pip-20.3.3           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  5.58it/s]\n",
            "packaging-20.8       | 36 KB     | : 100% 1.0/1 [00:00<00:00, 20.18it/s]\n",
            "requests-2.25.1      | 52 KB     | : 100% 1.0/1 [00:00<00:00, 18.31it/s]\n",
            "regex-2020.11.13     | 318 KB    | : 100% 1.0/1 [00:00<00:00, 17.02it/s]\n",
            "dataclasses-0.7      | 30 KB     | : 100% 1.0/1 [00:00<00:00, 20.28it/s]\n",
            "pyopenssl-20.0.1     | 49 KB     | : 100% 1.0/1 [00:00<00:00, 22.01it/s]\n",
            "ncurses-6.2          | 817 KB    | : 100% 1.0/1 [00:00<00:00,  3.68it/s]\n",
            "pyparsing-2.4.7      | 65 KB     | : 100% 1.0/1 [00:00<00:00, 19.96it/s]\n",
            "libedit-3.1.20191231 | 116 KB    | : 100% 1.0/1 [00:00<00:00, 19.42it/s]\n",
            "tk-8.6.10            | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  6.40it/s]\n",
            "libstdcxx-ng-9.1.0   | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  7.70it/s]\n",
            "pytorch-1.7.1        | 575.6 MB  | : 100% 1.0/1 [01:19<00:00, 79.29s/it]               \n",
            "sacremoses-master    | 404 KB    | : 100% 1.0/1 [00:02<00:00,  2.30s/it]\n",
            "filelock-3.0.12      | 13 KB     | : 100% 1.0/1 [00:00<00:00, 14.56it/s]\n",
            "mkl_fft-1.2.0        | 149 KB    | : 100% 1.0/1 [00:00<00:00, 20.46it/s]\n",
            "ld_impl_linux-64-2.3 | 568 KB    | : 100% 1.0/1 [00:00<00:00, 16.39it/s]\n",
            "brotlipy-0.7.0       | 320 KB    | : 100% 1.0/1 [00:00<00:00, 18.60it/s]\n",
            "cudatoolkit-10.2.89  | 365.1 MB  | : 100% 1.0/1 [00:08<00:00,  8.17s/it]               \n",
            "pycparser-2.20       | 94 KB     | : 100% 1.0/1 [00:00<00:00,  2.44it/s]\n",
            "joblib-1.0.0         | 208 KB    | : 100% 1.0/1 [00:00<00:00, 10.62it/s]\n",
            "typing_extensions-3. | 28 KB     | : 100% 1.0/1 [00:00<00:00, 19.89it/s]\n",
            "sqlite-3.33.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 12.04it/s]\n",
            "torchvision-0.8.2    | 17.8 MB   | : 100% 1.0/1 [00:02<00:00,  2.52s/it]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Installing pip dependencies: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/myenv/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting appdirs==1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting beautifulsoup4==4.9.3\n",
            "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
            "Collecting blis==0.7.4\n",
            "  Downloading blis-0.7.4-cp36-cp36m-manylinux2014_x86_64.whl (9.8 MB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from blis==0.7.4->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 3)) (1.19.2)\n",
            "Collecting bs4==0.0.1\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "Collecting catalogue==1.0.0\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Collecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting contextvars==2.4\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: six in /usr/local/envs/myenv/lib/python3.6/site-packages (from cycler==0.10.0->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 8)) (1.15.0)\n",
            "Collecting cymem==2.0.5\n",
            "  Downloading cymem-2.0.5-cp36-cp36m-manylinux2014_x86_64.whl (35 kB)\n",
            "Collecting demoji==0.4.0\n",
            "  Downloading demoji-0.4.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from demoji==0.4.0->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 10)) (2.25.1)\n",
            "Collecting docx2txt==0.8\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Collecting ekphrasis==0.5.1\n",
            "  Downloading ekphrasis-0.5.1.tar.gz (80 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/envs/myenv/lib/python3.6/site-packages (from ekphrasis==0.5.1->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 12)) (4.55.1)\n",
            "Collecting emoji==1.1.0\n",
            "  Downloading emoji-1.1.0-py3-none-any.whl (132 kB)\n",
            "Collecting farasapy==0.0.11\n",
            "  Downloading farasapy-0.0.11-py3-none-any.whl (12 kB)\n",
            "Collecting ftfy==5.8\n",
            "  Downloading ftfy-5.8.tar.gz (64 kB)\n",
            "Collecting googletrans==4.0.0rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "Collecting h11==0.9.0\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "Collecting h2==3.2.0\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "Collecting hpack==3.0.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hstspreload==2020.12.22\n",
            "  Downloading hstspreload-2020.12.22-py3-none-any.whl (994 kB)\n",
            "Collecting httpcore==0.9.1\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/envs/myenv/lib/python3.6/site-packages (from httpx==0.13.3->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 22)) (2020.12.5)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/envs/myenv/lib/python3.6/site-packages (from httpx==0.13.3->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 22)) (2.10)\n",
            "Collecting hyperframe==5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting imagehash==4.2.0\n",
            "  Downloading ImageHash-4.2.0-py2.py3-none-any.whl (295 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/envs/myenv/lib/python3.6/site-packages (from imagehash==4.2.0->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 24)) (8.1.0)\n",
            "Collecting immutables==0.14\n",
            "  Downloading immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98 kB)\n",
            "Collecting jsonlines==2.0.0\n",
            "  Downloading jsonlines-2.0.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting kiwisolver==1.3.1\n",
            "  Using cached kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting langdetect==1.0.9\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "Collecting lifeeasy==2.3.3\n",
            "  Downloading lifeeasy-2.3.3-py3-none-any.whl (20 kB)\n",
            "Collecting lxml==4.6.3\n",
            "  Downloading lxml-4.6.3-cp36-cp36m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "Collecting matplotlib==3.3.3\n",
            "  Downloading matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (from matplotlib==3.3.3->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 32)) (2.4.7)\n",
            "Collecting murmurhash==1.0.5\n",
            "  Downloading murmurhash-1.0.5-cp36-cp36m-manylinux2014_x86_64.whl (20 kB)\n",
            "Collecting nltk==3.5\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "Requirement already satisfied: click in /usr/local/envs/myenv/lib/python3.6/site-packages (from nltk==3.5->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 34)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/envs/myenv/lib/python3.6/site-packages (from nltk==3.5->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 34)) (1.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/envs/myenv/lib/python3.6/site-packages (from nltk==3.5->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 34)) (2020.11.13)\n",
            "Collecting oauthlib==3.1.0\n",
            "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
            "Collecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
            "Collecting plac==1.1.3\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting preshed==3.0.5\n",
            "  Downloading preshed-3.0.5-cp36-cp36m-manylinux2014_x86_64.whl (126 kB)\n",
            "Collecting psutil==5.8.0\n",
            "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
            "Collecting pyarabic==0.6.10\n",
            "  Downloading PyArabic-0.6.10.tar.gz (108 kB)\n",
            "Collecting pyee==8.1.0\n",
            "  Downloading pyee-8.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting pygoogletranslation==2.0.6\n",
            "  Downloading pygoogletranslation-2.0.6-py3-none-any.whl (15 kB)\n",
            "Collecting pypdf2==1.26.0\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "Collecting pyppeteer==0.2.5\n",
            "  Downloading pyppeteer-0.2.5-py3-none-any.whl (87 kB)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/envs/myenv/lib/python3.6/site-packages (from pyppeteer==0.2.5->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 44)) (1.26.2)\n",
            "Collecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "Collecting pywavelets==1.1.1\n",
            "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
            "Collecting requests-oauthlib==1.3.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting rfc3986==1.4.0\n",
            "  Downloading rfc3986-1.4.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sarge==0.1.6\n",
            "  Downloading sarge-0.1.6.tar.gz (26 kB)\n",
            "Collecting scikit-learn==0.24.1\n",
            "  Downloading scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
            "Collecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "Collecting selenium==3.141.0\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "Collecting sentence-transformers==1.1.0\n",
            "  Downloading sentence-transformers-1.1.0.tar.gz (78 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from sentence-transformers==1.1.0->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 53)) (1.7.1)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting sentistrength==0.0.9\n",
            "  Downloading sentistrength-0.0.9-py3-none-any.whl (3.8 kB)\n",
            "Collecting sklearn==0.0\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Collecting sniffio==1.2.0\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting soupsieve==2.2.1\n",
            "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
            "Collecting spacy==2.3.5\n",
            "  Downloading spacy-2.3.5-cp36-cp36m-manylinux2014_x86_64.whl (10.4 MB)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.6/site-packages (from spacy==2.3.5->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 59)) (51.1.2.post20210112)\n",
            "Collecting srsly==1.0.5\n",
            "  Downloading srsly-1.0.5-cp36-cp36m-manylinux2014_x86_64.whl (184 kB)\n",
            "Collecting termcolor==1.1.0\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Collecting thinc==7.4.5\n",
            "  Downloading thinc-7.4.5-cp36-cp36m-manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting threadpoolctl==2.1.0\n",
            "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting transformers==4.2.2\n",
            "  Downloading transformers-4.2.2-py3-none-any.whl (1.8 MB)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==4.2.2->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 64)) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==4.2.2->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 64)) (20.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==4.2.2->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 64)) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/envs/myenv/lib/python3.6/site-packages/sacremoses-0.0.43-py3.8.egg (from transformers==4.2.2->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 64)) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==4.2.2->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 64)) (3.0.12)\n",
            "Collecting trectools==0.0.44\n",
            "  Downloading trectools-0.0.44.tar.gz (26 kB)\n",
            "Collecting tweepy==3.10.0\n",
            "  Downloading tweepy-3.10.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting tweet-preprocessor==0.6.0\n",
            "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
            "Collecting ujson==4.0.2\n",
            "  Downloading ujson-4.0.2-cp36-cp36m-manylinux1_x86_64.whl (179 kB)\n",
            "Collecting unidecode==1.1.2\n",
            "  Downloading Unidecode-1.1.2-py2.py3-none-any.whl (239 kB)\n",
            "Collecting uritools==3.0.0\n",
            "  Downloading uritools-3.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting urlextract==1.2.0\n",
            "  Downloading urlextract-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting wasabi==0.8.1\n",
            "  Downloading wasabi-0.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting wcwidth==0.2.5\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting websockets==8.1\n",
            "  Downloading websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78 kB)\n",
            "Collecting xlrd==2.0.1\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "Collecting zipp==3.4.0\n",
            "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting chardet==3.*\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-2.1.3-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pytz>=2017.2\n",
            "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests<3.0.0->demoji==0.4.0->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 10)) (1.7.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch>=1.6.0->sentence-transformers==1.1.0->-r /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/condaenv.qf01xeph.requirements.txt (line 53)) (3.7.4.3)\n",
            "Building wheels for collected packages: bs4, contextvars, docx2txt, ekphrasis, ftfy, googletrans, langdetect, nltk, pyarabic, pypdf2, sarge, sentence-transformers, sklearn, trectools\n",
            "  Building wheel for bs4 (setup.py): started\n",
            "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=60b8d9ea891cbac245b466c8eb5122d59c89d16f08cde72a1f1ec93a9676b1bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/6d/a97dd4f22376d4472d5f4c76c7646876052ff3166b3cf71050\n",
            "  Building wheel for contextvars (setup.py): started\n",
            "  Building wheel for contextvars (setup.py): finished with status 'done'\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=0a974ba757c380432bef7c2d4e1388a9f29d4278e7cb6a946c06626ebeb97720\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
            "  Building wheel for docx2txt (setup.py): started\n",
            "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3966 sha256=643bfdbeb16aa580cc2c41c3171bb40e72f8abd913c28ee1dc1224a16426c20a\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/d7/77/4dc0e151e2ef19b5474722fd943e312603f10016baab494f7a\n",
            "  Building wheel for ekphrasis (setup.py): started\n",
            "  Building wheel for ekphrasis (setup.py): finished with status 'done'\n",
            "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=82843 sha256=1c714b68ea46b7621964a050c583d72c4ae8cfc63bbf587b5c087fedcf26ff8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/80/3d/a326a4bc40633d1e10bce871e28e5e3ff4b4d0ea37cd0a0543\n",
            "  Building wheel for ftfy (setup.py): started\n",
            "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-py3-none-any.whl size=45613 sha256=9d80411d578e66a50d15d116b5b22f617bb049e1bf1921d400ac73d44e058781\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/35/f5/eb0a6ada2f64da8852637df14e12c7eb94f26c42546865d83d\n",
            "  Building wheel for googletrans (setup.py): started\n",
            "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17415 sha256=ee47288c92c8f02747bb82dd0e921d2060eb4c36d268d67bc170ba50aba78e4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/ef/55/d0c929bf03bc8b13c8164a1e00bce5065e0dc560d15f41e80c\n",
            "  Building wheel for langdetect (setup.py): started\n",
            "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=6cb34fdf8db53d516fa682c46785541e3949e29516707191b0d6668da2fc75e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/e8/62/ef79403841bab16f1c4260b967bee7fa579d78552a66c7f6e0\n",
            "  Building wheel for nltk (setup.py): started\n",
            "  Building wheel for nltk (setup.py): finished with status 'done'\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434677 sha256=a6b2bf8780154f6af4c20e621d3e5ddf414c96f42c086c19ac0c6f578bd9b7a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/5e/42/64abaeca668161c3e2cecc24f864a8fc421e3d07a104fc8a51\n",
            "  Building wheel for pyarabic (setup.py): started\n",
            "  Building wheel for pyarabic (setup.py): finished with status 'done'\n",
            "  Created wheel for pyarabic: filename=PyArabic-0.6.10-py3-none-any.whl size=113320 sha256=2fcc07522fd31d92f74536228f18b1732a7325a068ca3cb6b07484d0babd0577\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/3b/51/e20578be3b2654307323abde924015cfdddfe1962b509c1790\n",
            "  Building wheel for pypdf2 (setup.py): started\n",
            "  Building wheel for pypdf2 (setup.py): finished with status 'done'\n",
            "  Created wheel for pypdf2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61085 sha256=1cf36b95176be5fbff07afc1541fb10fe31b4e8f9ec55a00774568816837708e\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/28/4b/142b7d8c98eeeb73534b9c5b6558ddd3bab3c2c8192aa7ab30\n",
            "  Building wheel for sarge (setup.py): started\n",
            "  Building wheel for sarge (setup.py): finished with status 'done'\n",
            "  Created wheel for sarge: filename=sarge-0.1.6-py3-none-any.whl size=19050 sha256=85ec45ec9d8700cf9fc3b48980f4bb5244621585c4b0ee3983436723bb737f9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/48/be/0c948072252bb588087791593b789ea3c3fdd9050d1c3c06b4\n",
            "  Building wheel for sentence-transformers (setup.py): started\n",
            "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-py3-none-any.whl size=119616 sha256=89577b0a4043b61f108299c849ea5fd1fcd4c60a30d04a932c4e2d86a05a5215\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/fc/93/fa5873037e04b951ffd3fa8b768677e3d943db1cb6609c37bb\n",
            "  Building wheel for sklearn (setup.py): started\n",
            "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=b616ffe76e53e4609461466a9061db049863c0c362e5271848490e1ce830ebcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
            "  Building wheel for trectools (setup.py): started\n",
            "  Building wheel for trectools (setup.py): finished with status 'done'\n",
            "  Created wheel for trectools: filename=trectools-0.0.44-py3-none-any.whl size=26300 sha256=7a05bc6e408d0318962063716013cf24abfe00fc267a0685b52565e5721e5c24\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/a0/88/8994b1cf55228d084aab2e221bd770d4170a22e8003b1acdca\n",
            "Successfully built bs4 contextvars docx2txt ekphrasis ftfy googletrans langdetect nltk pyarabic pypdf2 sarge sentence-transformers sklearn trectools\n",
            "Installing collected packages: immutables, zipp, hyperframe, hpack, contextvars, soupsieve, sniffio, murmurhash, importlib-metadata, h2, h11, cymem, chardet, wcwidth, wasabi, threadpoolctl, srsly, scipy, rfc3986, pywavelets, pytz, python-dateutil, preshed, plac, oauthlib, kiwisolver, httpcore, hstspreload, cycler, catalogue, blis, beautifulsoup4, websockets, uritools, unidecode, ujson, transformers, thinc, termcolor, sentencepiece, scikit-learn, sarge, requests-oauthlib, pypdf2, pyee, psutil, pandas, nltk, matplotlib, lxml, imagehash, httpx, ftfy, docx2txt, colorama, bs4, appdirs, xlrd, urlextract, tweet-preprocessor, tweepy, trectools, spacy, sklearn, sentistrength, sentence-transformers, selenium, pyppeteer, pygoogletranslation, pyarabic, lifeeasy, langdetect, jsonlines, googletrans, farasapy, emoji, ekphrasis, demoji\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "Successfully installed appdirs-1.4.4 beautifulsoup4-4.9.3 blis-0.7.4 bs4-0.0.1 catalogue-1.0.0 chardet-3.0.4 colorama-0.4.4 contextvars-2.4 cycler-0.10.0 cymem-2.0.5 demoji-0.4.0 docx2txt-0.8 ekphrasis-0.5.1 emoji-1.1.0 farasapy-0.0.11 ftfy-5.8 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 imagehash-4.2.0 immutables-0.14 importlib-metadata-2.1.3 jsonlines-2.0.0 kiwisolver-1.3.1 langdetect-1.0.9 lifeeasy-2.3.3 lxml-4.6.3 matplotlib-3.3.3 murmurhash-1.0.5 nltk-3.5 oauthlib-3.1.0 pandas-1.1.5 plac-1.1.3 preshed-3.0.5 psutil-5.8.0 pyarabic-0.6.10 pyee-8.1.0 pygoogletranslation-2.0.6 pypdf2-1.26.0 pyppeteer-0.2.5 python-dateutil-2.8.1 pytz-2022.2.1 pywavelets-1.1.1 requests-oauthlib-1.3.0 rfc3986-1.4.0 sarge-0.1.6 scikit-learn-0.24.1 scipy-1.5.4 selenium-3.141.0 sentence-transformers-1.1.0 sentencepiece-0.1.95 sentistrength-0.0.9 sklearn-0.0 sniffio-1.2.0 soupsieve-2.2.1 spacy-2.3.5 srsly-1.0.5 termcolor-1.1.0 thinc-7.4.5 threadpoolctl-2.1.0 transformers-4.2.2 trectools-0.0.44 tweepy-3.10.0 tweet-preprocessor-0.6.0 ujson-4.0.2 unidecode-1.1.2 uritools-3.0.0 urlextract-1.2.0 wasabi-0.8.1 wcwidth-0.2.5 websockets-8.1 xlrd-2.0.1 zipp-3.4.0\n",
            "\n",
            "\b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ],
      "source": [
        "!conda env create -f /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/environment.yml python=3.6.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0JcDjeMvnuTs",
        "outputId": "f57c8f9a-7d06-456a-98ee-48370e24f4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                     /usr/local\n",
            "maskrcnn_benchmark       /usr/local/envs/maskrcnn_benchmark\n",
            "myenv                    /usr/local/envs/myenv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# New environment (myenv)\n",
        "!conda env list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u5aQ3r7k19pd",
        "outputId": "e636c422-d2ab-4692-d308-465f59cb6561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Cython\n",
            "  Using cached Cython-0.29.32-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (2.0 MB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/envs/myenv/lib/python3.6/site-packages (from h5py) (1.19.2)\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.3.0-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (297 kB)\n",
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/envs/myenv/lib/python3.6/site-packages (from pytorch-transformers) (4.55.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from pytorch-transformers) (1.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/envs/myenv/lib/python3.6/site-packages (from pytorch-transformers) (0.1.95)\n",
            "Requirement already satisfied: requests in /usr/local/envs/myenv/lib/python3.6/site-packages (from pytorch-transformers) (2.25.1)\n",
            "Requirement already satisfied: regex in /usr/local/envs/myenv/lib/python3.6/site-packages (from pytorch-transformers) (2020.11.13)\n",
            "Requirement already satisfied: sacremoses in /usr/local/envs/myenv/lib/python3.6/site-packages/sacremoses-0.0.43-py3.8.egg (from pytorch-transformers) (0.0.43)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch>=1.0.0->pytorch-transformers) (0.7)\n",
            "Collecting tensorpack\n",
            "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
            "Requirement already satisfied: six in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorpack) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorpack) (5.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorpack) (1.1.0)\n",
            "Collecting msgpack>=0.5.2\n",
            "  Using cached msgpack-1.0.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Using cached msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pyzmq>=16\n",
            "  Using cached pyzmq-24.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting tabulate>=0.7.7\n",
            "  Using cached tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Collecting tools\n",
            "  Downloading tools-0.1.9.tar.gz (34 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/envs/myenv/lib/python3.6/site-packages (from tools) (4.6.3)\n",
            "Collecting boto3\n",
            "  Using cached boto3-1.23.10-py3-none-any.whl (132 kB)\n",
            "Collecting botocore<1.27.0,>=1.26.10\n",
            "  Using cached botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/envs/myenv/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3->pytorch-transformers) (1.26.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3->pytorch-transformers) (2.8.1)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Using cached s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "Collecting cached-property\n",
            "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pytils\n",
            "  Downloading pytils-0.4.1.tar.gz (99 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "  Downloading pytils-0.4.0.tar.gz (91 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "  Downloading pytils-0.3.tar.gz (89 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->pytorch-transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/envs/myenv/lib/python3.6/site-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/envs/myenv/lib/python3.6/site-packages (from sacremoses->pytorch-transformers) (1.0.0)\n",
            "Building wheels for collected packages: tools, pytils\n",
            "  Building wheel for tools (setup.py): started\n",
            "  Building wheel for tools (setup.py): finished with status 'done'\n",
            "  Created wheel for tools: filename=tools-0.1.9-py3-none-any.whl size=46758 sha256=0d463b6a78a5362eceb7044da501af8442490c7fceea65971d147237ec6a5a45\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9a/1e/ce5202fe73d4c84cb5bf36dee0395adf42cf6ad5bd18d664fc\n",
            "  Building wheel for pytils (setup.py): started\n",
            "  Building wheel for pytils (setup.py): finished with status 'done'\n",
            "  Created wheel for pytils: filename=pytils-0.3-py3-none-any.whl size=40355 sha256=bf258d67f5b519365d7cefb067068891fccff1885bc318dc424cd185bf743434\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/40/b8/85d20ee26272520271c32f1324af2aeb382431d3115bacb2a1\n",
            "Successfully built tools pytils\n",
            "Installing collected packages: jmespath, botocore, s3transfer, msgpack, tabulate, pyzmq, pytils, msgpack-numpy, cached-property, boto3, tools, tensorpack, pytorch-transformers, lmdb, h5py, Cython\n",
            "Successfully installed Cython-0.29.32 boto3-1.23.10 botocore-1.26.10 cached-property-1.5.2 h5py-3.1.0 jmespath-0.10.0 lmdb-1.3.0 msgpack-1.0.4 msgpack-numpy-0.4.8 pytils-0.3 pytorch-transformers-1.2.0 pyzmq-24.0.1 s3transfer-0.5.2 tabulate-0.8.10 tensorpack-0.11 tools-0.1.9\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate myenv &&\n",
        "pip install h5py lmdb pytorch-transformers tensorpack tools Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ul0Ardce_kau",
        "outputId": "ab201ea7-03ea-4989-bcdf-44852cd01ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboardX) (3.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboardX) (1.19.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/envs/myenv/lib/python3.6/site-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.6/site-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (51.1.2.post20210112)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate myenv &&\n",
        "pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O0dr_LWoqVZq",
        "outputId": "c6c63e70-ba50-47ce-e60f-bce91f7aded5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wheel in /usr/local/envs/myenv/lib/python3.6/site-packages (0.36.2)\n",
            "Collecting thundersvm-cuda10.1==0.3.4\n",
            "  Downloading https://github.com/Xtra-Computing/thundersvm/releases/download/v0.3.4/thundersvm_cuda10.1-0.3.4-cp36-cp36m-linux_x86_64.whl (514 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/envs/myenv/lib/python3.6/site-packages (from thundersvm-cuda10.1==0.3.4) (1.5.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/envs/myenv/lib/python3.6/site-packages (from thundersvm-cuda10.1==0.3.4) (0.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.6/site-packages (from thundersvm-cuda10.1==0.3.4) (1.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from scikit-learn->thundersvm-cuda10.1==0.3.4) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/envs/myenv/lib/python3.6/site-packages (from scikit-learn->thundersvm-cuda10.1==0.3.4) (1.0.0)\n",
            "Installing collected packages: thundersvm-cuda10.1\n",
            "Successfully installed thundersvm-cuda10.1-0.3.4\n"
          ]
        }
      ],
      "source": [
        "#SVM multithreading module import\n",
        "%%bash\n",
        "source activate myenv &&\n",
        "pip install wheel https://github.com/Xtra-Computing/thundersvm/releases/download/v0.3.4/thundersvm_cuda10.1-0.3.4-cp36-cp36m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0T5u1gADRRpp",
        "outputId": "6b104e65-3b15-4588-d476-b7c475daf45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.19.2)\n",
            "  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
            "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.5.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/envs/myenv/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/envs/myenv/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
            "Installing collected packages: imbalanced-learn, imblearn\n",
            "Successfully installed imbalanced-learn-0.8.1 imblearn-0.0\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate myenv &&\n",
        "pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bqQGSNHJP_eF",
        "outputId": "e8db4ac3-46cd-46e1-a477-38c3603e12a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
            "Collecting ipython>=5.0.0\n",
            "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel) (51.1.2.post20210112)\n",
            "Collecting jedi<=0.17.2,>=0.10\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "Collecting parso<0.8.0,>=0.7.0\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.31-py3-none-any.whl (382 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/myenv/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel) (0.2.5)\n",
            "Collecting tornado>=4.2\n",
            "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
            "Collecting traitlets>=4.1.0\n",
            "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
            "Requirement already satisfied: six in /usr/local/envs/myenv/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (1.15.0)\n",
            "Collecting mlxtend\n",
            "  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from mlxtend) (1.0.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from mlxtend) (1.5.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from mlxtend) (3.3.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from mlxtend) (1.19.2)\n",
            "  Downloading mlxtend-0.20.0-py2.py3-none-any.whl (1.3 MB)\n",
            "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (from mlxtend) (0.24.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/myenv/lib/python3.6/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from matplotlib>=3.0.0->mlxtend) (8.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from pandas>=0.24.2->mlxtend) (2022.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting jupyter-client\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/envs/myenv/lib/python3.6/site-packages (from jupyter-client->ipykernel) (24.0.1)\n",
            "Collecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
            "Collecting nest-asyncio>=1.5\n",
            "  Downloading nest_asyncio-1.5.5-py3-none-any.whl (5.2 kB)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting pexpect\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: ipython-genutils, decorator, traitlets, ptyprocess, parso, tornado, pygments, prompt-toolkit, pickleshare, pexpect, nest-asyncio, jupyter-core, jedi, entrypoints, backcall, jupyter-client, ipython, mlxtend, ipykernel\n",
            "Successfully installed backcall-0.2.0 decorator-5.1.1 entrypoints-0.4 ipykernel-5.5.6 ipython-7.16.3 ipython-genutils-0.2.0 jedi-0.17.2 jupyter-client-7.1.2 jupyter-core-4.9.2 mlxtend-0.19.0 nest-asyncio-1.5.5 parso-0.7.1 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.31 ptyprocess-0.7.0 pygments-2.13.0 tornado-6.1 traitlets-4.3.3\n",
            "Installed kernelspec python3 in /root/.local/share/jupyter/kernels/python3\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate myenv &&\n",
        "pip install ipykernel mlxtend\n",
        "python -m ipykernel install --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z6Kk-Lkm-onO"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate myenv &&\n",
        "#pip install sklearn-genetic-opt --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RWOtCNVQxHJU",
        "outputId": "f785fe69-6c42-45d5-b785-6d44f6760fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "['', '/usr/local/envs/myenv/lib/python36.zip', '/usr/local/envs/myenv/lib/python3.6', '/usr/local/envs/myenv/lib/python3.6/lib-dynload', '/usr/local/envs/myenv/lib/python3.6/site-packages', '/usr/local/envs/myenv/lib/python3.6/site-packages/sacremoses-0.0.43-py3.8.egg', '/content/drive/MyDrive/ColabNotebooks/multimodal_fake_news_detection']\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate myenv &&\n",
        "echo $PYTHONPATH\n",
        "python\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ColabNotebooks/multimodal_fake_news_detection')\n",
        "#sys.path.append('/content/drive/MyDrive/ColabNotebooks/multimodal_fake_news_detection/vilbert-multi-task')\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hUB9K4A6ubH_"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate myenv &&\n",
        "#pip install thundersvm==0.3.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDbGB2PGQGsR"
      },
      "source": [
        "# Default environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfV9UH-QKHiZ"
      },
      "outputs": [],
      "source": [
        "#!conda create --name classification -y python=3.7 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPTIBXVgE5gH"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install keras "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgI_djnWMbAu"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install tensorflow-gpu==2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBB40LVUMUo1"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install sklearn-genetic-opt sklearn pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nKo_FdMG5oe"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#python -c 'from sklearn_genetic import GAFeatureSelectionCV'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUoecywhNnuR"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install ipykernel #mlxtend\n",
        "#python -m ipykernel install --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL6PWrLFFPgo"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oqOth3v2NNv"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install seaborn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0zBQOgJnt_J"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoBU2nBfUv4I"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#pip install scikit-learn==1.0.2 scipy==1.7.3 #imbalanced-learn\n",
        "#pip install scikit-learn==0.24.2 scipy imblearn mlxtend \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7Hh383_AImv"
      },
      "outputs": [],
      "source": [
        "#%%bash\n",
        "#source activate classification &&\n",
        "#python\n",
        "#%tensorflow_version 2.x\n",
        "#import tensorflow as tf\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "  #raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT3y4tUo8KVv",
        "outputId": "af96872c-0e0e-41b3-bd8d-bdbbf4a54726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-gpu==2.4.0\n",
            "  Downloading tensorflow_gpu-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.7/394.7 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting mlxtend\n",
            "  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn\n",
            "  Downloading seaborn-0.12.0-py3-none-any.whl (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.1/285.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf>=3.9.2\n",
            "  Downloading protobuf-4.21.7-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/site-packages (from tensorflow-gpu==2.4.0) (0.37.1)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-pasta~=0.2\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard~=2.4\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting astunparse~=1.6.3\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting six~=1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2022.4-py2.py3-none-any.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.8/500.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.8/960.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlxtend\n",
            "  Downloading mlxtend-0.20.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from mlxtend) (63.4.1)\n",
            "Collecting protobuf>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.28.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.26.11)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.9.0-py3-none-any.whl (5.8 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn, bayesian-optimization, termcolor, wrapt\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1304 sha256=fad7d9cd29099cca0f503f2574b4adc6a3c3ed22851cfa0518d7f31abaf3198b\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11662 sha256=01cdee12f39f895a948c5a7d87e4f4777199becd6df07d142881bdf1983372fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=9fdac3fe912b80455179ab4644252601d6a13cc120f0f8d1632fc26d3c90e7a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70824 sha256=6be324f1bff38e6152e790f257050cb80f54fb1021097ee78654e7ab74085c89\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built sklearn bayesian-optimization termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, pytz, pyasn1, keras, flatbuffers, zipp, threadpoolctl, tensorboard-data-server, six, rsa, pyparsing, pyasn1-modules, protobuf, pillow, oauthlib, numpy, MarkupSafe, kiwisolver, joblib, gast, fonttools, cycler, cachetools, werkzeug, scipy, requests-oauthlib, python-dateutil, packaging, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, absl-py, scikit-learn, pandas, matplotlib, markdown, google-auth-oauthlib, tensorboard, sklearn, seaborn, mlxtend, imbalanced-learn, bayesian-optimization, tensorflow-gpu, imblearn\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "Successfully installed MarkupSafe-2.1.1 absl-py-0.15.0 astunparse-1.6.3 bayesian-optimization-1.2.0 cachetools-5.2.0 cycler-0.11.0 flatbuffers-1.12 fonttools-4.37.4 gast-0.3.3 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 imbalanced-learn-0.8.1 imblearn-0.0 importlib-metadata-5.0.0 joblib-1.2.0 keras-2.10.0 keras-preprocessing-1.1.2 kiwisolver-1.4.4 markdown-3.4.1 matplotlib-3.5.3 mlxtend-0.19.0 numpy-1.19.5 oauthlib-3.2.1 opt-einsum-3.3.0 packaging-21.3 pandas-1.3.5 pillow-9.2.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.4 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-0.24.2 scipy-1.7.3 seaborn-0.12.0 six-1.15.0 sklearn-0.0 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.0 termcolor-1.1.0 threadpoolctl-3.1.0 typing-extensions-3.7.4.3 werkzeug-2.2.2 wrapt-1.12.1 zipp-3.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "kiwisolver",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install keras tensorflow-gpu==2.4.0 sklearn pandas numpy matplotlib  scikit-learn==0.24.2 scipy imblearn mlxtend seaborn bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuhidgHjAhlB",
        "outputId": "3f074397-10b6-47f3-cfa1-37a0111efb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.16.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting matplotlib-inline>=0.1\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from ipykernel) (21.3)\n",
            "Collecting traitlets>=5.1.0\n",
            "  Downloading traitlets-5.4.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-7.3.5-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy>=1.0\n",
            "  Downloading debugpy-1.6.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado>=6.1\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq>=17\n",
            "  Downloading pyzmq-24.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.31-py3-none-any.whl (382 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.3/382.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython>=7.23.1->ipykernel) (63.4.1)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting jupyter-core>=4.9.2\n",
            "  Downloading jupyter_core-4.11.1-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->ipykernel) (3.0.9)\n",
            "Collecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.15.0)\n",
            "Installing collected packages: wcwidth, ptyprocess, pickleshare, backcall, traitlets, tornado, pyzmq, pygments, psutil, prompt-toolkit, pexpect, parso, nest-asyncio, entrypoints, decorator, debugpy, matplotlib-inline, jupyter-core, jedi, jupyter-client, ipython, ipykernel\n",
            "Successfully installed backcall-0.2.0 debugpy-1.6.3 decorator-5.1.1 entrypoints-0.4 ipykernel-6.16.0 ipython-7.34.0 jedi-0.18.1 jupyter-client-7.3.5 jupyter-core-4.11.1 matplotlib-inline-0.1.6 nest-asyncio-1.5.6 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.31 psutil-5.9.2 ptyprocess-0.7.0 pygments-2.13.0 pyzmq-24.0.1 tornado-6.2 traitlets-5.4.0 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pexpect",
                  "pickleshare",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed kernelspec python3 in /root/.local/share/jupyter/kernels/python3\n"
          ]
        }
      ],
      "source": [
        "!pip install ipykernel \n",
        "!python -m ipykernel install --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh8_1V3VTvO0",
        "outputId": "e7598d46-37bd-4e38-d69b-bdc717deddb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAd3yDw6jiuq"
      },
      "source": [
        "#Extracting features from regions faster R-cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IKM2bY3CLUD",
        "outputId": "2aba0b81-2c84-4267-fca2-ac3a4b33c901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process is terminated.\n"
          ]
        }
      ],
      "source": [
        "#Representation in regions with RCNN \n",
        "%%bash\n",
        "source activate maskrcnn_benchmark &&\n",
        "python /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vilbert-multi-task/script/extract_features.py --model_file /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vilbert-multi-task/data/detectron_model.pth --config_file /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vilbert-multi-task/data/detectron_config.yaml --image_dir /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/data/mediaeval/images --output_folder /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/data/lesa/pfe_rcnn_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIc__aToQt2X",
        "outputId": "a774b982-ff03-459d-9246-2b64dd0e7c4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1734 [00:00<?, ?it/s]\r  0%|          | 1/1734 [00:01<33:23,  1.16s/it]\r  0%|          | 2/1734 [00:01<28:08,  1.03it/s]\r  0%|          | 3/1734 [00:02<26:42,  1.08it/s]\r  0%|          | 4/1734 [00:03<25:51,  1.12it/s]\r  0%|          | 5/1734 [00:04<25:08,  1.15it/s]\r  0%|          | 6/1734 [00:05<24:33,  1.17it/s]\r  0%|          | 7/1734 [00:06<25:57,  1.11it/s]\r  0%|          | 8/1734 [00:07<28:20,  1.02it/s]\r  1%|          | 9/1734 [00:08<27:52,  1.03it/s]\r  1%|          | 10/1734 [00:09<27:21,  1.05it/s]\r  1%|          | 11/1734 [00:10<27:01,  1.06it/s]\r  1%|          | 12/1734 [00:11<26:34,  1.08it/s]\r  1%|          | 13/1734 [00:12<27:26,  1.05it/s]\r  1%|          | 14/1734 [00:13<27:10,  1.06it/s]\r  1%|          | 15/1734 [00:14<26:51,  1.07it/s]\r  1%|          | 16/1734 [00:15<28:22,  1.01it/s]\r  1%|          | 17/1734 [00:16<28:03,  1.02it/s]\r  1%|          | 18/1734 [00:49<1:19:14,  2.77s/it]\r  1%|▏         | 23/1734 [00:50<1:03:05,  2.21s/it]\r  3%|▎         | 47/1734 [00:50<30:30,  1.08s/it]  \r  4%|▍         | 67/1734 [00:51<21:23,  1.30it/s]\r  5%|▌         | 91/1734 [00:51<15:33,  1.76it/s]\r  7%|▋         | 117/1734 [00:51<11:55,  2.26it/s]\r  8%|▊         | 143/1734 [00:51<09:37,  2.76it/s]\r  9%|▉         | 162/1734 [00:52<08:28,  3.09it/s]\r 11%|█         | 183/1734 [00:53<07:29,  3.45it/s]\r 12%|█▏        | 210/1734 [00:53<06:29,  3.91it/s]\r 14%|█▎        | 236/1734 [00:53<05:41,  4.39it/s]\r 14%|█▍        | 250/1734 [00:54<05:22,  4.60it/s]\r 16%|█▌        | 275/1734 [00:54<04:48,  5.05it/s]\r 17%|█▋        | 290/1734 [00:55<04:36,  5.22it/s]\r 17%|█▋        | 301/1734 [00:56<04:30,  5.30it/s]\r 19%|█▉        | 326/1734 [00:56<04:05,  5.73it/s]\r 20%|█▉        | 344/1734 [00:57<03:52,  5.98it/s]\r 21%|██        | 366/1734 [00:57<03:35,  6.35it/s]\r 22%|██▏       | 388/1734 [00:57<03:20,  6.72it/s]\r 24%|██▎       | 408/1734 [00:58<03:09,  6.99it/s]\r 25%|██▍       | 433/1734 [00:58<02:55,  7.41it/s]\r 26%|██▌       | 449/1734 [00:59<02:48,  7.61it/s]\r 27%|██▋       | 475/1734 [00:59<02:36,  8.03it/s]\r 29%|██▉       | 499/1734 [00:59<02:26,  8.42it/s]\r 30%|██▉       | 518/1734 [00:59<02:20,  8.65it/s]\r 31%|███▏      | 544/1734 [00:59<02:11,  9.07it/s]\r 33%|███▎      | 570/1734 [01:00<02:02,  9.49it/s]\r 34%|███▍      | 595/1734 [01:00<01:55,  9.89it/s]\r 36%|███▌      | 617/1734 [01:00<01:50, 10.14it/s]\r 37%|███▋      | 643/1734 [01:00<01:43, 10.55it/s]\r 39%|███▊      | 670/1734 [01:01<01:36, 10.98it/s]\r 40%|████      | 697/1734 [01:01<01:30, 11.40it/s]\r 42%|████▏     | 720/1734 [01:01<01:26, 11.66it/s]\r 43%|████▎     | 738/1734 [01:02<01:24, 11.81it/s]\r 43%|████▎     | 751/1734 [01:03<01:22, 11.90it/s]\r 45%|████▍     | 779/1734 [01:03<01:17, 12.32it/s]\r 46%|████▌     | 794/1734 [01:03<01:15, 12.45it/s]\r 47%|████▋     | 807/1734 [01:04<01:13, 12.54it/s]\r 48%|████▊     | 834/1734 [01:04<01:09, 12.94it/s]\r 50%|████▉     | 861/1734 [01:04<01:05, 13.34it/s]\r 51%|█████     | 887/1734 [01:04<01:01, 13.72it/s]\r 52%|█████▏    | 907/1734 [01:05<00:59, 13.91it/s]\r 53%|█████▎    | 927/1734 [01:05<00:56, 14.19it/s]\r 55%|█████▍    | 952/1734 [01:05<00:53, 14.55it/s]\r 56%|█████▋    | 977/1734 [01:05<00:50, 14.91it/s]\r 58%|█████▊    | 1003/1734 [01:05<00:47, 15.28it/s]\r 59%|█████▉    | 1031/1734 [01:05<00:44, 15.69it/s]\r 61%|██████    | 1055/1734 [01:06<00:42, 15.91it/s]\r 62%|██████▏   | 1082/1734 [01:06<00:40, 16.29it/s]\r 64%|██████▍   | 1108/1734 [01:07<00:38, 16.46it/s]\r 65%|██████▌   | 1128/1734 [01:07<00:36, 16.60it/s]\r 66%|██████▋   | 1153/1734 [01:08<00:34, 16.95it/s]\r 67%|██████▋   | 1169/1734 [01:08<00:33, 17.03it/s]\r 69%|██████▉   | 1195/1734 [01:09<00:31, 17.26it/s]\r 70%|███████   | 1215/1734 [01:09<00:29, 17.39it/s]\r 72%|███████▏  | 1240/1734 [01:09<00:27, 17.72it/s]\r 73%|███████▎  | 1267/1734 [01:10<00:25, 18.08it/s]\r 75%|███████▍  | 1293/1734 [01:10<00:23, 18.42it/s]\r 76%|███████▌  | 1320/1734 [01:10<00:22, 18.78it/s]\r 77%|███████▋  | 1342/1734 [01:10<00:20, 18.93it/s]\r 78%|███████▊  | 1358/1734 [01:11<00:19, 18.92it/s]\r 79%|███████▉  | 1370/1734 [01:12<00:19, 18.94it/s]\r 80%|████████  | 1392/1734 [01:13<00:17, 19.02it/s]\r 82%|████████▏ | 1418/1734 [01:13<00:16, 19.35it/s]\r 83%|████████▎ | 1431/1734 [01:13<00:15, 19.38it/s]\r 84%|████████▍ | 1457/1734 [01:13<00:14, 19.70it/s]\r 85%|████████▌ | 1479/1734 [01:14<00:12, 19.97it/s]\r 87%|████████▋ | 1504/1734 [01:14<00:11, 20.28it/s]\r 88%|████████▊ | 1529/1734 [01:14<00:09, 20.59it/s]\r 89%|████████▉ | 1550/1734 [01:14<00:08, 20.69it/s]\r 90%|█████████ | 1569/1734 [01:15<00:07, 20.78it/s]\r 91%|█████████ | 1581/1734 [01:16<00:07, 20.77it/s]\r 92%|█████████▏| 1590/1734 [01:16<00:06, 20.73it/s]\r 93%|█████████▎| 1615/1734 [01:16<00:05, 21.03it/s]\r 94%|█████████▍| 1629/1734 [01:17<00:04, 21.05it/s]\r 95%|█████████▌| 1654/1734 [01:17<00:03, 21.34it/s]\r 96%|█████████▌| 1668/1734 [01:18<00:03, 21.34it/s]\r 97%|█████████▋| 1679/1734 [01:18<00:02, 21.32it/s]\r 98%|█████████▊| 1706/1734 [01:18<00:01, 21.64it/s]\r 99%|█████████▉| 1720/1734 [01:19<00:00, 21.65it/s]\r100%|██████████| 1734/1734 [01:19<00:00, 21.81it/s]\n"
          ]
        }
      ],
      "source": [
        "#convert to lmdb format\n",
        "%%bash\n",
        "source activate maskrcnn_benchmark &&\n",
        "python /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/vilbert-multi-task/script/convert_to_lmdb.py --features_dir /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/data/mediaeval/rcnn_feats --lmdb_file /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/data/lesa/pfe_rcnn_lmdbs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4BFqouOBR2U"
      },
      "source": [
        "# Vilbert Features extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WAKMCIXpLsW",
        "outputId": "65528f0e-606d-4ba5-80e7-790b974985bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/231508 [00:00<?, ?B/s]\r  1%|          | 2048/231508 [00:00<00:20, 11280.39B/s]\r 23%|██▎       | 52224/231508 [00:00<00:01, 166260.23B/s]\r 38%|███▊      | 87040/231508 [00:00<00:00, 174376.77B/s]\r 83%|████████▎ | 191488/231508 [00:00<00:00, 328790.75B/s]\r100%|██████████| 231508/231508 [00:00<00:00, 312785.36B/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n",
            "\r  0%|          | 0.00/230M [00:00<?, ?B/s]\r  0%|          | 464k/230M [00:00<00:50, 4.74MB/s]\r  2%|▏         | 4.76M/230M [00:00<00:08, 28.4MB/s]\r  6%|▌         | 12.9M/230M [00:00<00:04, 54.6MB/s]\r  9%|▉         | 21.1M/230M [00:00<00:03, 66.8MB/s]\r 12%|█▏        | 28.6M/230M [00:00<00:02, 70.8MB/s]\r 16%|█▌        | 36.8M/230M [00:00<00:02, 75.9MB/s]\r 19%|█▉        | 44.1M/230M [00:00<00:02, 75.3MB/s]\r 23%|██▎       | 52.6M/230M [00:00<00:02, 79.6MB/s]\r 26%|██▌       | 60.4M/230M [00:00<00:02, 80.3MB/s]\r 30%|██▉       | 68.1M/230M [00:01<00:02, 78.4MB/s]\r 33%|███▎      | 75.6M/230M [00:01<00:02, 77.1MB/s]\r 36%|███▌      | 82.9M/230M [00:01<00:02, 74.0MB/s]\r 39%|███▉      | 90.0M/230M [00:01<00:02, 73.2MB/s]\r 42%|████▏     | 97.1M/230M [00:01<00:01, 73.6MB/s]\r 45%|████▌     | 104M/230M [00:01<00:01, 73.6MB/s] \r 48%|████▊     | 112M/230M [00:01<00:01, 74.8MB/s]\r 52%|█████▏    | 119M/230M [00:01<00:01, 75.5MB/s]\r 55%|█████▍    | 126M/230M [00:01<00:01, 72.3MB/s]\r 58%|█████▊    | 133M/230M [00:01<00:01, 72.6MB/s]\r 61%|██████    | 141M/230M [00:02<00:01, 74.1MB/s]\r 64%|██████▍   | 148M/230M [00:02<00:01, 74.0MB/s]\r 67%|██████▋   | 155M/230M [00:02<00:01, 73.1MB/s]\r 71%|███████   | 163M/230M [00:02<00:00, 76.4MB/s]\r 74%|███████▍  | 171M/230M [00:02<00:00, 77.8MB/s]\r 78%|███████▊  | 179M/230M [00:02<00:00, 79.3MB/s]\r 81%|████████  | 186M/230M [00:02<00:00, 77.5MB/s]\r 84%|████████▍ | 194M/230M [00:02<00:00, 77.9MB/s]\r 87%|████████▋ | 201M/230M [00:02<00:00, 73.1MB/s]\r 90%|█████████ | 208M/230M [00:03<00:00, 67.2MB/s]\r 94%|█████████▍| 216M/230M [00:03<00:00, 71.1MB/s]\r 97%|█████████▋| 224M/230M [00:03<00:00, 73.2MB/s]\r100%|██████████| 230M/230M [00:03<00:00, 72.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Vilbert features extraction\n",
        "%%bash\n",
        "source activate myenv &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python vilbert_code/extract_features.py --model multi_task --dset lesa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srn6YyhlnXwo"
      },
      "outputs": [],
      "source": [
        "#Some images have no detectable objects. For those images, we take random crops and extract ResNet-152 last layer features. \n",
        "#%%bash\n",
        "#source activate myenv &&\n",
        "#cd /content/drive/MyDrive/ColabNotebooks/image_text_claim_detection\n",
        "#python vilbert_code/extract_missing_imgfeats.py --dset lesa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKSh3oW4rm0F"
      },
      "source": [
        "# PFE_FINAL_TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGkqJwWgrwCK"
      },
      "source": [
        "ANN_FINAL_TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6k874zq1GMN",
        "outputId": "3da97ae0-1242-4a9d-d920-5a338650c3f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 251\n",
            " percentage: 18% \n",
            " fake:17%, reel:82% \n",
            "--------------------------------------\n",
            "ANN evaluation\n",
            "----------------------------------------\n",
            "AUC_Test = 0.644\n",
            "Balanced_Accuracy_test=  0.6437\n",
            "G_mean_te= 0.6467\n",
            "----------------------------------------\n",
            "classification report\n",
            "----------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.78      0.39        45\n",
            "           1       0.91      0.51      0.65       206\n",
            "\n",
            "    accuracy                           0.56       251\n",
            "   macro avg       0.59      0.64      0.52       251\n",
            "weighted avg       0.80      0.56      0.61       251\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#ANN sur Lesa\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python PFE_FINAL_TESTS/ANN_FINAL_TESTS_LESA.py --feat pooled --model multi_task --dset lesa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvT_oyGnG4a1"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2DrCZ1bv57V",
        "outputId": "85b3d390-04d8-4482-da95-713fafdd60fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "ANN evaluation\n",
            "----------------------------------------\n",
            "AUC_Teste = 69.830\n",
            "Balanced_Accuracy_test=  0.6983\n",
            "G_mean_te= 0.6985\n",
            "----------------------------------------\n",
            "classification report\n",
            "----------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.59      0.56        86\n",
            "           1       0.84      0.80      0.82       224\n",
            "\n",
            "    accuracy                           0.75       310\n",
            "   macro avg       0.69      0.70      0.69       310\n",
            "weighted avg       0.75      0.75      0.75       310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#ANN sur Mediaeval\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python PFE_FINAL_TESTS/ANN_FINAL_TESTS_MEDIAEVAL.py --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xJDDxdgLfWW",
        "outputId": "4d29ea9c-45ac-4a16-a295-dbc96eafe941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "Train on 1792 samples, validate on 250 samples\n",
            "Epoch 1/8\n",
            "1792/1792 [==============================] - 1s 313us/sample - loss: 8.4017 - auc: 0.5094 - val_loss: 6.7540 - val_auc: 0.6043\n",
            "Epoch 2/8\n",
            "1792/1792 [==============================] - 0s 25us/sample - loss: 6.2383 - auc: 0.5704 - val_loss: 5.3360 - val_auc: 0.6156\n",
            "Epoch 3/8\n",
            "1792/1792 [==============================] - 0s 21us/sample - loss: 4.9713 - auc: 0.7171 - val_loss: 4.3739 - val_auc: 0.6047\n",
            "Epoch 4/8\n",
            "1792/1792 [==============================] - 0s 21us/sample - loss: 4.0573 - auc: 0.7396 - val_loss: 4.0718 - val_auc: 0.6231\n",
            "Epoch 5/8\n",
            "1792/1792 [==============================] - 0s 23us/sample - loss: 3.4688 - auc: 0.7750 - val_loss: 3.9258 - val_auc: 0.6561\n",
            "Epoch 6/8\n",
            "1792/1792 [==============================] - 0s 20us/sample - loss: 3.0249 - auc: 0.8283 - val_loss: 3.5629 - val_auc: 0.7055\n",
            "Epoch 7/8\n",
            "1792/1792 [==============================] - 0s 21us/sample - loss: 2.6208 - auc: 0.8896 - val_loss: 3.2488 - val_auc: 0.7003\n",
            "Epoch 8/8\n",
            "1792/1792 [==============================] - 0s 20us/sample - loss: 2.3126 - auc: 0.9194 - val_loss: 3.5692 - val_auc: 0.6782\n",
            "Score : loss of 3.569191661834717; auc of 67.82400608062744%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.59      0.56        86\n",
            "           1       0.84      0.80      0.82       224\n",
            "\n",
            "    accuracy                           0.75       310\n",
            "   macro avg       0.69      0.70      0.69       310\n",
            "weighted avg       0.75      0.75      0.75       310\n",
            "\n",
            "----------------------------------\n",
            "training performences\n",
            "----------------------------------\n",
            "AUC_Entrainement = 0.857\n",
            "Balanced_Accuracy_train:  0.8571\n",
            "G_mean_tr: 0.8571\n",
            "[[776 120]\n",
            " [136 760]]\n",
            "----------------------------------\n",
            "validation performences\n",
            "----------------------------------\n",
            "AUC_Validation = 0.636\n",
            "Balanced_Accuracy_val:  0.6360\n",
            "G_mean_vl: 0.6360\n",
            "[[65 60]\n",
            " [31 94]]\n",
            "----------------------------------\n",
            "testing performences\n",
            "----------------------------------\n",
            "AUC_Teste = 0.698\n",
            "Balanced_Accuracy_test:  0.6983\n",
            "G_mean_te: 0.6985\n",
            "[[ 51  35]\n",
            " [ 44 180]]\n"
          ]
        }
      ],
      "source": [
        "#ANN4_mediaeval,Adamax, smote, epques=8, BS=512\n",
        "\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python NN_training/ANN_training.py --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU_eUu36HDoV",
        "outputId": "d390b70a-0f8c-4e8c-84e6-49c88662b967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "after applying SMOTE for imbalance condition\n",
            "Counter({0: 1000, 1: 1000})\n",
            "\n",
            "\n",
            "(2000, 2050)\n",
            "(182, 2050)\n",
            "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.764   \u001b[0m | \u001b[0m 8.703   \u001b[0m | \u001b[0m 574.9   \u001b[0m | \u001b[0m 0.9727  \u001b[0m | \u001b[0m 0.3574  \u001b[0m | \u001b[0m 71.59   \u001b[0m | \u001b[0m 1.432   \u001b[0m | \u001b[0m 2.953   \u001b[0m | \u001b[0m 0.007224\u001b[0m | \u001b[0m 266.5   \u001b[0m | \u001b[0m 0.4348  \u001b[0m | \u001b[0m 5.456   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.779   \u001b[0m | \u001b[0m 888.1   \u001b[0m | \u001b[0m 0.9834  \u001b[0m | \u001b[0m 0.08192 \u001b[0m | \u001b[0m 62.15   \u001b[0m | \u001b[0m 1.018   \u001b[0m | \u001b[0m 1.773   \u001b[0m | \u001b[0m 0.04512 \u001b[0m | \u001b[0m 980.0   \u001b[0m | \u001b[0m 0.4361  \u001b[0m | \u001b[0m 6.643   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 7.077   \u001b[0m | \u001b[0m 891.4   \u001b[0m | \u001b[0m 0.1732  \u001b[0m | \u001b[0m 0.03747 \u001b[0m | \u001b[0m 62.47   \u001b[0m | \u001b[0m 1.336   \u001b[0m | \u001b[0m 2.467   \u001b[0m | \u001b[0m 0.409   \u001b[0m | \u001b[0m 545.3   \u001b[0m | \u001b[0m 0.9376  \u001b[0m | \u001b[0m 3.652   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.9737  \u001b[0m | \u001b[0m 189.0   \u001b[0m | \u001b[0m 0.5452  \u001b[0m | \u001b[0m 0.2622  \u001b[0m | \u001b[0m 65.94   \u001b[0m | \u001b[0m 1.803   \u001b[0m | \u001b[0m 2.3     \u001b[0m | \u001b[0m 0.3975  \u001b[0m | \u001b[0m 642.7   \u001b[0m | \u001b[0m 0.7674  \u001b[0m | \u001b[0m 1.253   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.734   \u001b[0m | \u001b[0m 3.38    \u001b[0m | \u001b[0m 530.5   \u001b[0m | \u001b[0m 0.6867  \u001b[0m | \u001b[0m 0.1268  \u001b[0m | \u001b[0m 58.15   \u001b[0m | \u001b[0m 2.25    \u001b[0m | \u001b[0m 2.791   \u001b[0m | \u001b[0m 0.3635  \u001b[0m | \u001b[0m 656.5   \u001b[0m | \u001b[0m 0.1914  \u001b[0m | \u001b[0m 3.485   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.642   \u001b[0m | \u001b[0m 943.0   \u001b[0m | \u001b[0m 0.4318  \u001b[0m | \u001b[0m 0.4151  \u001b[0m | \u001b[0m 45.18   \u001b[0m | \u001b[0m 2.809   \u001b[0m | \u001b[0m 1.81    \u001b[0m | \u001b[0m 0.3318  \u001b[0m | \u001b[0m 590.1   \u001b[0m | \u001b[0m 0.8454  \u001b[0m | \u001b[0m 6.027   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 5.361   \u001b[0m | \u001b[0m 116.0   \u001b[0m | \u001b[0m 0.5973  \u001b[0m | \u001b[0m 0.1227  \u001b[0m | \u001b[0m 74.86   \u001b[0m | \u001b[0m 2.789   \u001b[0m | \u001b[0m 2.029   \u001b[0m | \u001b[0m 0.604   \u001b[0m | \u001b[0m 75.98   \u001b[0m | \u001b[0m 0.5401  \u001b[0m | \u001b[0m 0.9043  \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.526   \u001b[0m | \u001b[0m 5.531   \u001b[0m | \u001b[0m 392.7   \u001b[0m | \u001b[0m 0.7678  \u001b[0m | \u001b[0m 0.02427 \u001b[0m | \u001b[0m 16.32   \u001b[0m | \u001b[0m 2.368   \u001b[0m | \u001b[0m 2.029   \u001b[0m | \u001b[0m 0.5721  \u001b[0m | \u001b[0m 865.5   \u001b[0m | \u001b[0m 0.4877  \u001b[0m | \u001b[0m 5.671   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.555   \u001b[0m | \u001b[0m 4.592   \u001b[0m | \u001b[0m 951.3   \u001b[0m | \u001b[0m 0.6669  \u001b[0m | \u001b[0m 0.07436 \u001b[0m | \u001b[0m 40.27   \u001b[0m | \u001b[0m 2.732   \u001b[0m | \u001b[0m 1.701   \u001b[0m | \u001b[0m 0.1898  \u001b[0m | \u001b[0m 489.2   \u001b[0m | \u001b[0m 0.3928  \u001b[0m | \u001b[0m 4.333   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5165  \u001b[0m | \u001b[0m 3.931   \u001b[0m | \u001b[0m 290.8   \u001b[0m | \u001b[0m 0.4125  \u001b[0m | \u001b[0m 0.2095  \u001b[0m | \u001b[0m 90.83   \u001b[0m | \u001b[0m 2.959   \u001b[0m | \u001b[0m 2.247   \u001b[0m | \u001b[0m 0.0841  \u001b[0m | \u001b[0m 753.3   \u001b[0m | \u001b[0m 0.6787  \u001b[0m | \u001b[0m 5.782   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7615  \u001b[0m | \u001b[0m 3.127   \u001b[0m | \u001b[0m 90.41   \u001b[0m | \u001b[0m 0.6118  \u001b[0m | \u001b[0m 0.06201 \u001b[0m | \u001b[0m 77.4    \u001b[0m | \u001b[0m 2.589   \u001b[0m | \u001b[0m 1.817   \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 186.2   \u001b[0m | \u001b[0m 0.9426  \u001b[0m | \u001b[0m 3.258   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 6.867   \u001b[0m | \u001b[0m 778.8   \u001b[0m | \u001b[0m 0.9812  \u001b[0m | \u001b[0m 0.4866  \u001b[0m | \u001b[0m 9.769   \u001b[0m | \u001b[0m 1.032   \u001b[0m | \u001b[0m 2.087   \u001b[0m | \u001b[0m 0.03484 \u001b[0m | \u001b[0m 676.7   \u001b[0m | \u001b[0m 0.5349  \u001b[0m | \u001b[0m 4.666   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 3.972   \u001b[0m | \u001b[0m 302.3   \u001b[0m | \u001b[0m 0.9497  \u001b[0m | \u001b[0m 0.3641  \u001b[0m | \u001b[0m 6.594   \u001b[0m | \u001b[0m 1.199   \u001b[0m | \u001b[0m 2.263   \u001b[0m | \u001b[0m 0.2887  \u001b[0m | \u001b[0m 423.3   \u001b[0m | \u001b[0m 0.7815  \u001b[0m | \u001b[0m 2.479   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5705  \u001b[0m | \u001b[0m 8.332   \u001b[0m | \u001b[0m 746.7   \u001b[0m | \u001b[0m 0.5519  \u001b[0m | \u001b[0m 0.09048 \u001b[0m | \u001b[0m 44.5    \u001b[0m | \u001b[0m 2.526   \u001b[0m | \u001b[0m 2.982   \u001b[0m | \u001b[0m 0.07458 \u001b[0m | \u001b[0m 146.6   \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 5.836   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.799   \u001b[0m | \u001b[0m 854.8   \u001b[0m | \u001b[0m 0.7867  \u001b[0m | \u001b[0m 0.3441  \u001b[0m | \u001b[0m 37.95   \u001b[0m | \u001b[0m 1.889   \u001b[0m | \u001b[0m 1.733   \u001b[0m | \u001b[0m 0.8406  \u001b[0m | \u001b[0m 342.9   \u001b[0m | \u001b[0m 0.3226  \u001b[0m | \u001b[0m 6.547   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.51    \u001b[0m | \u001b[0m 8.28    \u001b[0m | \u001b[0m 992.9   \u001b[0m | \u001b[0m 0.8075  \u001b[0m | \u001b[0m 0.04346 \u001b[0m | \u001b[0m 14.55   \u001b[0m | \u001b[0m 2.114   \u001b[0m | \u001b[0m 2.712   \u001b[0m | \u001b[0m 0.8843  \u001b[0m | \u001b[0m 655.8   \u001b[0m | \u001b[0m 0.9558  \u001b[0m | \u001b[0m 1.063   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5005  \u001b[0m | \u001b[0m 1.994   \u001b[0m | \u001b[0m 361.8   \u001b[0m | \u001b[0m 0.2568  \u001b[0m | \u001b[0m 0.1561  \u001b[0m | \u001b[0m 17.13   \u001b[0m | \u001b[0m 1.751   \u001b[0m | \u001b[0m 1.06    \u001b[0m | \u001b[0m 0.5382  \u001b[0m | \u001b[0m 969.1   \u001b[0m | \u001b[0m 0.4451  \u001b[0m | \u001b[0m 4.369   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.4995  \u001b[0m | \u001b[0m 5.506   \u001b[0m | \u001b[0m 957.9   \u001b[0m | \u001b[0m 0.7345  \u001b[0m | \u001b[0m 0.4124  \u001b[0m | \u001b[0m 37.57   \u001b[0m | \u001b[0m 2.815   \u001b[0m | \u001b[0m 1.37    \u001b[0m | \u001b[0m 0.4086  \u001b[0m | \u001b[0m 757.8   \u001b[0m | \u001b[0m 0.3335  \u001b[0m | \u001b[0m 6.203   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.536   \u001b[0m | \u001b[0m 7.746   \u001b[0m | \u001b[0m 195.8   \u001b[0m | \u001b[0m 0.2307  \u001b[0m | \u001b[0m 0.02622 \u001b[0m | \u001b[0m 86.72   \u001b[0m | \u001b[0m 1.678   \u001b[0m | \u001b[0m 1.786   \u001b[0m | \u001b[0m 0.2711  \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.4569  \u001b[0m | \u001b[0m 1.643   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5185  \u001b[0m | \u001b[0m 5.068   \u001b[0m | \u001b[0m 233.1   \u001b[0m | \u001b[0m 0.5114  \u001b[0m | \u001b[0m 0.4742  \u001b[0m | \u001b[0m 40.95   \u001b[0m | \u001b[0m 2.908   \u001b[0m | \u001b[0m 1.114   \u001b[0m | \u001b[0m 0.5493  \u001b[0m | \u001b[0m 618.2   \u001b[0m | \u001b[0m 0.9618  \u001b[0m | \u001b[0m 6.476   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 4.598   \u001b[0m | \u001b[0m 785.4   \u001b[0m | \u001b[0m 0.9759  \u001b[0m | \u001b[0m 0.3683  \u001b[0m | \u001b[0m 95.67   \u001b[0m | \u001b[0m 2.878   \u001b[0m | \u001b[0m 1.964   \u001b[0m | \u001b[0m 0.6602  \u001b[0m | \u001b[0m 192.4   \u001b[0m | \u001b[0m 0.437   \u001b[0m | \u001b[0m 6.063   \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.678   \u001b[0m | \u001b[0m 5.195   \u001b[0m | \u001b[0m 309.2   \u001b[0m | \u001b[0m 0.1228  \u001b[0m | \u001b[0m 0.1159  \u001b[0m | \u001b[0m 17.75   \u001b[0m | \u001b[0m 1.468   \u001b[0m | \u001b[0m 1.767   \u001b[0m | \u001b[0m 0.04386 \u001b[0m | \u001b[0m 860.5   \u001b[0m | \u001b[0m 0.4038  \u001b[0m | \u001b[0m 3.972   \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5075  \u001b[0m | \u001b[0m 5.725   \u001b[0m | \u001b[0m 163.8   \u001b[0m | \u001b[0m 0.08271 \u001b[0m | \u001b[0m 0.07827 \u001b[0m | \u001b[0m 98.71   \u001b[0m | \u001b[0m 1.209   \u001b[0m | \u001b[0m 1.845   \u001b[0m | \u001b[0m 0.8752  \u001b[0m | \u001b[0m 602.5   \u001b[0m | \u001b[0m 0.01753 \u001b[0m | \u001b[0m 6.221   \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.675   \u001b[0m | \u001b[0m 3.457   \u001b[0m | \u001b[0m 198.4   \u001b[0m | \u001b[0m 0.3372  \u001b[0m | \u001b[0m 0.2971  \u001b[0m | \u001b[0m 9.548   \u001b[0m | \u001b[0m 2.287   \u001b[0m | \u001b[0m 2.22    \u001b[0m | \u001b[0m 0.2296  \u001b[0m | \u001b[0m 442.0   \u001b[0m | \u001b[0m 0.1935  \u001b[0m | \u001b[0m 0.1493  \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.735   \u001b[0m | \u001b[0m 5.255   \u001b[0m | \u001b[0m 473.8   \u001b[0m | \u001b[0m 0.8421  \u001b[0m | \u001b[0m 0.09953 \u001b[0m | \u001b[0m 47.42   \u001b[0m | \u001b[0m 2.335   \u001b[0m | \u001b[0m 1.137   \u001b[0m | \u001b[0m 0.356   \u001b[0m | \u001b[0m 705.6   \u001b[0m | \u001b[0m 0.2451  \u001b[0m | \u001b[0m 2.548   \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 5.196   \u001b[0m | \u001b[0m 438.2   \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 0.4299  \u001b[0m | \u001b[0m 84.39   \u001b[0m | \u001b[0m 1.853   \u001b[0m | \u001b[0m 1.38    \u001b[0m | \u001b[0m 0.6392  \u001b[0m | \u001b[0m 444.1   \u001b[0m | \u001b[0m 0.5058  \u001b[0m | \u001b[0m 4.557   \u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6765  \u001b[0m | \u001b[0m 8.459   \u001b[0m | \u001b[0m 833.8   \u001b[0m | \u001b[0m 0.1232  \u001b[0m | \u001b[0m 0.4537  \u001b[0m | \u001b[0m 69.64   \u001b[0m | \u001b[0m 1.639   \u001b[0m | \u001b[0m 2.46    \u001b[0m | \u001b[0m 0.4755  \u001b[0m | \u001b[0m 578.9   \u001b[0m | \u001b[0m 0.5718  \u001b[0m | \u001b[0m 1.06    \u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5415  \u001b[0m | \u001b[0m 3.258   \u001b[0m | \u001b[0m 464.2   \u001b[0m | \u001b[0m 0.05773 \u001b[0m | \u001b[0m 0.3619  \u001b[0m | \u001b[0m 36.72   \u001b[0m | \u001b[0m 1.954   \u001b[0m | \u001b[0m 2.896   \u001b[0m | \u001b[0m 0.8681  \u001b[0m | \u001b[0m 286.9   \u001b[0m | \u001b[0m 0.4003  \u001b[0m | \u001b[0m 3.999   \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.075   \u001b[0m | \u001b[0m 821.8   \u001b[0m | \u001b[0m 0.3238  \u001b[0m | \u001b[0m 0.05781 \u001b[0m | \u001b[0m 72.48   \u001b[0m | \u001b[0m 2.03    \u001b[0m | \u001b[0m 1.054   \u001b[0m | \u001b[0m 0.5632  \u001b[0m | \u001b[0m 784.9   \u001b[0m | \u001b[0m 0.03104 \u001b[0m | \u001b[0m 4.603   \u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.5005  \u001b[0m | \u001b[0m 2.251   \u001b[0m | \u001b[0m 463.8   \u001b[0m | \u001b[0m 0.07217 \u001b[0m | \u001b[0m 0.2661  \u001b[0m | \u001b[0m 94.25   \u001b[0m | \u001b[0m 1.61    \u001b[0m | \u001b[0m 1.127   \u001b[0m | \u001b[0m 0.8484  \u001b[0m | \u001b[0m 970.9   \u001b[0m | \u001b[0m 0.4911  \u001b[0m | \u001b[0m 6.36    \u001b[0m |\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.675   \u001b[0m | \u001b[0m 8.126   \u001b[0m | \u001b[0m 33.74   \u001b[0m | \u001b[0m 0.06233 \u001b[0m | \u001b[0m 0.1027  \u001b[0m | \u001b[0m 91.11   \u001b[0m | \u001b[0m 1.146   \u001b[0m | \u001b[0m 1.209   \u001b[0m | \u001b[0m 0.9029  \u001b[0m | \u001b[0m 1.012e+0\u001b[0m | \u001b[0m 0.8978  \u001b[0m | \u001b[0m 0.6711  \u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.703   \u001b[0m | \u001b[0m 96.7    \u001b[0m | \u001b[0m 0.7547  \u001b[0m | \u001b[0m 0.2951  \u001b[0m | \u001b[0m 82.77   \u001b[0m | \u001b[0m 1.806   \u001b[0m | \u001b[0m 1.031   \u001b[0m | \u001b[0m 0.6096  \u001b[0m | \u001b[0m 174.9   \u001b[0m | \u001b[0m 0.7017  \u001b[0m | \u001b[0m 4.585   \u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 4.902   \u001b[0m | \u001b[0m 731.2   \u001b[0m | \u001b[0m 0.5781  \u001b[0m | \u001b[0m 0.09472 \u001b[0m | \u001b[0m 65.77   \u001b[0m | \u001b[0m 2.611   \u001b[0m | \u001b[0m 2.526   \u001b[0m | \u001b[0m 0.9484  \u001b[0m | \u001b[0m 376.4   \u001b[0m | \u001b[0m 0.631   \u001b[0m | \u001b[0m 0.4634  \u001b[0m |\n",
            "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.713   \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 32.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 320.5   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
            "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.528   \u001b[0m | \u001b[0m 3.475   \u001b[0m | \u001b[0m 917.8   \u001b[0m | \u001b[0m 0.298   \u001b[0m | \u001b[0m 0.1752  \u001b[0m | \u001b[0m 63.41   \u001b[0m | \u001b[0m 2.182   \u001b[0m | \u001b[0m 1.426   \u001b[0m | \u001b[0m 0.5497  \u001b[0m | \u001b[0m 567.8   \u001b[0m | \u001b[0m 0.8767  \u001b[0m | \u001b[0m 1.971   \u001b[0m |\n",
            "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6235  \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 387.8   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
            "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.508   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
            "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 7.031   \u001b[0m | \u001b[0m 33.84   \u001b[0m | \u001b[0m 0.5334  \u001b[0m | \u001b[0m 0.3634  \u001b[0m | \u001b[0m 6.623   \u001b[0m | \u001b[0m 1.582   \u001b[0m | \u001b[0m 2.646   \u001b[0m | \u001b[0m 0.7072  \u001b[0m | \u001b[0m 807.4   \u001b[0m | \u001b[0m 0.8149  \u001b[0m | \u001b[0m 1.126   \u001b[0m |\n",
            "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 666.3   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.024e+0\u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
            "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.454   \u001b[0m | \u001b[0m 1.02e+03\u001b[0m | \u001b[0m 0.6109  \u001b[0m | \u001b[0m 0.328   \u001b[0m | \u001b[0m 97.09   \u001b[0m | \u001b[0m 2.72    \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 0.8093  \u001b[0m | \u001b[0m 271.2   \u001b[0m | \u001b[0m 0.7515  \u001b[0m | \u001b[0m 5.183   \u001b[0m |\n",
            "=============================================================================================================================================================\n",
            "\n",
            "\n",
            "Best params: {'activation': 8.70326855112309, 'batch_size': 574.8543911823166, 'dropout': 0.9726843599648843, 'dropout_rate': 0.35740799683718233, 'epochs': 71.58650951214345, 'layers1': 1.4321789911607528, 'layers2': 2.9525489095524833, 'learning_rate': 0.007224024949385273, 'neurons': 266.5241154568122, 'normalization': 0.4347915324044458, 'optimizer': 5.455680452556267}.\n",
            "\n",
            "\n",
            "Best accuracy: 0.764.\n",
            "\n",
            "\n",
            "{'activation': 'relu', 'batch_size': 575, 'dropout': 0.9726843599648843, 'dropout_rate': 0.35740799683718233, 'epochs': 72, 'layers1': 1, 'layers2': 3, 'learning_rate': 0.007224024949385273, 'neurons': 267, 'normalization': 0.4347915324044458, 'optimizer': <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f48b8da7b90>}\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-20 07:37:17.395065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-05-20 07:37:25.469462: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-05-20 07:37:25.470501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-05-20 07:37:25.489044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:25.489973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2022-05-20 07:37:25.490032: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-05-20 07:37:25.492920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-05-20 07:37:25.493006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-05-20 07:37:25.494022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-05-20 07:37:25.494348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-05-20 07:37:25.496124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-05-20 07:37:25.496834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-05-20 07:37:25.497086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-05-20 07:37:25.497192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:25.498120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:25.498941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-05-20 07:37:25.499501: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-05-20 07:37:25.499639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:25.500573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2022-05-20 07:37:25.500639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-05-20 07:37:25.500699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-05-20 07:37:25.500774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-05-20 07:37:25.500832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-05-20 07:37:25.500891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-05-20 07:37:25.500948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-05-20 07:37:25.500995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-05-20 07:37:25.501041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-05-20 07:37:25.501177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:25.502229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:25.503126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-05-20 07:37:25.503201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-05-20 07:37:26.155702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-05-20 07:37:26.155765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2022-05-20 07:37:26.155785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2022-05-20 07:37:26.156025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:26.157077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:26.158068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-20 07:37:26.158978: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-05-20 07:37:26.159042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2022-05-20 07:37:26.270777: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-05-20 07:37:26.271284: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "2022-05-20 07:37:26.901906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-05-20 07:37:27.180828: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b83889e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8101200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b471f200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b45dcdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4488f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b42edb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b40dab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4958664f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4222950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b832e170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49204c6cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4712e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9e96830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae7abf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8d52950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f492019b4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b817bb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49204c6cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b435ee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b817b200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476f290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4920046560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b829d7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f493256a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4920046560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b42225f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f492019be60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f960e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b449df80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f493256ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b437ca70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8365320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4920282cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b43c1710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4292710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4f1dd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476f9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f493256a290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f1a440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b44b7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b454ecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b832ed40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476fd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4400200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8e098c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b46b0680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b832e7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4fc6e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b43c7320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8353cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b46bcdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8423290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b454e4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4292e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49203dcd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4920463b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49203bc170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4243c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b439fa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b46efd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae77c320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b96700e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f2f680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4c67710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f15dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49203bc7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476fb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476f050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49203dc0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4556050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f492027dc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8cf7320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8cf7e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49202e5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b43d3a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f492027d680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476ff80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4920463ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4243a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4dc0b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4bf19e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f185f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4222320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4920291e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b469dc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b469d5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f493256a0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8069b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49203dc050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49204c6ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4932dbbd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4bf1b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4c0c170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49204360e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae6a49e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4932dbbc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476f7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49202915f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b44fcdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b43a7a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae716ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b44fca70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f86a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b81e07a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b81e00e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4920291dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b81e0c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f492026c0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4932dbb4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b82edf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b82eddd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b84200e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b42faef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae6b6710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b440eb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b96700e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4cc33b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4932dbb680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8069560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b81e0f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae732290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f980e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4e53b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49200dcc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49202910e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49200c3680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b81e0dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49203dc200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b46699e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b476f560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b440e560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f5dcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b467ea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8294ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8d2f9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8d2f170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b467e200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b467e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8398710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f492006e8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b81b7170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b9f034d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b43b7200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f492017f200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b83e5200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae6b8f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b8069b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4932dbb680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49204c6b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b467e050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b43784d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4397560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4fb68c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae682050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4397cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b822c9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b4da8290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f495865b830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48ae6b8050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b42437a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f48b467e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 22 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49204c6a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate classification &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/\n",
        "python NN_training/ANN_training.py  --feat pooled --model multi_task --dset lesa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trODc3Tur7BV"
      },
      "source": [
        "CNN1d_FINAL_TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8vRhExI-OYX",
        "outputId": "b9f4dd2f-f9f1-4f24-a4f6-32f72d2a267d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "2022-09-26 17:09:14.552918: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 177471488 exceeds 10% of free system memory.\n",
            "2022-09-26 17:09:14.818233: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 177471488 exceeds 10% of free system memory.\n",
            "CNN-1d evaluation\n",
            "----------------------------------------\n",
            "AUC_Test = 0.736\n",
            "Balanced_Accuracy_test=  0.7359\n",
            "G_mean_te= 0.7361\n",
            "----------------------------------------\n",
            "[[ 64  22]\n",
            " [ 61 163]]\n",
            "classification report\n",
            "----------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.74      0.61        86\n",
            "           1       0.88      0.73      0.80       224\n",
            "\n",
            "    accuracy                           0.73       310\n",
            "   macro avg       0.70      0.74      0.70       310\n",
            "weighted avg       0.78      0.73      0.74       310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#CNN-1d sur mediaeval\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python PFE_FINAL_TESTS/CNN1d_FINAL_TESTS_MEDIAEVAL.py --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB15HEHqzEhl",
        "outputId": "a0c1f580-33db-488b-d215-7ac053531b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 251\n",
            " percentage: 18% \n",
            " fake:18%, reel:81% \n",
            "--------------------------------------\n",
            "CNN-1d evaluation\n",
            "----------------------------------------\n",
            "AUC_Test = 68.261\n",
            "Balanced_Accuracy_test=  0.6826\n",
            "G_mean_te= 0.6819\n",
            "----------------------------------------\n",
            "[[ 26  20]\n",
            " [ 41 164]]\n",
            "classification report\n",
            "----------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.57      0.46        46\n",
            "           1       0.89      0.80      0.84       205\n",
            "\n",
            "    accuracy                           0.76       251\n",
            "   macro avg       0.64      0.68      0.65       251\n",
            "weighted avg       0.80      0.76      0.77       251\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#CNN-1d sur lesa\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python PFE_FINAL_TESTS/CNN1d_FINAL_TESTS_LESA.py --feat pooled --model multi_task --dset lesa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWX2tXcAALjp"
      },
      "source": [
        "Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g29S0cGbDM9k",
        "outputId": "5900ed2b-5983-4858-952a-378b94bca7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 2048, 64)          448       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 2043, 64)          24640     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2043, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 681, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 676, 128)          49280     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 671, 128)          98432     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 223, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 223, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 28544)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               14615040  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 14,788,353\n",
            "Trainable params: 14,788,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "56/56 [==============================] - 3s 22ms/step - loss: 2.1477 - accuracy: 0.5056 - val_loss: 1.4363 - val_accuracy: 0.5000\n",
            "Epoch 2/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.3772 - accuracy: 0.4949 - val_loss: 1.2457 - val_accuracy: 0.5000\n",
            "Epoch 3/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.2174 - accuracy: 0.5033 - val_loss: 1.1489 - val_accuracy: 0.5280\n",
            "Epoch 4/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.1299 - accuracy: 0.5617 - val_loss: 1.0835 - val_accuracy: 0.5760\n",
            "Epoch 5/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.0692 - accuracy: 0.5596 - val_loss: 1.0378 - val_accuracy: 0.5000\n",
            "Epoch 6/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.0130 - accuracy: 0.5869 - val_loss: 0.9897 - val_accuracy: 0.5760\n",
            "Epoch 7/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 0.9339 - accuracy: 0.6677 - val_loss: 0.9582 - val_accuracy: 0.5880\n",
            "Epoch 8/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 0.8824 - accuracy: 0.7137 - val_loss: 0.9163 - val_accuracy: 0.6360\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9163 - accuracy: 0.6360\n",
            "Score : loss of 0.9163258075714111; accuracy of 63.599997758865356%\n",
            "\n",
            "Balanced_Accuracy\n",
            "Balanced_Accuracy_train:  0.7193, G_mean_tr: 0.7193\n",
            "Balanced_Accuracy_val:  0.6360, G_mean_vl: 0.6360\n",
            "Balanced_Accuracy_test:  0.7083, G_mean_te: 0.7085\n",
            "\n",
            "AUC_Entrainement = 0.719\n",
            "AUC_Validation = 0.636\n",
            "AUC_Teste = 0.708\n",
            "\n",
            "confusion_matrix for train set\n",
            "[[781 115]\n",
            " [388 508]]\n",
            "confusion_matrix for validation set\n",
            "[[92 33]\n",
            " [58 67]]\n",
            "confusion_matrix for test set\n",
            "[[ 70  16]\n",
            " [ 89 135]]\n",
            "rapport for test set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.81      0.57        86\n",
            "           1       0.89      0.60      0.72       224\n",
            "\n",
            "    accuracy                           0.66       310\n",
            "   macro avg       0.67      0.71      0.65       310\n",
            "weighted avg       0.77      0.66      0.68       310\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#CNN1_mediaeval,Adamax, smote, epques=8, BS=32\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python NN_training/CNN_training.py  --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-h9BpK9AEUe",
        "outputId": "3100a6dc-7111-4274-f3f9-294fd91397a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 2048, 64)          448       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 2043, 64)          24640     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2043, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2038, 128)         49280     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 2033, 128)         98432     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 677, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 677, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 86656)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               44368384  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 44,541,697\n",
            "Trainable params: 44,541,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "\r 1/56 [..............................] - ETA: 2:16 - loss: 2.5819 - accuracy: 0.4375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 2.8683 - accuracy: 0.4080  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 3.0424 - accuracy: 0.4107\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 3.0219 - accuracy: 0.4317\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 2.9660 - accuracy: 0.4512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 2.9072 - accuracy: 0.4636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 2.8519 - accuracy: 0.4721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 2.8011 - accuracy: 0.4788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 2.7550 - accuracy: 0.4833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 2.7131 - accuracy: 0.4870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 2.6749 - accuracy: 0.4898\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 2.6398 - accuracy: 0.4913\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 2.6075 - accuracy: 0.4918\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 2.5776 - accuracy: 0.4921\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 2.5497 - accuracy: 0.4922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 2.5236 - accuracy: 0.4924\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 2.4992 - accuracy: 0.4932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 2.4761 - accuracy: 0.4941\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 2.4544 - accuracy: 0.4954\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 2.4337 - accuracy: 0.4969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 2.4142 - accuracy: 0.4988\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 2.3955 - accuracy: 0.5004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 2.3777 - accuracy: 0.5019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 2.3607 - accuracy: 0.5033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 2.3444 - accuracy: 0.5044\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 2.3288 - accuracy: 0.5055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 2.3138 - accuracy: 0.5062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 2.2994 - accuracy: 0.5068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 5s 38ms/step - loss: 2.2856 - accuracy: 0.5074 - val_loss: 1.5229 - val_accuracy: 0.5880\n",
            "Epoch 2/8\n",
            "\r 1/56 [..............................] - ETA: 1s - loss: 1.5237 - accuracy: 0.4062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 1.5207 - accuracy: 0.4531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 1.5176 - accuracy: 0.4744\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 1.5146 - accuracy: 0.4855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 1.5119 - accuracy: 0.4843\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 1.5092 - accuracy: 0.4839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 1.5065 - accuracy: 0.4867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 1.5039 - accuracy: 0.4931\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 1.5012 - accuracy: 0.5020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 1.4986 - accuracy: 0.5100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 1.4959 - accuracy: 0.5165\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 1.4933 - accuracy: 0.5214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 1.4908 - accuracy: 0.5249\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 1.4883 - accuracy: 0.5278\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 1.4859 - accuracy: 0.5294\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 1.4835 - accuracy: 0.5305\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 1.4811 - accuracy: 0.5316\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 1.4788 - accuracy: 0.5325\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 1.4765 - accuracy: 0.5334\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 1.4742 - accuracy: 0.5344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 1.4720 - accuracy: 0.5356\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 1.4698 - accuracy: 0.5368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 1.4676 - accuracy: 0.5379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 1.4654 - accuracy: 0.5387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 1.4633 - accuracy: 0.5394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 1.4611 - accuracy: 0.5399\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 1.4591 - accuracy: 0.5403\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 1.4570 - accuracy: 0.5406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 2s 30ms/step - loss: 1.4550 - accuracy: 0.5408 - val_loss: 1.3037 - val_accuracy: 0.6680\n",
            "Epoch 3/8\n",
            "\r 1/56 [..............................] - ETA: 1s - loss: 1.2973 - accuracy: 0.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 1.2940 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 1.2936 - accuracy: 0.6397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 1.2926 - accuracy: 0.6468\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 1.2916 - accuracy: 0.6523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 1.2907 - accuracy: 0.6530\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 1.2897 - accuracy: 0.6558\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 1.2884 - accuracy: 0.6592\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 1.2870 - accuracy: 0.6605\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 1.2855 - accuracy: 0.6600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 1.2841 - accuracy: 0.6585\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 1.2826 - accuracy: 0.6568\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 1.2812 - accuracy: 0.6550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 1.2798 - accuracy: 0.6531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 1.2785 - accuracy: 0.6519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 1.2771 - accuracy: 0.6512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 1.2757 - accuracy: 0.6507\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 1.2744 - accuracy: 0.6501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 1.2731 - accuracy: 0.6497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 1.2717 - accuracy: 0.6495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 1.2704 - accuracy: 0.6493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 1.2691 - accuracy: 0.6491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 1.2678 - accuracy: 0.6490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 1.2664 - accuracy: 0.6490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 1.2650 - accuracy: 0.6488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 1.2637 - accuracy: 0.6486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 1.2624 - accuracy: 0.6485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 1.2612 - accuracy: 0.6481\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 2s 30ms/step - loss: 1.2600 - accuracy: 0.6478 - val_loss: 1.1657 - val_accuracy: 0.6280\n",
            "Epoch 4/8\n",
            "\r 1/56 [..............................] - ETA: 1s - loss: 1.1175 - accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 1.1165 - accuracy: 0.7205\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 1.1285 - accuracy: 0.6807\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 1.1355 - accuracy: 0.6632\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 1.1388 - accuracy: 0.6592\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 1.1410 - accuracy: 0.6581\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 1.1426 - accuracy: 0.6578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 1.1436 - accuracy: 0.6589\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 1.1442 - accuracy: 0.6602\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 1.1445 - accuracy: 0.6606\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 1.1451 - accuracy: 0.6596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 1.1453 - accuracy: 0.6590\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 1.1449 - accuracy: 0.6593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 1.1447 - accuracy: 0.6592\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 1.1444 - accuracy: 0.6588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 1.1438 - accuracy: 0.6587\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 1.1432 - accuracy: 0.6589\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 1.1423 - accuracy: 0.6593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 1.1414 - accuracy: 0.6599\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 1.1404 - accuracy: 0.6605\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 1.1394 - accuracy: 0.6610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 1.1384 - accuracy: 0.6616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 1.1374 - accuracy: 0.6621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 1.1364 - accuracy: 0.6627\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 1.1353 - accuracy: 0.6634\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 1.1342 - accuracy: 0.6641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 1.1332 - accuracy: 0.6647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 1.1322 - accuracy: 0.6653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 2s 30ms/step - loss: 1.1311 - accuracy: 0.6659 - val_loss: 1.0782 - val_accuracy: 0.6720\n",
            "Epoch 5/8\n",
            "\r 1/56 [..............................] - ETA: 1s - loss: 1.1479 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 1.1021 - accuracy: 0.6997\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 1.0887 - accuracy: 0.7048\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 1.0787 - accuracy: 0.7047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 1.0690 - accuracy: 0.7066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 1.0614 - accuracy: 0.7096\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 1.0554 - accuracy: 0.7119\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 1.0511 - accuracy: 0.7143\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 1.0473 - accuracy: 0.7162\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 1.0439 - accuracy: 0.7172\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 1.0402 - accuracy: 0.7185\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 1.0371 - accuracy: 0.7195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 1.0345 - accuracy: 0.7206\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 1.0321 - accuracy: 0.7220\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 1.0300 - accuracy: 0.7234\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 1.0282 - accuracy: 0.7245\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 1.0267 - accuracy: 0.7250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 1.0253 - accuracy: 0.7254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 1.0244 - accuracy: 0.7255\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 1.0234 - accuracy: 0.7256\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 1.0226 - accuracy: 0.7258\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 1.0216 - accuracy: 0.7260\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 1.0206 - accuracy: 0.7264\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 1.0196 - accuracy: 0.7267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 1.0187 - accuracy: 0.7270\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 1.0177 - accuracy: 0.7274\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 1.0168 - accuracy: 0.7277\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 1.0158 - accuracy: 0.7280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 2s 32ms/step - loss: 1.0148 - accuracy: 0.7284 - val_loss: 1.0395 - val_accuracy: 0.6840\n",
            "Epoch 6/8\n",
            "\r 1/56 [..............................] - ETA: 1s - loss: 1.0153 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 0.9639 - accuracy: 0.7483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 0.9483 - accuracy: 0.7586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 0.9403 - accuracy: 0.7616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 0.9335 - accuracy: 0.7648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 0.9287 - accuracy: 0.7685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 0.9240 - accuracy: 0.7718\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 0.9218 - accuracy: 0.7735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 0.9198 - accuracy: 0.7746\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 0.9167 - accuracy: 0.7762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 0.9138 - accuracy: 0.7777\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 0.9115 - accuracy: 0.7788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 0.9105 - accuracy: 0.7787\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 0.9101 - accuracy: 0.7782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 0.9104 - accuracy: 0.7774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 0.9105 - accuracy: 0.7768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 0.9112 - accuracy: 0.7759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 0.9117 - accuracy: 0.7752\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 0.9122 - accuracy: 0.7745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 0.9127 - accuracy: 0.7738\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 0.9131 - accuracy: 0.7733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 0.9133 - accuracy: 0.7728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 0.9134 - accuracy: 0.7724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 0.9134 - accuracy: 0.7722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 0.9132 - accuracy: 0.7722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 0.9131 - accuracy: 0.7722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 0.9130 - accuracy: 0.7721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 0.9128 - accuracy: 0.7722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 2s 30ms/step - loss: 0.9126 - accuracy: 0.7722 - val_loss: 0.9549 - val_accuracy: 0.7040\n",
            "Epoch 7/8\n",
            "\r 1/56 [..............................] - ETA: 1s - loss: 0.8405 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 0.8141 - accuracy: 0.8316\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 0.8053 - accuracy: 0.8299\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 0.8011 - accuracy: 0.8310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 0.7986 - accuracy: 0.8326\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 0.8010 - accuracy: 0.8293\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 0.8057 - accuracy: 0.8235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 0.8086 - accuracy: 0.8188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 0.8114 - accuracy: 0.8145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 0.8133 - accuracy: 0.8115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 0.8148 - accuracy: 0.8091\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 0.8158 - accuracy: 0.8078\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 0.8159 - accuracy: 0.8074\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 0.8160 - accuracy: 0.8074\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 0.8161 - accuracy: 0.8071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 0.8162 - accuracy: 0.8071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 0.8167 - accuracy: 0.8067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 0.8170 - accuracy: 0.8066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 0.8170 - accuracy: 0.8067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 0.8169 - accuracy: 0.8067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 0.8170 - accuracy: 0.8066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 0.8171 - accuracy: 0.8067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 0.8171 - accuracy: 0.8068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 0.8170 - accuracy: 0.8069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 0.8170 - accuracy: 0.8068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 0.8169 - accuracy: 0.8069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 0.8168 - accuracy: 0.8070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 0.8168 - accuracy: 0.8069\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 2s 30ms/step - loss: 0.8169 - accuracy: 0.8069 - val_loss: 0.8966 - val_accuracy: 0.7560\n",
            "Epoch 8/8\n",
            "\r 1/56 [..............................] - ETA: 1s - loss: 0.7606 - accuracy: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/56 [>.............................] - ETA: 1s - loss: 0.8291 - accuracy: 0.7552\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/56 [=>............................] - ETA: 1s - loss: 0.8423 - accuracy: 0.7556\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/56 [==>...........................] - ETA: 1s - loss: 0.8387 - accuracy: 0.7662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9/56 [===>..........................] - ETA: 1s - loss: 0.8351 - accuracy: 0.7708\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/56 [====>.........................] - ETA: 1s - loss: 0.8307 - accuracy: 0.7754\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/56 [=====>........................] - ETA: 1s - loss: 0.8272 - accuracy: 0.7790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/56 [=======>......................] - ETA: 1s - loss: 0.8224 - accuracy: 0.7830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17/56 [========>.....................] - ETA: 1s - loss: 0.8178 - accuracy: 0.7872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19/56 [=========>....................] - ETA: 1s - loss: 0.8137 - accuracy: 0.7906\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/56 [==========>...................] - ETA: 1s - loss: 0.8106 - accuracy: 0.7926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/56 [===========>..................] - ETA: 0s - loss: 0.8076 - accuracy: 0.7944\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/56 [============>.................] - ETA: 0s - loss: 0.8049 - accuracy: 0.7956\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/56 [=============>................] - ETA: 0s - loss: 0.8030 - accuracy: 0.7965\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/56 [==============>...............] - ETA: 0s - loss: 0.8012 - accuracy: 0.7973\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/56 [===============>..............] - ETA: 0s - loss: 0.7996 - accuracy: 0.7982\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/56 [================>.............] - ETA: 0s - loss: 0.7982 - accuracy: 0.7989\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/56 [=================>............] - ETA: 0s - loss: 0.7965 - accuracy: 0.7997\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r37/56 [==================>...........] - ETA: 0s - loss: 0.7949 - accuracy: 0.8006\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/56 [===================>..........] - ETA: 0s - loss: 0.7934 - accuracy: 0.8014\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r41/56 [====================>.........] - ETA: 0s - loss: 0.7918 - accuracy: 0.8023\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/56 [======================>.......] - ETA: 0s - loss: 0.7902 - accuracy: 0.8032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/56 [=======================>......] - ETA: 0s - loss: 0.7886 - accuracy: 0.8040\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r47/56 [========================>.....] - ETA: 0s - loss: 0.7871 - accuracy: 0.8048\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r49/56 [=========================>....] - ETA: 0s - loss: 0.7858 - accuracy: 0.8055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r51/56 [==========================>...] - ETA: 0s - loss: 0.7846 - accuracy: 0.8061\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r53/56 [===========================>..] - ETA: 0s - loss: 0.7838 - accuracy: 0.8065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r55/56 [============================>.] - ETA: 0s - loss: 0.7830 - accuracy: 0.8068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r56/56 [==============================] - 2s 30ms/step - loss: 0.7824 - accuracy: 0.8070 - val_loss: 0.9121 - val_accuracy: 0.7320\n",
            "\r1/8 [==>...........................] - ETA: 0s - loss: 1.1115 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/8 [=========================>....] - ETA: 0s - loss: 0.9526 - accuracy: 0.7098\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 0s 8ms/step - loss: 0.9121 - accuracy: 0.7320\n",
            "\r1/8 [==>...........................] - ETA: 1s - loss: 1.1115 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - ETA: 0s - loss: 0.9121 - accuracy: 0.7320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 0s 8ms/step - loss: 0.9121 - accuracy: 0.7320\n",
            "\n",
            "Val_loss and Val_Accuracy\n",
            "Score : loss of 0.9121469855308533; accuracy of 73.19999933242798%\n",
            "\n",
            "Balanced_Accuracy\n",
            "Balanced_Accuracy_train:  0.8694, G_mean_tr: 0.8694\n",
            "Balanced_Accuracy_val:  0.7320, G_mean_vl: 0.7320\n",
            "Balanced_Accuracy_test:  0.7359, G_mean_te: 0.7359\n",
            "\n",
            "AUC_Entrainement = 0.869\n",
            "AUC_Validation = 0.732\n",
            "AUC_Teste = 0.736\n",
            "\n",
            "confusion_matrix for train set\n",
            "[[847  49]\n",
            " [185 711]]\n",
            "confusion_matrix for validation set\n",
            "[[100  25]\n",
            " [ 42  83]]\n",
            "confusion_matrix for test set\n",
            "[[ 64  22]\n",
            " [ 61 163]]\n",
            "rapport for test set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.74      0.61        86\n",
            "           1       0.88      0.73      0.80       224\n",
            "\n",
            "    accuracy                           0.73       310\n",
            "   macro avg       0.70      0.74      0.70       310\n",
            "weighted avg       0.78      0.73      0.74       310\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-04 19:47:18.711344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-09-04 19:47:33.618279: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-09-04 19:47:33.619552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-09-04 19:47:33.642609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:33.643596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2022-09-04 19:47:33.643714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-09-04 19:47:33.647286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-09-04 19:47:33.647429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-09-04 19:47:33.648594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-09-04 19:47:33.649082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-09-04 19:47:33.651050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-09-04 19:47:33.651899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-09-04 19:47:33.652195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-09-04 19:47:33.652344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:33.653290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:33.654140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-09-04 19:47:33.654607: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-09-04 19:47:33.654757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:33.655567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2022-09-04 19:47:33.655639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-09-04 19:47:33.655681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-09-04 19:47:33.655720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-09-04 19:47:33.655757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-09-04 19:47:33.655789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-09-04 19:47:33.655825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-09-04 19:47:33.655862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-09-04 19:47:33.655899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-09-04 19:47:33.655985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:33.656844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:33.657627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-09-04 19:47:33.657719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-09-04 19:47:34.296293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-09-04 19:47:34.296341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2022-09-04 19:47:34.296354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2022-09-04 19:47:34.296578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:34.297273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:34.297926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-04 19:47:34.298487: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-09-04 19:47:34.298543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2022-09-04 19:47:34.421433: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-09-04 19:47:34.421905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "2022-09-04 19:47:35.277902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-09-04 19:47:35.605766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-09-04 19:47:35.615059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "#CNN6_mediaeval,Adamax, smote, epques=8, BS=32\n",
        "source activate classification &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python NN_training/CNN_training.py --normalize 1 --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN1_mediaeval,Adamax, smote, epques=8, BS=32\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python NN_training/CNN_training.py  --feat pooled --model multi_task --dset mediaeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfwy0GkMi6Xg",
        "outputId": "502f3d4c-04ba-474d-ad29-fae649f4176b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "2022-10-10 23:57:42.727544: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-10-10 23:57:42.730914: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "2022-10-10 23:57:53.721107: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 177471488 exceeds 10% of free system memory.\n",
            "2022-10-10 23:57:54.159578: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 177471488 exceeds 10% of free system memory.\n",
            "2022-10-10 23:57:54.275842: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 177471488 exceeds 10% of free system memory.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 2048, 64)          448       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 2043, 64)          24640     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2043, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 2038, 128)         49280     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 2033, 128)         98432     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 677, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 677, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 86656)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               44368384  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 44,541,697\n",
            "Trainable params: 44,541,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "2022-10-10 23:57:54.777410: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 177471488 exceeds 10% of free system memory.\n",
            "2022-10-10 23:57:54.801453: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 177471488 exceeds 10% of free system memory.\n",
            "56/56 [==============================] - 85s 1s/step - loss: 2.4065 - accuracy: 0.4970 - val_loss: 1.5837 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - 89s 2s/step - loss: 1.5135 - accuracy: 0.5355 - val_loss: 1.3552 - val_accuracy: 0.5880\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - 87s 2s/step - loss: 1.3083 - accuracy: 0.6152 - val_loss: 1.2720 - val_accuracy: 0.5520\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - 82s 1s/step - loss: 1.1730 - accuracy: 0.6834 - val_loss: 1.1582 - val_accuracy: 0.6040\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - 87s 2s/step - loss: 1.0334 - accuracy: 0.7365 - val_loss: 1.1016 - val_accuracy: 0.6320\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - 87s 2s/step - loss: 0.9535 - accuracy: 0.7662 - val_loss: 1.0749 - val_accuracy: 0.6960\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - 82s 1s/step - loss: 0.8613 - accuracy: 0.8214 - val_loss: 1.0476 - val_accuracy: 0.6760\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - 87s 2s/step - loss: 0.7763 - accuracy: 0.8552 - val_loss: 1.0248 - val_accuracy: 0.6560\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - 82s 1s/step - loss: 0.7587 - accuracy: 0.8361 - val_loss: 1.0764 - val_accuracy: 0.6800\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - 86s 2s/step - loss: 0.7038 - accuracy: 0.8577 - val_loss: 1.0872 - val_accuracy: 0.6640\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - 87s 2s/step - loss: 0.6543 - accuracy: 0.8729 - val_loss: 1.1125 - val_accuracy: 0.6800\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 1.0749 - accuracy: 0.6960\n",
            "Score : loss of 1.0748662948608398; accuracy of 69.59999799728394%\n",
            "\n",
            "Balanced_Accuracy\n",
            "Balanced_Accuracy_train:  0.8203, G_mean_tr: 0.8203\n",
            "Balanced_Accuracy_val:  0.6960, G_mean_vl: 0.6960\n",
            "Balanced_Accuracy_test:  0.6298, G_mean_te: 0.6300\n",
            "\n",
            "AUC_Entrainement = 0.820\n",
            "AUC_Validation = 0.696\n",
            "AUC_Teste = 0.630\n",
            "\n",
            "confusion_matrix for train set\n",
            "[[641 255]\n",
            " [ 67 829]]\n",
            "confusion_matrix for validation set\n",
            "[[ 60  65]\n",
            " [ 11 114]]\n",
            "confusion_matrix for test set\n",
            "[[ 30  56]\n",
            " [ 20 204]]\n",
            "rapport for test set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.35      0.44        86\n",
            "           1       0.78      0.91      0.84       224\n",
            "\n",
            "    accuracy                           0.75       310\n",
            "   macro avg       0.69      0.63      0.64       310\n",
            "weighted avg       0.73      0.75      0.73       310\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKGSBeXdsSzg"
      },
      "source": [
        "SVM_FINAL_TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwAsGObWp2QQ",
        "outputId": "f6b1070e-033a-4d2c-d21a-1629558ea55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "SVM evaluation\n",
            "----------------------------------------\n",
            "Balanced_Accuracy_test=  0.7698\n",
            "G_mean_test= 0.7700\n",
            "AUC_Test = 0.770\n",
            "[[ 61  25]\n",
            " [ 38 186]]\n",
            "classification report\n",
            "----------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.66        86\n",
            "           1       0.88      0.83      0.86       224\n",
            "\n",
            "    accuracy                           0.80       310\n",
            "   macro avg       0.75      0.77      0.76       310\n",
            "weighted avg       0.81      0.80      0.80       310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#SVM on mediaeval\n",
        "%%bash\n",
        "source activate myenv &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python PFE_FINAL_TESTS/SVM_FINAL_TESTS_MEDIAEVAL.py --feat pooled --model multi_task --dset mediaeval --pca 0.98"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJJ83_dk5TVU",
        "outputId": "c0e62955-088b-4501-9cfa-805aecb67581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 251\n",
            " percentage: 18% \n",
            " fake:17%, reel:82% \n",
            "--------------------------------------\n",
            "SVM evaluation\n",
            "----------------------------------------\n",
            "Balanced_Accuracy_test=  0.7560\n",
            "G_mean_test= 0.7581\n",
            "AUC_Test = 0.756\n",
            "[[ 32  13]\n",
            " [ 41 165]]\n",
            "classification report\n",
            "----------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.71      0.54        45\n",
            "           1       0.93      0.80      0.86       206\n",
            "\n",
            "    accuracy                           0.78       251\n",
            "   macro avg       0.68      0.76      0.70       251\n",
            "weighted avg       0.84      0.78      0.80       251\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#SVM on lesa\n",
        "%%bash\n",
        "source activate myenv &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python PFE_FINAL_TESTS/SVM_FINAL_TESTS_LESA.py --feat pooled --model multi_task --dset lesa --pca 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr2v21NTA_7V"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OppCuaotMrzW",
        "outputId": "22674b10-f54e-4b0c-c031-05995ddbf215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "best score: 0.8209\n",
            "----------------------------------------------\n",
            "SVM  on mediaeval,  multi_task-pooled\n",
            "PCA No Components: 0.98, Dim: 584, SV: 1289\n",
            "C: 0.460, Gamma: 1.300, kernel: rbf\n",
            "\n",
            "----------------------------------------------\n",
            "training performances \n",
            "----------------------------------------------\n",
            "Train Accuracy: 0.9196\n",
            "Train AUC-Score: 0.9196\n",
            "Train Balanced_Accuracy:  0.9196\n",
            "Train G_mean: 0.9196 \n",
            "[[810  86]\n",
            " [ 58 838]]\n",
            "----------------------------------------------\n",
            "testing performances \n",
            "----------------------------------------------\n",
            "Test Accuracy: 0.7968\n",
            "Test_roc_auc: 0.7698\n",
            "Test_balanced_Accuracy: 0.7698\n",
            "Test_G_mean: 0.7700, \n",
            "[[186  38]\n",
            " [ 25  61]]\n",
            "----------------------------------------------\n",
            "Test classification report \n",
            "----------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.66        86\n",
            "           1       0.88      0.83      0.86       224\n",
            "\n",
            "    accuracy                           0.80       310\n",
            "   macro avg       0.75      0.77      0.76       310\n",
            "weighted avg       0.81      0.80      0.80       310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "#SVM_mediaeval\n",
        "source activate myenv &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python svm_training/svm_vilbertfeats_New.py --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Ob_5ce9sI3",
        "outputId": "83f046dd-0800-4d20-945d-bc20a09bc3f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "best score: 0.8209\n",
            "----------------------------------------------\n",
            "SVM  on mediaeval,  multi_task-pooled\n",
            "PCA No Components: 0.98, Dim: 584, SV: 1289\n",
            "C: 0.460, Gamma: 1.300, kernel: rbf\n",
            "\n",
            "----------------------------------------------\n",
            "training performances \n",
            "----------------------------------------------\n",
            "Train Accuracy: 0.9196\n",
            "Train AUC-Score: 0.9196\n",
            "Train Balanced_Accuracy:  0.9196\n",
            "Train G_mean: 0.9196 \n",
            "[[810  86]\n",
            " [ 58 838]]\n",
            "----------------------------------------------\n",
            "testing performances \n",
            "----------------------------------------------\n",
            "Test Accuracy: 0.7968\n",
            "Test_roc_auc: 0.7698\n",
            "Test_balanced_Accuracy: 0.7698\n",
            "Test_G_mean: 0.7700, \n",
            "[[186  38]\n",
            " [ 25  61]]\n",
            "----------------------------------------------\n",
            "Test classification report \n",
            "----------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.66        86\n",
            "           1       0.88      0.83      0.86       224\n",
            "\n",
            "    accuracy                           0.80       310\n",
            "   macro avg       0.75      0.77      0.76       310\n",
            "weighted avg       0.81      0.80      0.80       310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "#SVM_mediaeval\n",
        "source activate myenv &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python svm_training/svm_vilbertfeats_New.py --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVpBhIDZYm1b",
        "outputId": "e4bcba7c-c182-4311-86a1-24db15eab9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 251\n",
            " percentage: 18% \n",
            " fake:17%, reel:82% \n",
            "--------------------------------------\n",
            "best score: 0.7677\n",
            "----------------------------------------------\n",
            "SVM  on lesa,  multi_task-pooled\n",
            "PCA No Components: 0.99, Dim: 577, SV: 1229\n",
            "C: 1.250, Gamma: 0.100, kernel: rbf\n",
            "\n",
            "----------------------------------------------\n",
            "training performances \n",
            "----------------------------------------------\n",
            "Train Accuracy: 0.8110\n",
            "Train AUC-Score: 0.8110\n",
            "Train Balanced_Accuracy:  0.8110\n",
            "Train G_mean: 0.8110 \n",
            "[[687 133]\n",
            " [177 643]]\n",
            "----------------------------------------------\n",
            "testing performances \n",
            "----------------------------------------------\n",
            "Test Accuracy: 0.7968\n",
            "Test_roc_auc: 0.7546\n",
            "Test_balanced_Accuracy: 0.7546\n",
            "Test_G_mean: 0.7567, \n",
            "[[169  37]\n",
            " [ 14  31]]\n",
            "----------------------------------------------\n",
            "Test classification report \n",
            "----------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.69      0.55        45\n",
            "           1       0.92      0.82      0.87       206\n",
            "\n",
            "    accuracy                           0.80       251\n",
            "   macro avg       0.69      0.75      0.71       251\n",
            "weighted avg       0.84      0.80      0.81       251\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#SVM on lesa\n",
        "%%bash\n",
        "source activate myenv &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python svm_training/svm_vilbertfeats_New.py --feat pooled --model multi_task --dset lesa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub47EOecY3gC"
      },
      "source": [
        "New training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3tAY3mDN9Sh",
        "outputId": "cd180e71-8b5a-42f9-f398-f155ac0bca07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 19% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 2048, 64)          448       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 2043, 64)          24640     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2043, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 681, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 676, 128)          49280     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 671, 128)          98432     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 223, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 223, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 28544)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               14615040  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 14,788,353\n",
            "Trainable params: 14,788,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/2\n",
            "46/46 [==============================] - 3s 28ms/step - loss: 2.1893 - accuracy: 0.5315 - val_loss: 1.5526 - val_accuracy: 0.5954\n",
            "Epoch 2/2\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1.4822 - accuracy: 0.5894 - val_loss: 1.3271 - val_accuracy: 0.5491\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.3271 - accuracy: 0.5491\n",
            "Score for fold 1: loss of 1.327111005783081; accuracy of 54.913294315338135%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 1.2676 - accuracy: 0.5651 - val_loss: 1.2039 - val_accuracy: 0.5357\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 1.1670 - accuracy: 0.6064 - val_loss: 1.1283 - val_accuracy: 0.6319\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1283 - accuracy: 0.6319\n",
            "Score for fold 2: loss of 1.128306269645691; accuracy of 63.18681240081787%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/2\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.0520 - accuracy: 0.6835 - val_loss: 1.0256 - val_accuracy: 0.6839\n",
            "Epoch 2/2\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 0.9411 - accuracy: 0.7493 - val_loss: 0.9883 - val_accuracy: 0.7385\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.9883 - accuracy: 0.7385\n",
            "Score for fold 3: loss of 0.9882851839065552; accuracy of 73.85057210922241%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.9138 - accuracy: 0.7592 - val_loss: 0.8843 - val_accuracy: 0.7684\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.8430 - accuracy: 0.7897 - val_loss: 0.8166 - val_accuracy: 0.7947\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8166 - accuracy: 0.7947\n",
            "Score for fold 4: loss of 0.8166353106498718; accuracy of 79.47368621826172%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/2\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.8435 - accuracy: 0.7663 - val_loss: 0.7929 - val_accuracy: 0.8305\n",
            "Epoch 2/2\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.7950 - accuracy: 0.7949 - val_loss: 0.7697 - val_accuracy: 0.8192\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7697 - accuracy: 0.8192\n",
            "Score for fold 5: loss of 0.7696542739868164; accuracy of 81.92090392112732%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.327111005783081 - Accuracy: 54.913294315338135%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.128306269645691 - Accuracy: 63.18681240081787%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.9882851839065552 - Accuracy: 73.85057210922241%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.8166353106498718 - Accuracy: 79.47368621826172%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.7696542739868164 - Accuracy: 81.92090392112732%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 70.66905379295349 (+- 10.183080429959126)\n",
            "> Loss: 1.0059984087944032\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "Balanced_Accuracy_train:  0.8526, G_mean_tr: 0.8526\n",
            "Balanced_Accuracy_test:  0.6436, G_mean_te: 0.6439\n",
            "\n",
            "AUC_Entrainement = 0.853\n",
            "AUC_Teste = 0.644\n"
          ]
        }
      ],
      "source": [
        "#CNN_cross_validation_mediaeval,Adamax, smote, epques=8, BS=32\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python NN_training/CNN+CrossValidation.py  --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeH78pY5NmqQ",
        "outputId": "79de44ff-b695-4b49-8841-223a546b55f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
            "test set statistic\n",
            "--------------------------------------\n",
            "Tweets number: 310\n",
            " percentage: 17% \n",
            " fake:27%, reel:72% \n",
            "--------------------------------------\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 2048, 64)          448       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 2043, 64)          24640     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2043, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 681, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 676, 128)          49280     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 671, 128)          98432     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 223, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 223, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 28544)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               14615040  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 14,788,353\n",
            "Trainable params: 14,788,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "56/56 [==============================] - 3s 22ms/step - loss: 2.2021 - accuracy: 0.4832 - val_loss: 1.5092 - val_accuracy: 0.5000\n",
            "Epoch 2/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.4488 - accuracy: 0.5302 - val_loss: 1.3083 - val_accuracy: 0.7040\n",
            "Epoch 3/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.2733 - accuracy: 0.6096 - val_loss: 1.2019 - val_accuracy: 0.5600\n",
            "Epoch 4/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 1.1457 - accuracy: 0.6539 - val_loss: 1.0880 - val_accuracy: 0.7040\n",
            "Epoch 5/8\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 1.0095 - accuracy: 0.7369 - val_loss: 1.0334 - val_accuracy: 0.7240\n",
            "Epoch 6/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 0.9482 - accuracy: 0.7612 - val_loss: 0.9684 - val_accuracy: 0.7560\n",
            "Epoch 7/8\n",
            "56/56 [==============================] - 1s 16ms/step - loss: 0.8915 - accuracy: 0.7756 - val_loss: 1.0203 - val_accuracy: 0.7200\n",
            "Epoch 8/8\n",
            "56/56 [==============================] - 1s 15ms/step - loss: 0.8906 - accuracy: 0.7423 - val_loss: 0.9031 - val_accuracy: 0.7360\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9031 - accuracy: 0.7360\n",
            "Score : loss of 0.9030595421791077; accuracy of 73.60000014305115%\n",
            "\n",
            "Balanced_Accuracy\n",
            "Balanced_Accuracy_train:  0.8426, G_mean_tr: 0.8426\n",
            "Balanced_Accuracy_val:  0.7360, G_mean_vl: 0.7360\n",
            "Balanced_Accuracy_test:  0.6683, G_mean_te: 0.6686\n",
            "\n",
            "AUC_Entrainement = 0.843\n",
            "AUC_Validation = 0.736\n",
            "AUC_Teste = 0.668\n",
            "\n",
            "confusion_matrix for train set\n",
            "[[769 127]\n",
            " [155 741]]\n",
            "confusion_matrix for validation set\n",
            "[[90 35]\n",
            " [31 94]]\n",
            "confusion_matrix for test set\n",
            "[[ 47  39]\n",
            " [ 47 177]]\n",
            "rapport for test set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.55      0.52        86\n",
            "           1       0.82      0.79      0.80       224\n",
            "\n",
            "    accuracy                           0.72       310\n",
            "   macro avg       0.66      0.67      0.66       310\n",
            "weighted avg       0.73      0.72      0.73       310\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#CNN2_mediaeval,Adamax, smote, epques=8, BS=32\n",
        "%cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "!python NN_training/CNN_training.py  --feat pooled --model multi_task --dset mediaeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr-Z6Ud9bkOr"
      },
      "source": [
        "# data set preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GohxOET9cdeu",
        "outputId": "62780e61-1cb2-4e16-9359-5bf241e2db14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***************************lesa**************************\n",
            "(1340, 2)\n",
            "Counter({1: 1111, 0: 229})\n",
            "NB 1=  83 %\n",
            "NB 0=  17 %\n",
            "***************************mediaeval****************************\n",
            "(1725, 2)\n",
            "Counter({1: 1246, 0: 479})\n",
            "NB 1=  72 %\n",
            "NB 0=  28 %\n",
            "*************************combined*********************************************\n",
            "(3065, 2)\n",
            "Counter({1: 2357, 0: 708})\n",
            "NB 1=  77 %\n",
            "NB 0=  23 %\n",
            "*******************************add fake**************\n",
            "(479, 2)\n",
            "(1819, 2)\n",
            "Counter({1: 1111, 0: 708})\n",
            "NB 1=  61 %\n",
            "NB 0=  39 %\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "print(\"***************************lesa**************************\")\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/multimodal_fake_news_detection/data/lesa/splits/train_6.csv',header=None)\n",
        "print(df1.shape)\n",
        "X1 = df1.iloc[:,:-1].values\n",
        "y1 = df1.iloc[:,-1].values\n",
        "print(Counter(y1))\n",
        "print('NB 1= ',round(1111/1340*100),'%')\n",
        "print('NB 0= ',round(229/1340*100),'%')\n",
        "\n",
        "\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/multimodal_fake_news_detection/data/mediaeval/splits/train_6.csv',header=None)\n",
        "print(\"***************************mediaeval****************************\")\n",
        "print(df2.shape)\n",
        "X2= df2.iloc[:,:-1].values\n",
        "y2 = df2.iloc[:,-1].values\n",
        "print(Counter(y2))\n",
        "print('NB 1= ',round(1246/1725*100),'%')\n",
        "print('NB 0= ',round(479/1725*100),'%')\n",
        "\n",
        "print(\"*************************combined*********************************************\")\n",
        "\n",
        "df3=df1.append(df2, ignore_index=True)\n",
        "print(df3.shape)\n",
        "X3 = df3.iloc[:,:-1].values\n",
        "y3 = df3.iloc[:,-1].values\n",
        "print(Counter(y3))\n",
        "print('NB 1= ',round(2357/3065*100),'%')\n",
        "print('NB 0= ',round(708/3065*100),'%')\n",
        "print(\"*******************************add fake**************\")\n",
        "df2=df2.drop(df2.loc[df2[1]==1].index).reset_index(drop = True)\n",
        "print(df2.shape) \n",
        "df4=df1.append(df2, ignore_index=True)\n",
        "print(df4.shape)\n",
        "X4 = df4.iloc[:,:-1].values\n",
        "y4 = df4.iloc[:,-1].values\n",
        "print(Counter(y4))\n",
        "print('NB 1= ',round(1111/1819*100),'%')\n",
        "print('NB 0= ',round(708/1819*100),'%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "rYgTNhVaUea8",
        "outputId": "4f7d2f31-8f55-4261-d49a-251c933ff2ee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "  \n",
        "  \n",
        "Lesa= ['faux', 'vrais'] \n",
        "  \n",
        "data = [229, 1111] \n",
        "  \n",
        "  \n",
        "explode = (0.1, 0.0)#, 0.2, 0.3, 0.0, 0.0) \n",
        "  \n",
        "colors = ( \"beige\", \"blue\")# \"brown\", , \"indigo\", \"beige\") \n",
        "  \n",
        "wp = { 'linewidth' : 1, 'edgecolor' : \"green\" } \n",
        "  \n",
        "def func(pct, allvalues): \n",
        "    absolute = round(pct / 100.*np.sum(allvalues)) \n",
        "    return \"{:.1f}%\\n({:d} )\".format(pct, absolute) \n",
        "  \n",
        "fig, ax = plt.subplots(figsize =(7, 5)) \n",
        "wedges, texts, autotexts = ax.pie(data,  \n",
        "                                  autopct = lambda pct: func(pct, data), \n",
        "                                  explode = explode,  \n",
        "                                  labels = Lesa, \n",
        "                                  shadow = True, \n",
        "                                  colors = colors, \n",
        "                                  startangle = 90, \n",
        "                                  wedgeprops = wp, \n",
        "                                  textprops = dict(color =\"black\",size = 14, weight =\"bold\")) \n",
        "  \n",
        "ax.legend(wedges, Lesa,\n",
        "          loc =\"center left\", \n",
        "          bbox_to_anchor =(1, 0, 0.5, 1)) \n",
        "  \n",
        "plt.setp(autotexts, size = 14, weight =\"bold\") \n",
        "#plt. savefig(\"/content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection/pictures_test/MediaEval_statistics.png\") \n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBLQigvyuEWh",
        "outputId": "75f2f5ff-6681-41e2-d64c-5e6f29c74e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "basic information of dataset\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1339 entries, 0 to 1338\n",
            "Columns: 2053 entries, 1 to 2053\n",
            "dtypes: float64(2053)\n",
            "memory usage: 21.0 MB\n",
            "\n",
            "\n",
            "basics statistics:\n",
            "               1            2     ...          2052          2053\n",
            "count  1339.000000  1339.000000  ...   1339.000000  1.339000e+03\n",
            "mean      0.794594     0.415547  ...   1141.108290  5.610611e+03\n",
            "std       0.898894     0.533070  ...   5003.525585  7.490376e+04\n",
            "min       0.000000     0.000000  ...      0.000000  0.000000e+00\n",
            "25%       0.000000     0.000000  ...      0.000000  5.659136e-01\n",
            "50%       0.493644     0.165345  ...     10.000000  1.238854e+00\n",
            "75%       1.358481     0.730175  ...    154.500000  1.117580e+01\n",
            "max       3.974640     3.128106  ...  61303.000000  2.408320e+06\n",
            "\n",
            "[8 rows x 2053 columns]\n",
            "\n",
            "\n",
            "the uniqueness in dataset\n",
            "\n",
            "\n",
            "1        868\n",
            "2        750\n",
            "3       1054\n",
            "4        749\n",
            "5       1234\n",
            "        ... \n",
            "2049     340\n",
            "2050     965\n",
            "2051    1160\n",
            "2052     329\n",
            "2053    1163\n",
            "Length: 2053, dtype: int64\n",
            "\n",
            "\n",
            "skewness of the dataset\n",
            "By column\n",
            "1        1.064235\n",
            "2        1.397192\n",
            "3        0.483239\n",
            "4        1.330463\n",
            "5        0.223778\n",
            "          ...    \n",
            "2049     8.881400\n",
            "2050     6.985868\n",
            "2051     9.850986\n",
            "2052     7.490634\n",
            "2053    26.699778\n",
            "Length: 2053, dtype: float64\n",
            "\n",
            "\n",
            "By samples\n",
            "0       41.141185\n",
            "1       45.302390\n",
            "2       32.061864\n",
            "3       40.372419\n",
            "4       44.738114\n",
            "          ...    \n",
            "1334    45.290990\n",
            "1335    45.304950\n",
            "1336    32.938718\n",
            "1337    45.285165\n",
            "1338    42.498414\n",
            "Length: 1339, dtype: float64\n",
            "\n",
            "\n",
            "kurtosis of dataset\n",
            "\n",
            "\n",
            "1         0.334914\n",
            "2         1.765343\n",
            "3        -0.574403\n",
            "4         1.148511\n",
            "5        -0.210556\n",
            "           ...    \n",
            "2049    100.136836\n",
            "2050     64.880544\n",
            "2051    141.582693\n",
            "2052     66.135848\n",
            "2053    814.120044\n",
            "Length: 2053, dtype: float64\n",
            "\n",
            "\n",
            "correlation for all features in the dataset\n",
            "\n",
            "\n",
            "          1         2         3     ...      2051      2052      2053\n",
            "1     1.000000  0.188766  0.197718  ...  0.033674 -0.036895 -0.040816\n",
            "2     0.188766  1.000000  0.102895  ...  0.004857  0.093900  0.075159\n",
            "3     0.197718  0.102895  1.000000  ...  0.050795 -0.039687 -0.052126\n",
            "4    -0.233507  0.108251 -0.189826  ...  0.046861  0.094238  0.097189\n",
            "5    -0.089164  0.052463 -0.084942  ... -0.062354 -0.038823  0.008132\n",
            "...        ...       ...       ...  ...       ...       ...       ...\n",
            "2049 -0.042139  0.038101 -0.061585  ... -0.003789  0.032874  0.008915\n",
            "2050 -0.060367  0.101396 -0.045384  ...  0.307068  0.715152  0.609851\n",
            "2051  0.033674  0.004857  0.050795  ...  1.000000  0.208489  0.070561\n",
            "2052 -0.036895  0.093900 -0.039687  ...  0.208489  1.000000  0.225149\n",
            "2053 -0.040816  0.075159 -0.052126  ...  0.070561  0.225149  1.000000\n",
            "\n",
            "[2053 rows x 2053 columns]\n",
            "\n",
            "\n",
            "checking imbalance of the labels\n",
            "Counter({1: 1110, 0: 229})\n",
            "\n",
            "\n",
            "(1339, 2)\n",
            "[[ 0.03777716  0.00503882 -0.00675902 ...  0.00503324 -0.00199392\n",
            "  -0.00150961]\n",
            " [ 0.01381814  0.01433615  0.06266607 ...  0.00692416 -0.0013335\n",
            "  -0.00488625]]\n",
            "[0.07566269 0.05218665]\n",
            "*********************\n",
            "          1         2         3     ...      2051      2052      2053\n",
            "PC-1  0.037777  0.005039 -0.006759  ...  0.005033 -0.001994 -0.001510\n",
            "PC-2  0.013818  0.014336  0.062666  ...  0.006924 -0.001334 -0.004886\n",
            "\n",
            "[2 rows x 2053 columns]\n",
            "*********************\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate classification &&\n",
        "cd /content/drive/MyDrive/Halima-ColabNotebooks/multimodal_fake_news_detection\n",
        "python svm_training/svm_training1/dataset_info.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLzRtGtqNoWI",
        "outputId": "a67411ea-a887-4bbe-9061-7ec48d834ae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a=np.array([False, True , False])\n",
        "a=a*1\n",
        "print(a)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "w3PUx5_rzVvz",
        "OP6T2S_-3J9I",
        "Mgia-Ua1kDnV",
        "vDbGB2PGQGsR",
        "EAd3yDw6jiuq",
        "G4BFqouOBR2U",
        "zcsJCCE4Bd6H",
        "kuHdytPGCvqT",
        "xGw-f1naDoDN",
        "95z3wTPKFFgf",
        "ue1se4osD88N",
        "nDg9kzcz18Ry",
        "UZ_2dxsRFUzB",
        "Nr-Z6Ud9bkOr"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
